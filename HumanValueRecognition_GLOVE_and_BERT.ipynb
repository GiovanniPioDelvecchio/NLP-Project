{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c104e49b5744e85ac32bf8eaa631aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04b4b7d920d849ff9de655e4f1be121e",
              "IPY_MODEL_d270f8ff78464a03aedf5af00972dfc6",
              "IPY_MODEL_ff43d4605e8747689b01a22321e4e8a6"
            ],
            "layout": "IPY_MODEL_87e123e1a6214a0e8fa19ce34dae93eb"
          }
        },
        "04b4b7d920d849ff9de655e4f1be121e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ebef705591493595b2775423d6d518",
            "placeholder": "​",
            "style": "IPY_MODEL_c88ee05eee7f4d93be1c5a5c6c1f97f8",
            "value": "100%"
          }
        },
        "d270f8ff78464a03aedf5af00972dfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0398f8bc05480da47f52ee1e5555da",
            "max": 4176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f14eef72b914af7a66c9b6d3a758294",
            "value": 4176
          }
        },
        "ff43d4605e8747689b01a22321e4e8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1a88b1d4b1c4100b32a6c3cde34611f",
            "placeholder": "​",
            "style": "IPY_MODEL_314b831f60784d499a29dddad43ee838",
            "value": " 4176/4176 [00:03&lt;00:00, 1163.93ex/s]"
          }
        },
        "87e123e1a6214a0e8fa19ce34dae93eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ebef705591493595b2775423d6d518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88ee05eee7f4d93be1c5a5c6c1f97f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f0398f8bc05480da47f52ee1e5555da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f14eef72b914af7a66c9b6d3a758294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1a88b1d4b1c4100b32a6c3cde34611f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314b831f60784d499a29dddad43ee838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c58f6475e834652b5c6c1cf3cee7423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1b08c6cabbb4ee48469c093a13e6ef2",
              "IPY_MODEL_4d1dd8b20bbd42d6b8770ff7a9568ee0",
              "IPY_MODEL_f97b734bfc73452eb06e955e2ab27835"
            ],
            "layout": "IPY_MODEL_a648212654eb4000a0bd55491057a44e"
          }
        },
        "b1b08c6cabbb4ee48469c093a13e6ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1730709430a04d81bdbccfd8a3eec405",
            "placeholder": "​",
            "style": "IPY_MODEL_e8408933aad543af9c52b616097ed255",
            "value": "100%"
          }
        },
        "4d1dd8b20bbd42d6b8770ff7a9568ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2354b540b74d6a84aba1ddf4efad87",
            "max": 1217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bf108f03ee34136a5d035708b2e3c0b",
            "value": 1217
          }
        },
        "f97b734bfc73452eb06e955e2ab27835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f3337c65664ee5856158b7fb05bdcb",
            "placeholder": "​",
            "style": "IPY_MODEL_df9f0e53d92c457a81fd14e70e8638c2",
            "value": " 1217/1217 [00:00&lt;00:00, 1329.64ex/s]"
          }
        },
        "a648212654eb4000a0bd55491057a44e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1730709430a04d81bdbccfd8a3eec405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8408933aad543af9c52b616097ed255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad2354b540b74d6a84aba1ddf4efad87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf108f03ee34136a5d035708b2e3c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f3337c65664ee5856158b7fb05bdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df9f0e53d92c457a81fd14e70e8638c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cb4e570df1f486f9f34bcd69dbcc74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_252a945a052b4aaa8acf7afc1857754c",
              "IPY_MODEL_bfa9388962d74bd3a381820a2ce91706",
              "IPY_MODEL_495f20874fe34888b4fc4611dc2e2c12"
            ],
            "layout": "IPY_MODEL_676e6bad052a453cbe7ffe031f2f1a51"
          }
        },
        "252a945a052b4aaa8acf7afc1857754c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658e54be10cd4e6eb0611d9eaa6f4800",
            "placeholder": "​",
            "style": "IPY_MODEL_5d9478b7068b4ef086eedee50f5345bb",
            "value": "100%"
          }
        },
        "bfa9388962d74bd3a381820a2ce91706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7082b017a24c5bb6899b27b4bc440d",
            "max": 1896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03a53be19d7c4a73b2ba91cad2a07bd1",
            "value": 1896
          }
        },
        "495f20874fe34888b4fc4611dc2e2c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45dec7c9ac6845c5ad55166bd13fd4d5",
            "placeholder": "​",
            "style": "IPY_MODEL_13ebafd1415040b690860fda01899345",
            "value": " 1896/1896 [00:01&lt;00:00, 864.40ex/s]"
          }
        },
        "676e6bad052a453cbe7ffe031f2f1a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658e54be10cd4e6eb0611d9eaa6f4800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d9478b7068b4ef086eedee50f5345bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be7082b017a24c5bb6899b27b4bc440d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a53be19d7c4a73b2ba91cad2a07bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45dec7c9ac6845c5ad55166bd13fd4d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ebafd1415040b690860fda01899345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "204ed3813e5b4e5e9026485ed5c25d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c86b67c9398a4636acacf6f14e4fd42a",
              "IPY_MODEL_e9e750d5c8b046d9b732ec3e190381cb",
              "IPY_MODEL_37627cf9a90745da96168588f184cb96"
            ],
            "layout": "IPY_MODEL_a3cf63338e6f4fc38ee6c774301ae6bd"
          }
        },
        "c86b67c9398a4636acacf6f14e4fd42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e2a3fa1428411d9fc5e9ad5768de22",
            "placeholder": "​",
            "style": "IPY_MODEL_0a14b0194e9048aa92e339ee707cf088",
            "value": "100%"
          }
        },
        "e9e750d5c8b046d9b732ec3e190381cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43335f1174284f3ca193c28d4068482a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d0cd3510f674a618c7fa26cf267ae50",
            "value": 100
          }
        },
        "37627cf9a90745da96168588f184cb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea8dc2ab196433da436b34143297a80",
            "placeholder": "​",
            "style": "IPY_MODEL_5aa84a2a8a664bd0b34eb3d07e2ef643",
            "value": " 100/100 [00:00&lt;00:00, 1046.66ex/s]"
          }
        },
        "a3cf63338e6f4fc38ee6c774301ae6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e2a3fa1428411d9fc5e9ad5768de22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a14b0194e9048aa92e339ee707cf088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43335f1174284f3ca193c28d4068482a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0cd3510f674a618c7fa26cf267ae50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fea8dc2ab196433da436b34143297a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa84a2a8a664bd0b34eb3d07e2ef643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP course project\n",
        "**Summary**: Application of text classification approaches for Human Value Detection <br>\n",
        "**Members**:\n",
        "- Dell'Olio Domenico\n",
        "- Delvecchio Giovanni Pio\n",
        "- Disabato Raffaele  \n"
      ],
      "metadata": {
        "id": "wWUTpjsbw3DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project was developed in order to create and test various models to address the task of Human Value Detection proposed in the challenge: <br>\n",
        "https://touche.webis.de/semeval23/touche23-web/index.html <br>\n",
        "\n",
        "The challenge can be tackled as a multi-label text clasification problem, thus we decided to implement and test various architectures in order to compare their performances. <br>\n",
        "These architectures were either already present at the state of the art or were obtained as a result of experiments."
      ],
      "metadata": {
        "id": "D6YEI0XMxl2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook contains the following implementations:\n",
        "- GloVe baseline with two layers of Bi-GRU, followed by flatten and two dense layers with ReLU activation and a single dense layer with no activation;\n",
        "- BERT baseline with two layers of Bi-LSTM (transfer learning), where the output cell states are concatenated and passed to a dense layer with ReLU activation and a single dense layer with no activation;\n",
        "- finetuning of BERT followed by a dense layer with ReLU activation followed by a dense layer with no activation.\n",
        "\n",
        "## This notebook does **not** contain:\n",
        "- exstensive Data analysis (it is explored in the other notebook)"
      ],
      "metadata": {
        "id": "3tcwwV4uu6kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cF2LQqwOLX2",
        "outputId": "70c555db-09a5-4bbf-d80f-85ed9c332feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# installation of the required libraries\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for the download of the datasets\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYe5zjeVO5yS",
        "outputId": "86b0aee2-2e09-4ba9-bbd4-9507d3c0448b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-09 16:03:10--  https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1012498 (989K) [application/octet-stream]\n",
            "Saving to: ‘arguments-training.tsv’\n",
            "\n",
            "arguments-training. 100%[===================>] 988.77K   176KB/s    in 6.7s    \n",
            "\n",
            "2023-02-09 16:03:20 (147 KB/s) - ‘arguments-training.tsv’ saved [1012498/1012498]\n",
            "\n",
            "--2023-02-09 16:03:20--  https://zenodo.org/record/7550385/files/labels-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253843 (248K) [application/octet-stream]\n",
            "Saving to: ‘labels-training.tsv’\n",
            "\n",
            "labels-training.tsv 100%[===================>] 247.89K   318KB/s    in 0.8s    \n",
            "\n",
            "2023-02-09 16:03:23 (318 KB/s) - ‘labels-training.tsv’ saved [253843/253843]\n",
            "\n",
            "--2023-02-09 16:03:23--  https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362608 (354K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>] 354.11K   304KB/s    in 1.2s    \n",
            "\n",
            "2023-02-09 16:03:26 (304 KB/s) - ‘arguments-validation.tsv’ saved [362608/362608]\n",
            "\n",
            "--2023-02-09 16:03:26--  https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89484 (87K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation.tsv’\n",
            "\n",
            "labels-validation.t 100%[===================>]  87.39K   452KB/s    in 0.2s    \n",
            "\n",
            "2023-02-09 16:03:28 (452 KB/s) - ‘labels-validation.tsv’ saved [89484/89484]\n",
            "\n",
            "--2023-02-09 16:03:28--  https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290185 (283K) [application/octet-stream]\n",
            "Saving to: ‘arguments-test.tsv’\n",
            "\n",
            "arguments-test.tsv  100%[===================>] 283.38K   351KB/s    in 0.8s    \n",
            "\n",
            "2023-02-09 16:03:31 (351 KB/s) - ‘arguments-test.tsv’ saved [290185/290185]\n",
            "\n",
            "--2023-02-09 16:03:31--  https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22082 (22K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation-zhihu.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>]  21.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-09 16:03:33 (268 MB/s) - ‘arguments-validation-zhihu.tsv’ saved [22082/22082]\n",
            "\n",
            "--2023-02-09 16:03:33--  https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5072 (5.0K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation-zhihu.tsv’\n",
            "\n",
            "labels-validation-z 100%[===================>]   4.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-09 16:03:34 (697 MB/s) - ‘labels-validation-zhihu.tsv’ saved [5072/5072]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for dataset loading\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# torch imports\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "from torchinfo import summary\n",
        "from torch.optim import AdamW\n",
        "\n",
        "#huggingface imports\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "\n",
        "# progress bar\n",
        "from tqdm import tqdm\n",
        "# garbage collector\n",
        "import gc\n",
        "\n",
        "# imports for evaluation\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "4-K7IcSRPtPO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "  \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "  Params:\n",
        "    seed: the seed to use. \n",
        "  \"\"\"\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "OFk0dSBHFCYx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell needed to fix the seeds and define the available device\n",
        "# for the training of the models\n",
        "seed = 10\n",
        "fix_random(seed)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "DbJvCz2MOnRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2060401c-e338-4e08-a9aa-ac7b55e4b07b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def huggingface_from_pandas(pandas_df):\n",
        "  \"\"\"\n",
        "  Function converting a pandas dataframe to a huggingface dataset.\n",
        "  It also returns an ordered list containing the target labels\n",
        "\n",
        "  Params:\n",
        "    pandas_df: the dataset that has to be converted\n",
        "  Returns:\n",
        "    hf_ds:     the huggingface dataset obrained from pandas_df\n",
        "    label_cols: the ordered list of target labels of pandas_df\n",
        "  \"\"\"\n",
        "\n",
        "  hf_ds = Dataset.from_pandas(pandas_df, preserve_index=False)\n",
        "  hf_ds = hf_ds.remove_columns([\"Argument ID\", \"Argument ID2\"])\n",
        "  # Aggregating labels in a single list\n",
        "  hf_ds = hf_ds.map(lambda x:{\"labels\": [int(x[col]) for col in hf_ds.column_names if\n",
        "                                      col not in ['Conclusion', 'Stance', 'Premise']]})\n",
        "  label_cols = [col for col in hf_ds.column_names if col not in ['Conclusion', 'Stance', 'Premise', \"labels\"]]\n",
        "  # here we are removing the columns related to the labels from the dataset\n",
        "  hf_ds = hf_ds.remove_columns(label_cols)\n",
        "  return hf_ds, label_cols"
      ],
      "metadata": {
        "id": "pLN6XBISHnLf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The challenge provides the already splitted dataset in Train, Validation and Test splits. However the Test split does not have public labels available, \n",
        "so we decided to split the Training set in (Training, Validation) \n",
        "(with proportions 80-20 on unique conclusions) and to use the validation set as Test set.  <br>\n",
        "We decided to probe the robustness of our model on the Chinese validation\n",
        "set too, which has a different cultural background."
      ],
      "metadata": {
        "id": "hq8Fgjoj0__P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_wrt_conclusions(train, ratio = 0.8):\n",
        "  val = []\n",
        "  unique_conc = pd.unique(train[\"Conclusion\"])\n",
        "  num_train_con = int(len(unique_conc)*ratio)\n",
        "  train_unique_conc = np.random.choice(unique_conc, num_train_con, replace = False)\n",
        "  val_unique_conc = set(unique_conc) - set(train_unique_conc)\n",
        "  train_set_to_return = train[train.Conclusion.isin(train_unique_conc)] \n",
        "  val_set_to_return = train[train.Conclusion.isin(val_unique_conc)]\n",
        "  return train_set_to_return, val_set_to_return"
      ],
      "metadata": {
        "id": "swL5m3C4x7wV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loading and splitting\n",
        "raw_training = pd.read_csv(\"arguments-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_training_lab = pd.read_csv(\"labels-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test = pd.read_csv(\"arguments-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_lab = pd.read_csv(\"labels-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn=pd.read_csv(\"arguments-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn_lab=pd.read_csv(\"labels-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "\n",
        "train = raw_training.join(raw_training_lab,how='inner' ,lsuffix='2') # joining labels\n",
        "test = raw_test.join(raw_test_lab, how='inner', lsuffix='2') # joining labels\n",
        "test_chn = raw_test_chn.join(raw_test_chn_lab, how='inner', lsuffix='2') # joining labels\n",
        "fix_random(seed)\n",
        "train, val = train_test_split_wrt_conclusions(train) # splitting training\n",
        "\n",
        "train_ds, label_list = huggingface_from_pandas(train)\n",
        "val_ds, _ = huggingface_from_pandas(val)\n",
        "test_ds, _ = huggingface_from_pandas(test)\n",
        "test_chn_ds, _ = huggingface_from_pandas(test_chn) \n",
        "\n",
        "print(\"Single example from the training dataset: \")\n",
        "print(train_ds[0])\n",
        "print(\"Full list of target labels: \")\n",
        "print(label_list)\n",
        "num_classes = len(label_list)\n",
        "print(\"Total number of target labels: \")\n",
        "print(num_classes)\n",
        "whole_dataset = DatasetDict()\n",
        "whole_dataset[\"train\"] = train_ds.with_format(\"torch\")\n",
        "whole_dataset[\"val\"] = val_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test\"] = test_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test_chn\"] = test_chn_ds.with_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "6c104e49b5744e85ac32bf8eaa631aa4",
            "04b4b7d920d849ff9de655e4f1be121e",
            "d270f8ff78464a03aedf5af00972dfc6",
            "ff43d4605e8747689b01a22321e4e8a6",
            "87e123e1a6214a0e8fa19ce34dae93eb",
            "d7ebef705591493595b2775423d6d518",
            "c88ee05eee7f4d93be1c5a5c6c1f97f8",
            "6f0398f8bc05480da47f52ee1e5555da",
            "5f14eef72b914af7a66c9b6d3a758294",
            "b1a88b1d4b1c4100b32a6c3cde34611f",
            "314b831f60784d499a29dddad43ee838",
            "4c58f6475e834652b5c6c1cf3cee7423",
            "b1b08c6cabbb4ee48469c093a13e6ef2",
            "4d1dd8b20bbd42d6b8770ff7a9568ee0",
            "f97b734bfc73452eb06e955e2ab27835",
            "a648212654eb4000a0bd55491057a44e",
            "1730709430a04d81bdbccfd8a3eec405",
            "e8408933aad543af9c52b616097ed255",
            "ad2354b540b74d6a84aba1ddf4efad87",
            "2bf108f03ee34136a5d035708b2e3c0b",
            "89f3337c65664ee5856158b7fb05bdcb",
            "df9f0e53d92c457a81fd14e70e8638c2",
            "8cb4e570df1f486f9f34bcd69dbcc74a",
            "252a945a052b4aaa8acf7afc1857754c",
            "bfa9388962d74bd3a381820a2ce91706",
            "495f20874fe34888b4fc4611dc2e2c12",
            "676e6bad052a453cbe7ffe031f2f1a51",
            "658e54be10cd4e6eb0611d9eaa6f4800",
            "5d9478b7068b4ef086eedee50f5345bb",
            "be7082b017a24c5bb6899b27b4bc440d",
            "03a53be19d7c4a73b2ba91cad2a07bd1",
            "45dec7c9ac6845c5ad55166bd13fd4d5",
            "13ebafd1415040b690860fda01899345",
            "204ed3813e5b4e5e9026485ed5c25d0f",
            "c86b67c9398a4636acacf6f14e4fd42a",
            "e9e750d5c8b046d9b732ec3e190381cb",
            "37627cf9a90745da96168588f184cb96",
            "a3cf63338e6f4fc38ee6c774301ae6bd",
            "80e2a3fa1428411d9fc5e9ad5768de22",
            "0a14b0194e9048aa92e339ee707cf088",
            "43335f1174284f3ca193c28d4068482a",
            "8d0cd3510f674a618c7fa26cf267ae50",
            "fea8dc2ab196433da436b34143297a80",
            "5aa84a2a8a664bd0b34eb3d07e2ef643"
          ]
        },
        "id": "FU98Kgv5Q3PO",
        "outputId": "ed6b6469-6d2d-4c68-8a18-920062ccbd1b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4176 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c104e49b5744e85ac32bf8eaa631aa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1217 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c58f6475e834652b5c6c1cf3cee7423"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1896 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cb4e570df1f486f9f34bcd69dbcc74a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "204ed3813e5b4e5e9026485ed5c25d0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single example from the training dataset: \n",
            "{'Conclusion': 'We should ban human cloning', 'Stance': 'in favor of', 'Premise': 'we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.', 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "Full list of target labels: \n",
            "['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']\n",
            "Total number of target labels: \n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, loader):\n",
        "  \"\"\"\n",
        "  Function needed to obtain the prediction for the target labels\n",
        "  given a model and a data loader.\n",
        "\n",
        "  Params:\n",
        "    model: the model that will be used to obtain the predictions over\n",
        "           the labels\n",
        "    loader: the data loader needed to feed the model with the data for which\n",
        "            we want to obtain label predictions\n",
        "  Returns:\n",
        "    Y_preds: tensor containing the predicted label for each example.\n",
        "             These labels are obtained as the output of the model passed to\n",
        "             a sigmoid function.\n",
        "  \"\"\"\n",
        "  Y_preds = []\n",
        "  model.eval()\n",
        "  for X, Y in loader:\n",
        "    with torch.no_grad():\n",
        "      preds = model(X)\n",
        "    Y_preds.append(preds)\n",
        "  gc.collect()\n",
        "  Y_preds = torch.cat(Y_preds)\n",
        "  Y_preds = Y_preds.sigmoid()\n",
        "  return Y_preds.detach()\n",
        "\n",
        "def keep_above_thresh(Y_preds, thr):\n",
        "  \"\"\"\n",
        "  Function needed to convert the results of the models to hard labels\n",
        "  using a threshold.\n",
        "  \n",
        "  Params:\n",
        "    Y_preds: scores obtained by the model which have to be converted to hard\n",
        "             labels\n",
        "    thr: threshold to be applied to the scores, element of (0, 1), if a score\n",
        "         is greater than thr it becomes a hard label with value 1, \n",
        "         0 otherwise\n",
        "  Retuns:\n",
        "    Y_preds_thr: hard labels obtained by thresholding Y_preds with thr\n",
        "  \"\"\"\n",
        "  Y_preds_thr = np.copy(Y_preds.numpy())\n",
        "  max_rows = Y_preds_thr.shape[0]\n",
        "  max_cols = Y_preds_thr.shape[1]\n",
        "  for i in range(max_rows):\n",
        "    new_row = np.array([1 if Y_preds_thr[i][j] > thr else 0 for j in range(max_cols)])\n",
        "    Y_preds_thr[i] = new_row\n",
        "  return Y_preds_thr\n",
        "\n",
        "def compute_macro_score(M_true, M_pred, score_func):\n",
        "  \"\"\"\n",
        "  Function needed to compute the macro aggregation of a scored function\n",
        "  over the different classes.\n",
        "\n",
        "  Params:\n",
        "    M_true: true labels needed to compute the scores\n",
        "    M_pred: predicted labels needed to compute the scores\n",
        "    score_func: scoring function to be computed\n",
        "  Returns:\n",
        "    macro: aggregation of the result of score_func computed over all the\n",
        "           labels.\n",
        "    scores: list of per-label score\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for i in range(M_true.shape[1]):\n",
        "      true = M_true[:, i]\n",
        "      pred = M_pred[:, i]\n",
        "      if score_func == accuracy_score:\n",
        "        scores.append(score_func(true, pred))\n",
        "      else: \n",
        "        scores.append(score_func(true, pred, zero_division=0))\n",
        "  macro = np.mean(scores)\n",
        "  return macro, scores\n",
        "  \n",
        "def support(true, pred, zero_division):\n",
        "  \"\"\"\n",
        "  Utility function to compute the support of the class labels,\n",
        "  pred and zero_division are dummy parameters needed to have conformity\n",
        "  with the sklearn functions to compute scores.\n",
        "\n",
        "  Params: \n",
        "    true: binary true labels for a single class for each example that are needed\n",
        "          to compute the support for the single class\n",
        "    pred: dummy parameter\n",
        "    zero_division: dummy parameter\n",
        "  Returns:\n",
        "    sum(true): the number of example for a single class (support)\n",
        "  \"\"\"\n",
        "  return sum(true)\n",
        "\n",
        "def print_report(classifier, loader, y_true, threshold, labels=label_list):\n",
        "  \"\"\"\n",
        "  Function needed to print the classification results given a classifier,\n",
        "  a dataset loader, true labels and a threshold. \n",
        "  The printed report includes macro accuracy, precision, recall and F1, as \n",
        "  well as per-class accuracy, precision, recall, F1 and support.\n",
        "\n",
        "  Params:\n",
        "    classifier: the model that has to be evaluated\n",
        "    loader: data-loader needed to feed the data to the classifier to get \n",
        "            predicted labels\n",
        "    y_true: true labels associated to the dataset associated to the loader\n",
        "    threshold: threshold for the conversion of the scores to hard labels,\n",
        "               check keep_above_thresh for further details\n",
        "    labels: ordered list of target labels. Defaults to the list extracted from\n",
        "            the dataset\n",
        "  \"\"\"\n",
        "\n",
        "  Y_preds = make_predictions(classifier, loader)\n",
        "  Y_preds_thr = keep_above_thresh(Y_preds.to('cpu'), threshold)\n",
        "\n",
        "  f1_macro, f1 = compute_macro_score(y_true, Y_preds_thr, f1_score)\n",
        "  acc_macro, acc = compute_macro_score(y_true, Y_preds_thr, accuracy_score)\n",
        "  prec_macro, prec = compute_macro_score(y_true, Y_preds_thr, precision_score)\n",
        "  rec_macro, rec = compute_macro_score(y_true, Y_preds_thr, recall_score)\n",
        "  _, sup = compute_macro_score(y_true, Y_preds_thr, support)\n",
        "\n",
        "  print(\"----- MACRO AVG. -----\")\n",
        "  print(f\"  F1-score:\\t{round(f1_macro,4)}\\n\\\n",
        "  Precision:\\t{round(prec_macro,4)}\\n\\\n",
        "  Recall:\\t{round(rec_macro,4)}\\n\\\n",
        "  Accuracy:\\t{round(acc_macro,4)}\")\n",
        "  print(\"----- PER-CLASS VALUES -----\")\n",
        "  print(\"  \\t\\t\\t\\tF1-score\\tPrecision\\tRecall\\t\\tAccuracy\\tSupport\")\n",
        "  for i in range(len(labels)):\n",
        "    print(\"  \" + labels[i]+\" \"*(len(max(labels, key=len))-len(labels[i])), end=\"\\t\")\n",
        "    print(f\"{round(f1[i],4)}\\t\\t{round(prec[i],4)}\\t\\t{round(rec[i],4)}\\t\\t{round(acc[i],4)}\\t\\t{sup[i]}\")"
      ],
      "metadata": {
        "id": "uU_qeLA6l7OE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first model that was developed is a GloVe 100d embedding + two Bi-GRU layers\n",
        "That serves as an advanced baseline to perfom experiments for multi-label classification problems like the current one. \n",
        "It is still a baseline since it has a simple architecture, OOV are treated using <br>zero-vectors, the hidden states of the Bi-GRU layers are initialized \n",
        "as zero-vectors and most importantly the model does not work with contextual information, but only with the semantics of the words. <br>\n",
        "Moreover an heavy preprocessing to the dataset is not applied except for lowercasing the arguments, tokenization and the addition of truncation and padding because the GloVe embeddings would return too many unmasked zero vectors. <br>\n",
        "About padding and truncation: the maximum allowed length is 35 which is \n",
        "slightly above the sum of the mean token length value for the premises and the\n",
        "conclusion. "
      ],
      "metadata": {
        "id": "LosoIWWz_5e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained GloVe setup\n",
        "\n",
        "global_vectors = GloVe(name='6B', dim=100)\n",
        "\n",
        "# the current choice is to give an id to each word\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "TOU9N3-WJgn3",
        "outputId": "6d236141-5774-4fe0-edad-6ec6404af0c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:43, 5.28MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:16<00:00, 24181.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words_emb = 35\n",
        "embed_len = 100\n",
        "\n",
        "# collate function where the Premises are tokenized and embedded in batches\n",
        "def vectorize_batch(batch):\n",
        "    X = [elem[\"Premise\"] + \" \" + elem[\"Stance\"] + \" \" +elem[\"Conclusion\"] for elem in batch]\n",
        "    Y = [elem[\"labels\"] for elem in batch]\n",
        "    X = [tokenizer(x) for x in X]\n",
        "    X = [tokens+[\"\"] * (max_words_emb-len(tokens))  if len(tokens)<max_words_emb else tokens[:max_words_emb] for tokens in X]\n",
        "    X_tensor = torch.zeros(len(batch), max_words_emb, embed_len)\n",
        "    Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "    for i, tokens in enumerate(X):\n",
        "        X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
        "        Y_tensor[i] = Y[i]\n",
        "    return X_tensor, Y_tensor"
      ],
      "metadata": {
        "id": "0eFmzKrDbvlJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class EmbeddingClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmbeddingClassifier, self).__init__() \n",
        "       \n",
        "        self.gru_layers = 1\n",
        "\n",
        "        self.gru = nn.GRU(input_size = embed_len,\n",
        "                          hidden_size = embed_len,\n",
        "                          num_layers = self.gru_layers,\n",
        "                          batch_first=True, \n",
        "                          bidirectional = True)\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "        self.linear_1 = nn.Linear(max_words_emb*embed_len*self.gru_layers*2, 512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_2 = nn.Linear(512,128)\n",
        "        self.linear_3 = nn.Linear(128, num_classes)\n",
        "        \n",
        "                \n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        h0 = torch.zeros(2*self.gru_layers,X_batch.shape[0], embed_len)\n",
        "        h0 = h0.to(device)\n",
        "        out, hn = self.gru(X_batch, h0)\n",
        "        out = self.flatten(out)\n",
        "        out = self.linear_1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear_2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear_3(out)\n",
        "        return out\n",
        "\n",
        "# Function needed to compute the validation loss and the accuracy\n",
        "def CalcValLoss(model, loss_fn, val_loader):\n",
        "    with torch.no_grad():\n",
        "      Y_shuffled, Y_preds, losses = [],[],[]\n",
        "      for X, Y in val_loader:\n",
        "        preds = model(X)\n",
        "        loss = loss_fn(preds, Y)\n",
        "        losses.append(loss.item())\n",
        "        Y_shuffled.append(Y)\n",
        "        Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "      Y_shuffled = torch.cat(Y_shuffled)\n",
        "      Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "      loss = torch.tensor(losses).mean()\n",
        "      print(\"Valid Loss : {:.3f}\".format(loss))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Training function\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name):\n",
        "    patience_acc = 0\n",
        "    precedent_loss = np.Inf\n",
        "    model.train()\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "\n",
        "            Y_preds = model(X)\n",
        "\n",
        "            loss = loss_fn(Y_preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        loss = CalcValLoss(model, loss_fn, val_loader)\n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "           patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc > early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"_best.pth\")\n",
        "        precedent_loss = loss\n",
        "            \n",
        "    return model"
      ],
      "metadata": {
        "id": "XHy7Zl7EK-FA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 1e-4\n",
        "batch_size = 32\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "embed_classifier = EmbeddingClassifier()\n",
        "optimizer = Adam(embed_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Construction of the Dataloaders for train and validation\n",
        "train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "\n",
        "\n",
        "embed_classifier.to(device)\n",
        "summary(embed_classifier, \n",
        "                input_data=next(iter(train_loader))[0],\n",
        "                device=device)\n"
      ],
      "metadata": {
        "id": "k4KSPSXAN6z0",
        "outputId": "11d8bdac-0980-4197-a791-1c762e642d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "EmbeddingClassifier                      [32, 20]                  --\n",
              "├─GRU: 1-1                               [32, 35, 200]             121,200\n",
              "├─Flatten: 1-2                           [32, 7000]                --\n",
              "├─Linear: 1-3                            [32, 512]                 3,584,512\n",
              "├─ReLU: 1-4                              [32, 512]                 --\n",
              "├─Linear: 1-5                            [32, 128]                 65,664\n",
              "├─ReLU: 1-6                              [32, 128]                 --\n",
              "├─Linear: 1-7                            [32, 20]                  2,580\n",
              "==========================================================================================\n",
              "Total params: 3,773,956\n",
              "Trainable params: 3,773,956\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 252.63\n",
              "==========================================================================================\n",
              "Input size (MB): 0.45\n",
              "Forward/backward pass size (MB): 1.96\n",
              "Params size (MB): 15.10\n",
              "Estimated Total Size (MB): 17.50\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "embed_classifier = TrainModel(embed_classifier, loss_fn, optimizer, train_loader, val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"glove\")"
      ],
      "metadata": {
        "id": "Ws7o13y5P5o4",
        "outputId": "2430d098-310a-4e44-dd5d-78de404bf15e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:15<00:00,  8.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.412\n",
            "Train Loss : 0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:15<00:00,  8.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.409\n",
            "Train Loss : 0.414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:15<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.400\n",
            "Train Loss : 0.404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:15<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.392\n",
            "Train Loss : 0.389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:18<00:00,  7.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.386\n",
            "Train Loss : 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:20<00:00,  6.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.382\n",
            "Train Loss : 0.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:20<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.378\n",
            "Train Loss : 0.354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:18<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.375\n",
            "Train Loss : 0.346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:22<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.374\n",
            "Train Loss : 0.339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:18<00:00,  7.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.374\n",
            "Train Loss : 0.332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:18<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.374\n",
            "Train Loss : 0.325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:19<00:00,  6.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.375\n",
            "Train Loss : 0.318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:17<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.377\n",
            "Train Loss : 0.311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:17<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.378\n",
            "Train Loss : 0.303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:18<00:00,  7.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.380\n",
            "Train Loss : 0.296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(embed_classifier, val_loader, whole_dataset[\"val\"][\"labels\"] ,0.25)\n",
        "# batchsize 32, 1e-4, no conclusion/stance 0.3648 max 25\n",
        "# batchsize 64, 1e-4, no conclusion/stance 0.3478\n",
        "# batchsize 32, 1e-4, conclusion/stance 0.3505 max 35\n"
      ],
      "metadata": {
        "id": "NsdbFRv1yrmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQktRncjzJ1C",
        "outputId": "8ea6e920-c8d5-4cd4-b4ae-1e5430be4545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model.to(device)\n",
        "print(\"Bert loaded\")"
      ],
      "metadata": {
        "id": "tt17dYqothM3",
        "outputId": "ec1d8bc2-4cae-49cd-a3a5-a9949ffcf41c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bert loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words_bert = 70\n",
        "# collate function that uses the tokenizer relative to the bert pretrained model\n",
        "def bert_vectorize_batch(batch):\n",
        "    X = [elem[\"Premise\"] + \" [SEP] \" + elem[\"Stance\"] + \" [SEP] \" + elem[\"Conclusion\"] for elem in batch]\n",
        "    Y = [elem[\"labels\"] for elem in batch]\n",
        "    X = bert_tokenizer(X, padding=\"max_length\", truncation=\"longest_first\", return_tensors = \"pt\", max_length = max_words_bert) \n",
        "    Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "    for i, tokens in enumerate(Y):    \n",
        "        Y_tensor[i] = Y[i]\n",
        "    X_tensor = torch.stack([X[\"input_ids\"], X[\"token_type_ids\"], X[\"attention_mask\"]])\n",
        "\n",
        "    return X_tensor, Y_tensor\n",
        "\n",
        "train_dataset = whole_dataset[\"train\"]\n",
        "val_dataset = whole_dataset[\"val\"] \n",
        "test_dataset = whole_dataset[\"test\"] "
      ],
      "metadata": {
        "id": "gCwN1D6evfAF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class BertLSTM(nn.Module):\n",
        "    def __init__(self,bert_model):\n",
        "        super(BertLSTM, self).__init__() \n",
        "        self.lstm_layers = 2\n",
        "        self.lstm_hs = 128\n",
        "        bert_hidden_size = bert_model.config.hidden_size\n",
        "\n",
        "        self.bert_model = bert_model\n",
        "        for param in self.bert_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=bert_hidden_size,\n",
        "                            hidden_size=self.lstm_hs,\n",
        "                            num_layers=self.lstm_layers ,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        self.reducer_c0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "        self.reducer_h0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "        self.linear_1 = nn.Linear(self.lstm_hs*2*self.lstm_layers, self.lstm_hs)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_2 = nn.Linear(self.lstm_hs, num_classes) \n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        out = self.bert_model(input_ids=X_batch[0], token_type_ids = X_batch[1], attention_mask = X_batch[2])\n",
        "        cell = self.reducer_c0(out.pooler_output)\n",
        "        hidden = self.reducer_h0(out.pooler_output)\n",
        "        out = out.last_hidden_state[:,1:,:]\n",
        "        c0 = torch.stack([cell,cell,cell,cell])\n",
        "        h0 = torch.stack([hidden, hidden, hidden, hidden])\n",
        "        out_lstm, hc_n  = self.lstm(out, (h0, c0))\n",
        "        c_n = hc_n[1].permute(1, 0, 2)\n",
        "        out = torch.cat([c_n[:,0,:], c_n[:,1,:]], 1)\n",
        "        out2 = torch.cat([c_n[:,2,:], c_n[:,3,:]], 1)\n",
        "        out = torch.cat([out, out2], 1)\n",
        "        out = self.linear_1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear_2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "oEb_5p623uWU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "prebert_classifier = BertLSTM(bert_model)\n",
        "optimizer = Adam(prebert_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "bert_train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "prebert_classifier.to(device)\n",
        "summary(prebert_classifier, \n",
        "                input_data=next(iter(bert_train_loader))[0],\n",
        "                device=device)"
      ],
      "metadata": {
        "id": "1sU40iio3-4l",
        "outputId": "7b6a55fa-689e-4025-b21a-91ff34ee9cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "BertLSTM                                                [32, 20]                  --\n",
              "├─BertModel: 1-1                                        [32, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [32, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [32, 70, 768]             (23,440,896)\n",
              "│    │    └─Embedding: 3-2                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              (393,216)\n",
              "│    │    └─LayerNorm: 3-4                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Dropout: 3-5                                [32, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [32, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        (85,054,464)\n",
              "│    └─BertPooler: 2-3                                  [32, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [32, 768]                 (590,592)\n",
              "│    │    └─Tanh: 3-8                                   [32, 768]                 --\n",
              "├─Linear: 1-2                                           [32, 128]                 98,432\n",
              "├─Linear: 1-3                                           [32, 128]                 98,432\n",
              "├─LSTM: 1-4                                             [32, 69, 256]             1,314,816\n",
              "├─Linear: 1-5                                           [32, 128]                 65,664\n",
              "├─ReLU: 1-6                                             [32, 128]                 --\n",
              "├─Linear: 1-7                                           [32, 20]                  2,580\n",
              "=========================================================================================================\n",
              "Total params: 111,062,164\n",
              "Trainable params: 1,579,924\n",
              "Non-trainable params: 109,482,240\n",
              "Total mult-adds (G): 6.40\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 1863.20\n",
              "Params size (MB): 444.25\n",
              "Estimated Total Size (MB): 2307.50\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "prebert_classifier = TrainModel(prebert_classifier, loss_fn, optimizer, bert_train_loader, bert_val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"bertencoder\")"
      ],
      "metadata": {
        "id": "qr86sx6J4cJY",
        "outputId": "f6fc3f44-ba51-4657-ffcb-82de60985268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:23<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.387\n",
            "Train Loss : 0.398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:24<00:00,  5.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.368\n",
            "Train Loss : 0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:22<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.363\n",
            "Train Loss : 0.327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 105/131 [00:18<00:04,  5.29it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(prebert_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "n_wI6jIOW4xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prebert_classifier = None\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Bv6fzs7uvYPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaaf3c59-810e-4a69-e122-45a36008aa8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class FineTunedBert(nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(FineTunedBert, self).__init__() \n",
        "        self.bert_model = bert_model\n",
        "        for param in self.bert_model.parameters():\n",
        "            param.requires_grad = True\n",
        "        bert_hidden_size = bert_model.config.hidden_size\n",
        "        self.linear_1 = nn.Linear(bert_hidden_size, bert_hidden_size//2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_2 = nn.Linear(bert_hidden_size//2, num_classes)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "\n",
        "        out = self.bert_model(input_ids=X_batch[0], \n",
        "                              token_type_ids = X_batch[1],\n",
        "                              attention_mask = X_batch[2])\n",
        "\n",
        "        out = out.last_hidden_state[:,0,:]\n",
        "        out = self.linear_1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear_2(out)\n",
        "        return out\n",
        "\n",
        "# Training function\n",
        "def finetune_bert(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name, scheduler):\n",
        "    patience_acc = 0\n",
        "    precedent_loss = np.Inf\n",
        "    model.train()\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            model.zero_grad()\n",
        "            Y_preds = model(X)\n",
        "            loss = loss_fn(Y_preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        loss = CalcValLoss(model, loss_fn, val_loader)\n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "           patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          precedent_loss = loss\n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc > early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"best.pth\")\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "L2AFayf470lu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_unfrozen = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model_unfrozen.to(device)\n",
        "print(\"reloaded\")"
      ],
      "metadata": {
        "outputId": "934cc0f5-ce8c-4fd0-806a-f4aad727071f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLK5mrMjAMAj"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 4\n",
        "learning_rate = 5e-5\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "finetune_classifier = FineTunedBert(bert_model_unfrozen)\n",
        "optimizer = AdamW(finetune_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
        "\n",
        "\n",
        "bert_train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(val_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(test_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
        "                                            num_training_steps=len(bert_train_loader)*epochs)\n",
        "\n",
        "finetune_classifier.to(device)\n",
        "summary(finetune_classifier,input_data=next(iter(bert_train_loader))[0], device=device, dtypes = [torch.int]*3)"
      ],
      "metadata": {
        "id": "v1bsrMwW_KYH",
        "outputId": "02122f55-b729-4d68-b5e7-5e4bce036279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "FineTunedBert                                           [16, 20]                  --\n",
              "├─BertModel: 1-1                                        [16, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [16, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [16, 70, 768]             23,440,896\n",
              "│    │    └─Embedding: 3-2                              [16, 70, 768]             1,536\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              393,216\n",
              "│    │    └─LayerNorm: 3-4                              [16, 70, 768]             1,536\n",
              "│    │    └─Dropout: 3-5                                [16, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [16, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        85,054,464\n",
              "│    └─BertPooler: 2-3                                  [16, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [16, 768]                 590,592\n",
              "│    │    └─Tanh: 3-8                                   [16, 768]                 --\n",
              "├─Linear: 1-2                                           [16, 384]                 295,296\n",
              "├─ReLU: 1-3                                             [16, 384]                 --\n",
              "├─Linear: 1-4                                           [16, 20]                  7,700\n",
              "=========================================================================================================\n",
              "Total params: 109,785,236\n",
              "Trainable params: 109,785,236\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.75\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.03\n",
              "Forward/backward pass size (MB): 929.55\n",
              "Params size (MB): 439.14\n",
              "Estimated Total Size (MB): 1368.72\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "finetune_classifier = finetune_bert(finetune_classifier, \n",
        "                                   loss_fn, optimizer,\n",
        "                                   bert_train_loader,\n",
        "                                   bert_val_loader,\n",
        "                                   epochs,\n",
        "                                   {\"patience\": 3, \"delta\": 1e-4}, \n",
        "                                   \"finebert\", scheduler)\n",
        "# 5e-5, 3 epochs, 32 batch size 0.436\n",
        "# 3e-5, 3 epochs, 16 batch size 0.43\n",
        "# 5e-5, 3 epochs, 16 batch size 0.4887\n",
        "# 5e-5, 4 epochs, 16 batch size 0.5115\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Bka5d2uStJ",
        "outputId": "c1a3f803-33d4-463b-8af8-8a22156d801d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:01<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.373\n",
            "Train Loss : 0.404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:02<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.345\n",
            "Train Loss : 0.323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:02<00:00,  4.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.338\n",
            "Train Loss : 0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:02<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.329\n",
            "Train Loss : 0.252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINETUNED BERT:\")\n",
        "print_report(finetune_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf3ede8-2cf5-4a74-d0b9-2ba59dd6bf9d",
        "id": "igiHgAFsvifc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINETUNED BERT:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.403\n",
            "  Precision:\t0.4485\n",
            "  Recall:\t0.4291\n",
            "  Accuracy:\t0.841\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3554\t\t0.2488\t\t0.622\t\t0.848\t\t82\n",
            "  Self-direction: action    \t0.5338\t\t0.4942\t\t0.5802\t\t0.756\t\t293\n",
            "  Stimulation               \t0.1154\t\t0.3333\t\t0.0698\t\t0.9622\t\t43\n",
            "  Hedonism                  \t0.2703\t\t1.0\t\t0.1562\t\t0.9778\t\t32\n",
            "  Achievement               \t0.6441\t\t0.5745\t\t0.7328\t\t0.7584\t\t363\n",
            "  Power: dominance          \t0.2694\t\t0.3939\t\t0.2047\t\t0.8841\t\t127\n",
            "  Power: resources          \t0.6031\t\t0.58\t\t0.6282\t\t0.8118\t\t277\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.9269\t\t89\n",
            "  Security: personal        \t0.7101\t\t0.6254\t\t0.8214\t\t0.7223\t\t504\n",
            "  Security: societal        \t0.7298\t\t0.6716\t\t0.7991\t\t0.7798\t\t453\n",
            "  Tradition                 \t0.2745\t\t0.3182\t\t0.2414\t\t0.9088\t\t87\n",
            "  Conformity: rules         \t0.5463\t\t0.468\t\t0.6559\t\t0.7502\t\t279\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.954\t\t56\n",
            "  Humility                  \t0.1031\t\t0.3333\t\t0.061\t\t0.9285\t\t82\n",
            "  Benevolence: caring       \t0.4129\t\t0.4251\t\t0.4013\t\t0.7149\t\t304\n",
            "  Benevolence: dependability\t0.288\t\t0.257\t\t0.3274\t\t0.7765\t\t168\n",
            "  Universalism: concern     \t0.6519\t\t0.5515\t\t0.7968\t\t0.6524\t\t497\n",
            "  Universalism: nature      \t0.7681\t\t0.8281\t\t0.7162\t\t0.9737\t\t74\n",
            "  Universalism: tolerance   \t0.4358\t\t0.5652\t\t0.3545\t\t0.917\t\t110\n",
            "  Universalism: objectivity \t0.3488\t\t0.3015\t\t0.4138\t\t0.8159\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "bert_chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n"
      ],
      "metadata": {
        "id": "RjbLllyCSzCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(embed_classifier, chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "62tEI5umoyte",
        "outputId": "defac49f-7600-4591-d31a-90d371a0078c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.1647\n",
            "  Precision:\t0.2646\n",
            "  Recall:\t0.1446\n",
            "  Accuracy:\t0.8745\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.0\t\t0.0\t\t0.0\t\t0.88\t\t6\n",
            "  Self-direction: action    \t0.2667\t\t0.5\t\t0.1818\t\t0.89\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Achievement               \t0.481\t\t0.475\t\t0.4872\t\t0.59\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Power: resources          \t0.3529\t\t0.4\t\t0.3158\t\t0.78\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.4762\t\t0.4545\t\t0.5\t\t0.67\t\t30\n",
            "  Security: societal        \t0.3462\t\t0.4286\t\t0.2903\t\t0.66\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.125\t\t1.0\t\t0.0667\t\t0.86\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.1429\t\t0.5\t\t0.0833\t\t0.88\t\t12\n",
            "  Benevolence: dependability\t0.0\t\t0.0\t\t0.0\t\t0.97\t\t3\n",
            "  Universalism: concern     \t0.4545\t\t0.4348\t\t0.4762\t\t0.76\t\t21\n",
            "  Universalism: nature      \t0.4615\t\t0.6\t\t0.375\t\t0.93\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Universalism: objectivity \t0.1875\t\t0.5\t\t0.1154\t\t0.74\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(prebert_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "o9mxpo4jorh4",
        "outputId": "75823938-6387-4710-d7cd-829370a133a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.2551\n",
            "  Precision:\t0.2188\n",
            "  Recall:\t0.3798\n",
            "  Accuracy:\t0.8035\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.5556\t\t0.4167\t\t0.8333\t\t0.92\t\t6\n",
            "  Self-direction: action    \t0.2979\t\t0.1944\t\t0.6364\t\t0.67\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Achievement               \t0.6\t\t0.4444\t\t0.9231\t\t0.52\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.9\t\t1\n",
            "  Power: resources          \t0.375\t\t0.2459\t\t0.7895\t\t0.5\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.495\t\t0.3521\t\t0.8333\t\t0.49\t\t30\n",
            "  Security: societal        \t0.4719\t\t0.3621\t\t0.6774\t\t0.53\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.3448\t\t0.3571\t\t0.3333\t\t0.81\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.4167\t\t0.4167\t\t0.4167\t\t0.86\t\t12\n",
            "  Benevolence: dependability\t0.0541\t\t0.0294\t\t0.3333\t\t0.65\t\t3\n",
            "  Universalism: concern     \t0.6154\t\t0.5161\t\t0.7619\t\t0.8\t\t21\n",
            "  Universalism: nature      \t0.3636\t\t0.6667\t\t0.25\t\t0.93\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Universalism: objectivity \t0.5122\t\t0.375\t\t0.8077\t\t0.6\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(finetune_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "l8nyZS91oqwE",
        "outputId": "0ce7e5b4-01af-424a-8a7f-542d21c8ec6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.2712\n",
            "  Precision:\t0.2211\n",
            "  Recall:\t0.3944\n",
            "  Accuracy:\t0.836\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.375\t\t0.2308\t\t1.0\t\t0.8\t\t6\n",
            "  Self-direction: action    \t0.36\t\t0.2308\t\t0.8182\t\t0.68\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t0\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Achievement               \t0.6598\t\t0.5517\t\t0.8205\t\t0.67\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Power: resources          \t0.4314\t\t0.3438\t\t0.5789\t\t0.71\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t1\n",
            "  Security: personal        \t0.5412\t\t0.4182\t\t0.7667\t\t0.61\t\t30\n",
            "  Security: societal        \t0.4444\t\t0.3902\t\t0.5161\t\t0.6\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.4324\t\t0.3636\t\t0.5333\t\t0.79\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.3158\t\t0.2308\t\t0.5\t\t0.74\t\t12\n",
            "  Benevolence: dependability\t0.0952\t\t0.0556\t\t0.3333\t\t0.81\t\t3\n",
            "  Universalism: concern     \t0.6154\t\t0.5161\t\t0.7619\t\t0.8\t\t21\n",
            "  Universalism: nature      \t0.7368\t\t0.6364\t\t0.875\t\t0.95\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.97\t\t2\n",
            "  Universalism: objectivity \t0.4167\t\t0.4545\t\t0.3846\t\t0.72\t\t26\n"
          ]
        }
      ]
    }
  ]
}