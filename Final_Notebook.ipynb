{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2222e6ffb3a14e09bb2cff351fdb721d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f59dd00cfa8e446bbf5a220b6d3e49b6",
              "IPY_MODEL_74a88c1ca8644a12a70f106d2680a4c8",
              "IPY_MODEL_992f97febc9f4392aeeef20a271bfb2a"
            ],
            "layout": "IPY_MODEL_132a1d280a6c484da148a77b4f810f3d"
          }
        },
        "f59dd00cfa8e446bbf5a220b6d3e49b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f71abc470cdc4a4f99b62659f07c36e7",
            "placeholder": "​",
            "style": "IPY_MODEL_fc5faf65847941f59547f0d4f0bcf498",
            "value": "100%"
          }
        },
        "74a88c1ca8644a12a70f106d2680a4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe896d3b807744beaa29c52ea593641f",
            "max": 4176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dad8e14257fb4c43bfd4b0ec655afaa4",
            "value": 4176
          }
        },
        "992f97febc9f4392aeeef20a271bfb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfad52be42f4f19a5a2e63f1f64ea05",
            "placeholder": "​",
            "style": "IPY_MODEL_0d2207458dde46279f0df27d5337d172",
            "value": " 4176/4176 [00:04&lt;00:00, 542.40ex/s]"
          }
        },
        "132a1d280a6c484da148a77b4f810f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71abc470cdc4a4f99b62659f07c36e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5faf65847941f59547f0d4f0bcf498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe896d3b807744beaa29c52ea593641f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad8e14257fb4c43bfd4b0ec655afaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acfad52be42f4f19a5a2e63f1f64ea05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2207458dde46279f0df27d5337d172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75e12e37f59543cc910f3d53ee34ba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcaca6ce81794cbfb5c91f920640a4d1",
              "IPY_MODEL_bcd46877dd6345ac9cfc896ac6cdbe01",
              "IPY_MODEL_08ce17f27ba54031a2ac642a27089d0f"
            ],
            "layout": "IPY_MODEL_680bf3bddfaf43739d144d41e66487af"
          }
        },
        "dcaca6ce81794cbfb5c91f920640a4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd0fc44fd5a4a28ab3156b24dab7a7b",
            "placeholder": "​",
            "style": "IPY_MODEL_64ac68b39f154607ae653194416504cd",
            "value": "100%"
          }
        },
        "bcd46877dd6345ac9cfc896ac6cdbe01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_277956d0bc7445c488c9b51fa74f4b46",
            "max": 1217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_500dbedbddf14321aeef1f31752364ad",
            "value": 1217
          }
        },
        "08ce17f27ba54031a2ac642a27089d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79c1e31a0f143b69811e019bdb6509f",
            "placeholder": "​",
            "style": "IPY_MODEL_47f03008e7734bfb9e9de38605535850",
            "value": " 1217/1217 [00:01&lt;00:00, 973.82ex/s]"
          }
        },
        "680bf3bddfaf43739d144d41e66487af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd0fc44fd5a4a28ab3156b24dab7a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ac68b39f154607ae653194416504cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "277956d0bc7445c488c9b51fa74f4b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500dbedbddf14321aeef1f31752364ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e79c1e31a0f143b69811e019bdb6509f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f03008e7734bfb9e9de38605535850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e0be0ac870b44659ae4850b037edc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52a36fe4834d4eabb26a886c74fe90dd",
              "IPY_MODEL_5abd3e560f8048a6ac42a357b0a81743",
              "IPY_MODEL_8772de9ebcb14fd7843fcf0ea16d7aa8"
            ],
            "layout": "IPY_MODEL_baf8e434341a4109bdd1339810fed772"
          }
        },
        "52a36fe4834d4eabb26a886c74fe90dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f55d60cf0d4f1f9b6b94dd0c635838",
            "placeholder": "​",
            "style": "IPY_MODEL_526eacacb8dd4d8f87b40e2cc223f9dc",
            "value": "100%"
          }
        },
        "5abd3e560f8048a6ac42a357b0a81743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86446c5e428d47c281d743f7610273a5",
            "max": 1896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_254e6454588e48289a4af3ec4ee0a2d5",
            "value": 1896
          }
        },
        "8772de9ebcb14fd7843fcf0ea16d7aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e8f34b7bf344efb4471fef01c6067a",
            "placeholder": "​",
            "style": "IPY_MODEL_5204b40c9e7a492a9aff98392ae5f93c",
            "value": " 1896/1896 [00:01&lt;00:00, 1334.11ex/s]"
          }
        },
        "baf8e434341a4109bdd1339810fed772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f55d60cf0d4f1f9b6b94dd0c635838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526eacacb8dd4d8f87b40e2cc223f9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86446c5e428d47c281d743f7610273a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254e6454588e48289a4af3ec4ee0a2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69e8f34b7bf344efb4471fef01c6067a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5204b40c9e7a492a9aff98392ae5f93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931006f7ac8d40e8b3dd68733fc45ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d33cce604f06433eb2b3b2fcbd5ed78e",
              "IPY_MODEL_6cfd3513e8a146898412edc202f00356",
              "IPY_MODEL_a0d9f30baba149648db795d50733b072"
            ],
            "layout": "IPY_MODEL_06b075807aa54d5c876e90bc9220a0c5"
          }
        },
        "d33cce604f06433eb2b3b2fcbd5ed78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d61edb6766f4ef1ac7f2c7ad12446cd",
            "placeholder": "​",
            "style": "IPY_MODEL_c13bf5dbcb144edfb143d4ed1e4ea56b",
            "value": "100%"
          }
        },
        "6cfd3513e8a146898412edc202f00356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d986c432ded4780b7af1409151b611c",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc502712038a4b6ea10d62238353f992",
            "value": 100
          }
        },
        "a0d9f30baba149648db795d50733b072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8867c3ff9f243f0b6fcbcf05dfdece0",
            "placeholder": "​",
            "style": "IPY_MODEL_22fbfc6b997c4bc1b112892056e08204",
            "value": " 100/100 [00:00&lt;00:00, 1929.22ex/s]"
          }
        },
        "06b075807aa54d5c876e90bc9220a0c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d61edb6766f4ef1ac7f2c7ad12446cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13bf5dbcb144edfb143d4ed1e4ea56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d986c432ded4780b7af1409151b611c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc502712038a4b6ea10d62238353f992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8867c3ff9f243f0b6fcbcf05dfdece0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fbfc6b997c4bc1b112892056e08204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e43302874f45388ad5320f6867ca7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c207a527cdbd445e8c051d94cd4035fb",
              "IPY_MODEL_b865316022d6439bbacc94e435f09186",
              "IPY_MODEL_b0c2cb96837e43f7a128cad4be0ccb24"
            ],
            "layout": "IPY_MODEL_6b041d8d8fce4d72850303f3dded58ee"
          }
        },
        "c207a527cdbd445e8c051d94cd4035fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87b578adb5843f5ae195ef9a35ebc7d",
            "placeholder": "​",
            "style": "IPY_MODEL_806f1497caf04d52b9246871c7ac814c",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b865316022d6439bbacc94e435f09186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a195a91b97c04eb891dea5c54ce10154",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8212945919d49788213c9b927292222",
            "value": 231508
          }
        },
        "b0c2cb96837e43f7a128cad4be0ccb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7dd1f201a04d49a9229002be0ba903",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc7ca8891de4706905a4496e1ea08ec",
            "value": " 232k/232k [00:00&lt;00:00, 262kB/s]"
          }
        },
        "6b041d8d8fce4d72850303f3dded58ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87b578adb5843f5ae195ef9a35ebc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806f1497caf04d52b9246871c7ac814c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a195a91b97c04eb891dea5c54ce10154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8212945919d49788213c9b927292222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b7dd1f201a04d49a9229002be0ba903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc7ca8891de4706905a4496e1ea08ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d790bef888c45bcaba7fc412feec7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d01edc801f149edabc6adcff5ad5915",
              "IPY_MODEL_024e0fde8f6e47ec9a5865fe2e68e284",
              "IPY_MODEL_1c9092e6aace4609a0fcce0cce5e3ba9"
            ],
            "layout": "IPY_MODEL_f9a4a0ea610b472d8a730bbf8b4e0670"
          }
        },
        "8d01edc801f149edabc6adcff5ad5915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2113ebe0c4214bd89e3a2813149003bd",
            "placeholder": "​",
            "style": "IPY_MODEL_63dd1d001d9f4ab4833fc8da8fcddb31",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "024e0fde8f6e47ec9a5865fe2e68e284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1006a3fca90543d3a8598ee5d8f33c8c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6db00617370d46dcb891f902ce4d6289",
            "value": 28
          }
        },
        "1c9092e6aace4609a0fcce0cce5e3ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5558d2755d194eb7aa6d000710b98c57",
            "placeholder": "​",
            "style": "IPY_MODEL_9ccec07865f348168273307e4877ca94",
            "value": " 28.0/28.0 [00:00&lt;00:00, 961B/s]"
          }
        },
        "f9a4a0ea610b472d8a730bbf8b4e0670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2113ebe0c4214bd89e3a2813149003bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63dd1d001d9f4ab4833fc8da8fcddb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1006a3fca90543d3a8598ee5d8f33c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db00617370d46dcb891f902ce4d6289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5558d2755d194eb7aa6d000710b98c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ccec07865f348168273307e4877ca94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8143d64533b84ebaac12523c428af741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f1483b541cb49b1a97e7eb62d0611a4",
              "IPY_MODEL_0ddf4ae9364247aab61e0bb53e2b5b1d",
              "IPY_MODEL_2cfa47170e2b4943851e024812912717"
            ],
            "layout": "IPY_MODEL_07f2a689d0064a079900a4090ca8e8f0"
          }
        },
        "2f1483b541cb49b1a97e7eb62d0611a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4644341faf9a47ef98e226cfe32e1732",
            "placeholder": "​",
            "style": "IPY_MODEL_3a9b58d2e90243bda813374fb788083c",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0ddf4ae9364247aab61e0bb53e2b5b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0343f4a183ca4f7f9fb51defc6d80a73",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_492094176a1144ada704aaf8a50e1c53",
            "value": 570
          }
        },
        "2cfa47170e2b4943851e024812912717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79539f3533814475b539b2609b4d044a",
            "placeholder": "​",
            "style": "IPY_MODEL_002bdcc7899f4017ba7c45b91e344e47",
            "value": " 570/570 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "07f2a689d0064a079900a4090ca8e8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4644341faf9a47ef98e226cfe32e1732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9b58d2e90243bda813374fb788083c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0343f4a183ca4f7f9fb51defc6d80a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492094176a1144ada704aaf8a50e1c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79539f3533814475b539b2609b4d044a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002bdcc7899f4017ba7c45b91e344e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2973e3fcbfc84d8d95d67ec870d78154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97d4458980734d64b1c3497c894de259",
              "IPY_MODEL_ceb0b7dadd3547a2893eafc2ff67c845",
              "IPY_MODEL_454ce92d492d45278f30103dfdc3cde9"
            ],
            "layout": "IPY_MODEL_08769365a26b42b8bcfd228693932e89"
          }
        },
        "97d4458980734d64b1c3497c894de259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7722128d454dc6b4d3dfcf9d377ac5",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6cd46ced964561ba5fec19b244b009",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "ceb0b7dadd3547a2893eafc2ff67c845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144558dc00304744bccdb603c3d6697d",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af6e42a16528413cb6357aa52d8d4ab5",
            "value": 440473133
          }
        },
        "454ce92d492d45278f30103dfdc3cde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e99378184940c2b808e0d20f6ca4b8",
            "placeholder": "​",
            "style": "IPY_MODEL_4f8c3e5064c942719deb95425e2d3566",
            "value": " 440M/440M [00:02&lt;00:00, 192MB/s]"
          }
        },
        "08769365a26b42b8bcfd228693932e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7722128d454dc6b4d3dfcf9d377ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6cd46ced964561ba5fec19b244b009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "144558dc00304744bccdb603c3d6697d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af6e42a16528413cb6357aa52d8d4ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68e99378184940c2b808e0d20f6ca4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8c3e5064c942719deb95425e2d3566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP course project\n",
        "**Summary**: Application of text classification approaches for Human Value Detection <br>\n",
        "**Members**:\n",
        "- Dell'Olio Domenico\n",
        "- Delvecchio Giovanni Pio\n",
        "- Disabato Raffaele  \n"
      ],
      "metadata": {
        "id": "wWUTpjsbw3DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project was developed in order to create and test various models to address the task of Human Value Detection proposed in the challenge: <br>\n",
        "https://touche.webis.de/semeval23/touche23-web/index.html <br>\n",
        "\n",
        "The challenge can be tackled as a multi-label text clasification problem, thus we decided to implement and test various architectures in order to compare their performances. <br>\n",
        "These architectures were either already present at the state of the art or were obtained as a result of experiments."
      ],
      "metadata": {
        "id": "D6YEI0XMxl2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook contains the following implementations:\n",
        "- GloVe baseline with two layers of Bi-GRU, followed by flatten and two dense layers with ReLU activation and a single dense layer with no activation;\n",
        "- BERT baseline with two layers of Bi-LSTM (transfer learning), where the output cell states are concatenated and passed to a dense layer with ReLU activation and a single dense layer with no activation;\n",
        "- finetuning of BERT followed by a dense layer with ReLU activation followed by a dense layer with no activation.\n",
        "\n",
        "## This notebook does **not** contain:\n",
        "- exstensive Data analysis (it is explored in the other notebook)"
      ],
      "metadata": {
        "id": "3tcwwV4uu6kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cF2LQqwOLX2",
        "outputId": "24fb0e36-938d-49e1-a246-b6e8bbe37f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# installation of the required libraries\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for the download of the datasets\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYe5zjeVO5yS",
        "outputId": "e49900a7-ebd3-477d-8a33-96e5088e4e1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-10 13:38:58--  https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1012498 (989K) [application/octet-stream]\n",
            "Saving to: ‘arguments-training.tsv’\n",
            "\n",
            "arguments-training. 100%[===================>] 988.77K   324KB/s    in 3.1s    \n",
            "\n",
            "2023-02-10 13:39:03 (324 KB/s) - ‘arguments-training.tsv’ saved [1012498/1012498]\n",
            "\n",
            "--2023-02-10 13:39:03--  https://zenodo.org/record/7550385/files/labels-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253843 (248K) [application/octet-stream]\n",
            "Saving to: ‘labels-training.tsv’\n",
            "\n",
            "labels-training.tsv 100%[===================>] 247.89K   319KB/s    in 0.8s    \n",
            "\n",
            "2023-02-10 13:39:06 (319 KB/s) - ‘labels-training.tsv’ saved [253843/253843]\n",
            "\n",
            "--2023-02-10 13:39:06--  https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362608 (354K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>] 354.11K   308KB/s    in 1.2s    \n",
            "\n",
            "2023-02-10 13:39:09 (308 KB/s) - ‘arguments-validation.tsv’ saved [362608/362608]\n",
            "\n",
            "--2023-02-10 13:39:09--  https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89484 (87K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation.tsv’\n",
            "\n",
            "labels-validation.t 100%[===================>]  87.39K   455KB/s    in 0.2s    \n",
            "\n",
            "2023-02-10 13:39:12 (455 KB/s) - ‘labels-validation.tsv’ saved [89484/89484]\n",
            "\n",
            "--2023-02-10 13:39:12--  https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290185 (283K) [application/octet-stream]\n",
            "Saving to: ‘arguments-test.tsv’\n",
            "\n",
            "arguments-test.tsv  100%[===================>] 283.38K   339KB/s    in 0.8s    \n",
            "\n",
            "2023-02-10 13:39:15 (339 KB/s) - ‘arguments-test.tsv’ saved [290185/290185]\n",
            "\n",
            "--2023-02-10 13:39:15--  https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22082 (22K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation-zhihu.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>]  21.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-10 13:39:17 (231 MB/s) - ‘arguments-validation-zhihu.tsv’ saved [22082/22082]\n",
            "\n",
            "--2023-02-10 13:39:17--  https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5072 (5.0K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation-zhihu.tsv’\n",
            "\n",
            "labels-validation-z 100%[===================>]   4.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-10 13:39:19 (915 MB/s) - ‘labels-validation-zhihu.tsv’ saved [5072/5072]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for dataset loading\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# torch imports\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "from torchinfo import summary\n",
        "from torch.optim import AdamW\n",
        "\n",
        "#huggingface imports\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "\n",
        "# progress bar\n",
        "from tqdm import tqdm\n",
        "# garbage collector\n",
        "import gc\n",
        "\n",
        "# imports for evaluation\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "4-K7IcSRPtPO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "  \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "  Params:\n",
        "    seed: the seed to use. \n",
        "  \"\"\"\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "OFk0dSBHFCYx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell needed to fix the seeds and define the available device\n",
        "# for the training of the models\n",
        "seed = 10\n",
        "fix_random(seed)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "DbJvCz2MOnRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0c25fa-1b94-4fd6-9de4-9fa92a34e7b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def huggingface_from_pandas(pandas_df):\n",
        "  \"\"\"\n",
        "  Function converting a pandas dataframe to a huggingface dataset.\n",
        "  It also returns an ordered list containing the target labels\n",
        "\n",
        "  Params:\n",
        "    pandas_df: the dataset that has to be converted\n",
        "  Returns:\n",
        "    hf_ds:     the huggingface dataset obrained from pandas_df\n",
        "    label_cols: the ordered list of target labels of pandas_df\n",
        "  \"\"\"\n",
        "\n",
        "  hf_ds = Dataset.from_pandas(pandas_df, preserve_index=False)\n",
        "  hf_ds = hf_ds.remove_columns([\"Argument ID\", \"Argument ID2\"])\n",
        "  # Aggregating labels in a single list\n",
        "  hf_ds = hf_ds.map(lambda x:{\"labels\": [int(x[col]) for col in hf_ds.column_names if\n",
        "                                      col not in ['Conclusion', 'Stance', 'Premise']]})\n",
        "  label_cols = [col for col in hf_ds.column_names if col not in ['Conclusion', 'Stance', 'Premise', \"labels\"]]\n",
        "  # here we are removing the columns related to the labels from the dataset\n",
        "  hf_ds = hf_ds.remove_columns(label_cols)\n",
        "  return hf_ds, label_cols"
      ],
      "metadata": {
        "id": "pLN6XBISHnLf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The challenge provides the already splitted dataset in Train, Validation and Test splits. However the Test split does not have public labels available, \n",
        "so we decided to split the Training set in (Training, Validation) \n",
        "(with proportions 80-20 on unique conclusions) and to use the validation set as Test set.  <br>\n",
        "We decided to probe the robustness of our model on the Chinese validation\n",
        "set too, which has a different cultural background."
      ],
      "metadata": {
        "id": "hq8Fgjoj0__P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_wrt_conclusions(train, ratio = 0.8):\n",
        "  \"\"\"\n",
        "  Function needed to perform the splits over the original train dataset,\n",
        "  in order to obtain a train and a validation set which are divided by unique\n",
        "  conclusions. The ratio parameter is needed in order to assign which portion \n",
        "  of the unique conclusions must be selected for the train split.\n",
        "  \n",
        "  Params:\n",
        "    train: the original train set, to be splitted (Pandas dataframe)\n",
        "    ratio: the proportion in (0, 1) of unique conclusions to be inserted in \n",
        "           the training dataframe.\n",
        "  Returns:\n",
        "    train_set_to_return: the portion of train that contains ratio unique\n",
        "                         conclusions.\n",
        "    val_set_to_return: the proportion of the train that contains 1 - ratio\n",
        "                       unique conclusions (the remaining ones)\n",
        "  \"\"\"\n",
        "  val = []\n",
        "  unique_conc = pd.unique(train[\"Conclusion\"])\n",
        "  num_train_con = int(len(unique_conc)*ratio)\n",
        "  train_unique_conc = np.random.choice(unique_conc, num_train_con, replace = False)\n",
        "  val_unique_conc = set(unique_conc) - set(train_unique_conc)\n",
        "  train_set_to_return = train[train.Conclusion.isin(train_unique_conc)] \n",
        "  val_set_to_return = train[train.Conclusion.isin(val_unique_conc)]\n",
        "  return train_set_to_return, val_set_to_return"
      ],
      "metadata": {
        "id": "swL5m3C4x7wV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loading and splitting\n",
        "raw_training = pd.read_csv(\"arguments-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_training_lab = pd.read_csv(\"labels-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test = pd.read_csv(\"arguments-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_lab = pd.read_csv(\"labels-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn=pd.read_csv(\"arguments-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn_lab=pd.read_csv(\"labels-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "\n",
        "train = raw_training.join(raw_training_lab,how='inner' ,lsuffix='2') # joining labels\n",
        "test = raw_test.join(raw_test_lab, how='inner', lsuffix='2') # joining labels\n",
        "test_chn = raw_test_chn.join(raw_test_chn_lab, how='inner', lsuffix='2') # joining labels\n",
        "fix_random(seed)\n",
        "train, val = train_test_split_wrt_conclusions(train) # splitting training\n",
        "\n",
        "train_ds, label_list = huggingface_from_pandas(train)\n",
        "val_ds, _ = huggingface_from_pandas(val)\n",
        "test_ds, _ = huggingface_from_pandas(test)\n",
        "test_chn_ds, _ = huggingface_from_pandas(test_chn) \n",
        "\n",
        "print(\"Single example from the training dataset: \")\n",
        "print(train_ds[0])\n",
        "print(\"Full list of target labels: \")\n",
        "print(label_list)\n",
        "num_classes = len(label_list)\n",
        "print(\"Total number of target labels: \")\n",
        "print(num_classes)\n",
        "whole_dataset = DatasetDict()\n",
        "whole_dataset[\"train\"] = train_ds.with_format(\"torch\")\n",
        "whole_dataset[\"val\"] = val_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test\"] = test_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test_chn\"] = test_chn_ds.with_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "2222e6ffb3a14e09bb2cff351fdb721d",
            "f59dd00cfa8e446bbf5a220b6d3e49b6",
            "74a88c1ca8644a12a70f106d2680a4c8",
            "992f97febc9f4392aeeef20a271bfb2a",
            "132a1d280a6c484da148a77b4f810f3d",
            "f71abc470cdc4a4f99b62659f07c36e7",
            "fc5faf65847941f59547f0d4f0bcf498",
            "fe896d3b807744beaa29c52ea593641f",
            "dad8e14257fb4c43bfd4b0ec655afaa4",
            "acfad52be42f4f19a5a2e63f1f64ea05",
            "0d2207458dde46279f0df27d5337d172",
            "75e12e37f59543cc910f3d53ee34ba8d",
            "dcaca6ce81794cbfb5c91f920640a4d1",
            "bcd46877dd6345ac9cfc896ac6cdbe01",
            "08ce17f27ba54031a2ac642a27089d0f",
            "680bf3bddfaf43739d144d41e66487af",
            "bbd0fc44fd5a4a28ab3156b24dab7a7b",
            "64ac68b39f154607ae653194416504cd",
            "277956d0bc7445c488c9b51fa74f4b46",
            "500dbedbddf14321aeef1f31752364ad",
            "e79c1e31a0f143b69811e019bdb6509f",
            "47f03008e7734bfb9e9de38605535850",
            "2e0be0ac870b44659ae4850b037edc35",
            "52a36fe4834d4eabb26a886c74fe90dd",
            "5abd3e560f8048a6ac42a357b0a81743",
            "8772de9ebcb14fd7843fcf0ea16d7aa8",
            "baf8e434341a4109bdd1339810fed772",
            "f5f55d60cf0d4f1f9b6b94dd0c635838",
            "526eacacb8dd4d8f87b40e2cc223f9dc",
            "86446c5e428d47c281d743f7610273a5",
            "254e6454588e48289a4af3ec4ee0a2d5",
            "69e8f34b7bf344efb4471fef01c6067a",
            "5204b40c9e7a492a9aff98392ae5f93c",
            "931006f7ac8d40e8b3dd68733fc45ffb",
            "d33cce604f06433eb2b3b2fcbd5ed78e",
            "6cfd3513e8a146898412edc202f00356",
            "a0d9f30baba149648db795d50733b072",
            "06b075807aa54d5c876e90bc9220a0c5",
            "4d61edb6766f4ef1ac7f2c7ad12446cd",
            "c13bf5dbcb144edfb143d4ed1e4ea56b",
            "3d986c432ded4780b7af1409151b611c",
            "dc502712038a4b6ea10d62238353f992",
            "e8867c3ff9f243f0b6fcbcf05dfdece0",
            "22fbfc6b997c4bc1b112892056e08204"
          ]
        },
        "id": "FU98Kgv5Q3PO",
        "outputId": "c2ea16a8-c52a-47ba-d0d3-0e1e9a053d34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4176 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2222e6ffb3a14e09bb2cff351fdb721d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1217 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75e12e37f59543cc910f3d53ee34ba8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1896 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e0be0ac870b44659ae4850b037edc35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "931006f7ac8d40e8b3dd68733fc45ffb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single example from the training dataset: \n",
            "{'Conclusion': 'We should ban human cloning', 'Stance': 'in favor of', 'Premise': 'we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.', 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "Full list of target labels: \n",
            "['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']\n",
            "Total number of target labels: \n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, loader):\n",
        "  \"\"\"\n",
        "  Function needed to obtain the prediction for the target labels\n",
        "  given a model and a data loader.\n",
        "\n",
        "  Params:\n",
        "    model: the model that will be used to obtain the predictions over\n",
        "           the labels\n",
        "    loader: the data loader needed to feed the model with the data for which\n",
        "            we want to obtain label predictions\n",
        "  Returns:\n",
        "    Y_preds: tensor containing the predicted label for each example.\n",
        "             These labels are obtained as the output of the model passed to\n",
        "             a sigmoid function.\n",
        "  \"\"\"\n",
        "  Y_preds = []\n",
        "  model.eval()\n",
        "  for X, Y in loader:\n",
        "    with torch.no_grad():\n",
        "      preds = model(X)\n",
        "    Y_preds.append(preds)\n",
        "  gc.collect()\n",
        "  Y_preds = torch.cat(Y_preds)\n",
        "  Y_preds = Y_preds.sigmoid()\n",
        "  return Y_preds.detach()\n",
        "\n",
        "def keep_above_thresh(Y_preds, thr):\n",
        "  \"\"\"\n",
        "  Function needed to convert the results of the models to hard labels\n",
        "  using a threshold.\n",
        "  \n",
        "  Params:\n",
        "    Y_preds: scores obtained by the model which have to be converted to hard\n",
        "             labels\n",
        "    thr: threshold to be applied to the scores, element of (0, 1), if a score\n",
        "         is greater than thr it becomes a hard label with value 1, \n",
        "         0 otherwise\n",
        "  Retuns:\n",
        "    Y_preds_thr: hard labels obtained by thresholding Y_preds with thr\n",
        "  \"\"\"\n",
        "  Y_preds_thr = np.copy(Y_preds.numpy())\n",
        "  max_rows = Y_preds_thr.shape[0]\n",
        "  max_cols = Y_preds_thr.shape[1]\n",
        "  for i in range(max_rows):\n",
        "    new_row = np.array([1 if Y_preds_thr[i][j] > thr else 0 for j in range(max_cols)])\n",
        "    Y_preds_thr[i] = new_row\n",
        "  return Y_preds_thr\n",
        "\n",
        "def compute_macro_score(M_true, M_pred, score_func):\n",
        "  \"\"\"\n",
        "  Function needed to compute the macro aggregation of a scored function\n",
        "  over the different classes.\n",
        "\n",
        "  Params:\n",
        "    M_true: true labels needed to compute the scores\n",
        "    M_pred: predicted labels needed to compute the scores\n",
        "    score_func: scoring function to be computed\n",
        "  Returns:\n",
        "    macro: aggregation of the result of score_func computed over all the\n",
        "           labels.\n",
        "    scores: list of per-label score\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for i in range(M_true.shape[1]):\n",
        "      true = M_true[:, i]\n",
        "      pred = M_pred[:, i]\n",
        "      if score_func == accuracy_score:\n",
        "        scores.append(score_func(true, pred))\n",
        "      else: \n",
        "        scores.append(score_func(true, pred, zero_division=0))\n",
        "  macro = np.mean(scores)\n",
        "  return macro, scores\n",
        "  \n",
        "def support(true, pred, zero_division):\n",
        "  \"\"\"\n",
        "  Utility function to compute the support of the class labels,\n",
        "  pred and zero_division are dummy parameters needed to have conformity\n",
        "  with the sklearn functions to compute scores.\n",
        "\n",
        "  Params: \n",
        "    true: binary true labels for a single class for each example that are needed\n",
        "          to compute the support for the single class\n",
        "    pred: dummy parameter\n",
        "    zero_division: dummy parameter\n",
        "  Returns:\n",
        "    sum(true): the number of example for a single class (support)\n",
        "  \"\"\"\n",
        "  return sum(true)\n",
        "\n",
        "def print_report(classifier, loader, y_true, threshold, labels=label_list):\n",
        "  \"\"\"\n",
        "  Function needed to print the classification results given a classifier,\n",
        "  a dataset loader, true labels and a threshold. \n",
        "  The printed report includes macro accuracy, precision, recall and F1, as \n",
        "  well as per-class accuracy, precision, recall, F1 and support.\n",
        "\n",
        "  Params:\n",
        "    classifier: the model that has to be evaluated\n",
        "    loader: data-loader needed to feed the data to the classifier to get \n",
        "            predicted labels\n",
        "    y_true: true labels associated to the dataset associated to the loader\n",
        "    threshold: threshold for the conversion of the scores to hard labels,\n",
        "               check keep_above_thresh for further details\n",
        "    labels: ordered list of target labels. Defaults to the list extracted from\n",
        "            the dataset\n",
        "  \"\"\"\n",
        "\n",
        "  Y_preds = make_predictions(classifier, loader)\n",
        "  Y_preds_thr = keep_above_thresh(Y_preds.to('cpu'), threshold)\n",
        "\n",
        "  f1_macro, f1 = compute_macro_score(y_true, Y_preds_thr, f1_score)\n",
        "  acc_macro, acc = compute_macro_score(y_true, Y_preds_thr, accuracy_score)\n",
        "  prec_macro, prec = compute_macro_score(y_true, Y_preds_thr, precision_score)\n",
        "  rec_macro, rec = compute_macro_score(y_true, Y_preds_thr, recall_score)\n",
        "  _, sup = compute_macro_score(y_true, Y_preds_thr, support)\n",
        "\n",
        "  print(\"----- MACRO AVG. -----\")\n",
        "  print(f\"  F1-score:\\t{round(f1_macro,4)}\\n\\\n",
        "  Precision:\\t{round(prec_macro,4)}\\n\\\n",
        "  Recall:\\t{round(rec_macro,4)}\\n\\\n",
        "  Accuracy:\\t{round(acc_macro,4)}\")\n",
        "  print(\"----- PER-CLASS VALUES -----\")\n",
        "  print(\"  \\t\\t\\t\\tF1-score\\tPrecision\\tRecall\\t\\tAccuracy\\tSupport\")\n",
        "  for i in range(len(labels)):\n",
        "    print(\"  \" + labels[i]+\" \"*(len(max(labels, key=len))-len(labels[i])), end=\"\\t\")\n",
        "    print(f\"{round(f1[i],4)}\\t\\t{round(prec[i],4)}\\t\\t{round(rec[i],4)}\\t\\t{round(acc[i],4)}\\t\\t{sup[i]}\")"
      ],
      "metadata": {
        "id": "uU_qeLA6l7OE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe model\n",
        "The first model that was developed is a GloVe 100d embedding + two Bi-GRU layers\n",
        "That serves as an advanced baseline to perfom experiments for multi-label classification problems like the current one. \n",
        "It is still a baseline since it has a simple architecture, OOV are treated using zero-vectors, the hidden states of the Bi-GRU layers are initialized \n",
        "as zero-vectors and most importantly the model does not work with contextual information, but only with the semantics of the words. <br>\n",
        "Moreover an heavy preprocessing to the dataset is not applied except for lowercasing the arguments, tokenization and the addition of truncation and padding because the GloVe embeddings would return too many unmasked zero vectors. <br>\n",
        "About padding and truncation: the maximum allowed length is 35 which is \n",
        "slightly above the sum of the mean token length value for the premises and the\n",
        "conclusion. \n",
        "\n",
        "N.B.: the last dense layer has no activation for all the models, since the loss\n",
        "function applies it by guaranteeing numerical stability. Thus the output of the\n",
        "layer must be passed to a sigmoid function before converting it to labels."
      ],
      "metadata": {
        "id": "LosoIWWz_5e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained GloVe setup\n",
        "\n",
        "global_vectors = GloVe(name='6B', dim=100)\n",
        "\n",
        "# the current choice is to give an id to each word\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "TOU9N3-WJgn3",
        "outputId": "bdf9baeb-ee2d-4edd-9212-e482dbdd9b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.36MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:17<00:00, 22567.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# these parameters are used both by the following function and by the \n",
        "# implementation of the GloVe model itself, thus are kept global\n",
        "max_words_emb = 35\n",
        "embed_len = 100\n",
        "\n",
        "# collate function where the Premises are tokenized and embedded in batches\n",
        "def vectorize_batch(batch):\n",
        "  \"\"\"\n",
        "  Collate function to preprocess the data for the GloVe model.\n",
        "  In particular it joins premises, stances and conclusions in the same string,\n",
        "  tokenizes, truncates and pads them and then converts each token to a GloVe\n",
        "  vector. Target labels are already one-hot encoded.\n",
        "\n",
        "  Params:\n",
        "    batch: batch of data to be preprocessed\n",
        "  Returns:\n",
        "    X_tensor: a tensor containing GloVe vectors of dimension 100, which has shape\n",
        "              (batch_size, max_words_emb, embed_len)\n",
        "    Y_tensor: a tensor containing labels, which has shape\n",
        "              (batch_size, num_classes)\n",
        "  \"\"\"\n",
        "  X = [elem[\"Premise\"] + \" \" + elem[\"Stance\"] + \" \" +elem[\"Conclusion\"] for elem in batch]\n",
        "  Y = [elem[\"labels\"] for elem in batch]\n",
        "  X = [tokenizer(x) for x in X]\n",
        "  X = [tokens+[\"\"] * (max_words_emb-len(tokens))  if len(tokens)<max_words_emb else tokens[:max_words_emb] for tokens in X]\n",
        "  X_tensor = torch.zeros(len(batch), max_words_emb, embed_len)\n",
        "  Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "  for i, tokens in enumerate(X):\n",
        "      X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
        "      Y_tensor[i] = Y[i]\n",
        "  return X_tensor, Y_tensor"
      ],
      "metadata": {
        "id": "0eFmzKrDbvlJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class EmbeddingClassifier(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the GloVe model.\n",
        "  Remark: max_words_emb, embed_len and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      super(EmbeddingClassifier, self).__init__() \n",
        "      \n",
        "      self.gru_layers = 2\n",
        "\n",
        "      self.gru = nn.GRU(input_size = embed_len,\n",
        "                        hidden_size = embed_len,\n",
        "                        num_layers = self.gru_layers,\n",
        "                        batch_first=True, \n",
        "                        bidirectional = True)\n",
        "      self.flatten = nn.Flatten(start_dim=1)\n",
        "      self.linear_1 = nn.Linear(max_words_emb*embed_len*2, 512)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.linear_2 = nn.Linear(512,128)\n",
        "      self.linear_3 = nn.Linear(128, num_classes)\n",
        "      \n",
        "              \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    \"\"\"\n",
        "    It is important to note that the initial hidden states of the GRU\n",
        "    layers are initialized with zero tensors.\n",
        "\n",
        "    The outcomes of the GRU layers are flattened and classified. \n",
        "    \"\"\"\n",
        "    h0 = torch.zeros(2*self.gru_layers,X_batch.shape[0], embed_len)\n",
        "    h0 = h0.to(device)\n",
        "    out, hn = self.gru(X_batch, h0)\n",
        "    out = self.flatten(out)\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_3(out)\n",
        "    return out\n",
        "\n",
        "# Function needed to compute the validation loss and the accuracy\n",
        "def compute_validation_loss(model, loss_fn, val_loader):\n",
        "  \"\"\"\n",
        "  Function computing and printing the loss on the validation set.\n",
        "  Params:\n",
        "    model: the model for which the loss must be computed and printed\n",
        "    loss_fn: the loss function to adopt\n",
        "    val_loader: dataloader for the validation set\n",
        "\n",
        "  Returns:\n",
        "    loss: the computed mean loss across the batch\n",
        "  \"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    losses = []\n",
        "    for X, Y in val_loader:\n",
        "      preds = model(X)\n",
        "      loss = loss_fn(preds, Y)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "    loss = torch.tensor(losses).mean()\n",
        "    print(\"Valid Loss : {:.3f}\".format(loss))\n",
        "  return loss\n",
        "\n",
        "\n",
        "# Training function\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name):\n",
        "  \"\"\"\n",
        "  Function for model training. If early stopping info is defined it saves the \n",
        "  last best models and eventually returns it, in case of early stopping.\n",
        "  In case early_stopping_info is not defined, the early stopping is not\n",
        "  applied.\n",
        "\n",
        "  Params:\n",
        "    model: the model that has to be trained\n",
        "    loss_fn: the loss function to adopt in order to perform the training\n",
        "    optimizer: the optimizer to be used for training\n",
        "    train_loader: the dataloader for the training dataset\n",
        "    val_loader: the dataloader for the validation dataset\n",
        "    epochs: the number of epochs for training\n",
        "    early_stopping_info: dictionary containing the parameters for the early stopping:\n",
        "                          - delta: min acceptable improvement in the validation loss\n",
        "                          - patience: number of epochs to wait for improvement\n",
        "    model_name: string containing the name of the model (used in order to save\n",
        "                the weights)\n",
        "  Returns:\n",
        "    model: the trained model\n",
        "  \"\"\"\n",
        "  patience_acc = 0\n",
        "  precedent_loss = np.Inf\n",
        "  model.train()\n",
        "  for i in range(1, epochs+1):\n",
        "      losses = []\n",
        "      for X, Y in tqdm(train_loader):\n",
        "\n",
        "          Y_preds = model(X)\n",
        "\n",
        "          loss = loss_fn(Y_preds, Y)\n",
        "          losses.append(loss.item())\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      loss = compute_validation_loss(model, loss_fn, val_loader)\n",
        "      print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "      if early_stopping_info != None:\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "            patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          precedent_loss = loss  \n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc >= early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"_best.pth\")           \n",
        "  return model\n"
      ],
      "metadata": {
        "id": "XHy7Zl7EK-FA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training informations\n",
        "The training was performed considering a maximum of 50 epochs with the following parameters for early stopping: patience equal to 3 epochs and delta equal to 1e-4. Batch size, learning rate and number of parameters for the layers were tuned by hand considering the results on the validation set.\n",
        "In particular the following pools were considered:\n",
        "- batch_size in \\{16, 32, 64\\}\n",
        "- learning rate in \\{1e-2, 1e-3, 1e-4\\}\n",
        "- hidden size of the GRU layers in \\{100, 200\\}\n",
        "- neurons of the linear layers in \\{512, 256, 128\\}"
      ],
      "metadata": {
        "id": "ZOyMHpzEK0mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 1e-4\n",
        "batch_size = 32\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "embed_classifier = EmbeddingClassifier()\n",
        "optimizer = Adam(embed_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Construction of the Dataloaders for train and validation\n",
        "train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "\n",
        "\n",
        "embed_classifier.to(device)\n",
        "summary(embed_classifier, \n",
        "                input_data=next(iter(train_loader))[0],\n",
        "                device=device)\n"
      ],
      "metadata": {
        "id": "k4KSPSXAN6z0",
        "outputId": "ef67b599-8922-4849-e01d-34968f0aeff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "EmbeddingClassifier                      [32, 20]                  --\n",
              "├─GRU: 1-1                               [32, 35, 200]             302,400\n",
              "├─Flatten: 1-2                           [32, 7000]                --\n",
              "├─Linear: 1-3                            [32, 512]                 3,584,512\n",
              "├─ReLU: 1-4                              [32, 512]                 --\n",
              "├─Linear: 1-5                            [32, 128]                 65,664\n",
              "├─ReLU: 1-6                              [32, 128]                 --\n",
              "├─Linear: 1-7                            [32, 20]                  2,580\n",
              "==========================================================================================\n",
              "Total params: 3,955,156\n",
              "Trainable params: 3,955,156\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 455.58\n",
              "==========================================================================================\n",
              "Input size (MB): 0.45\n",
              "Forward/backward pass size (MB): 1.96\n",
              "Params size (MB): 15.82\n",
              "Estimated Total Size (MB): 18.23\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "embed_classifier = TrainModel(embed_classifier, loss_fn, optimizer, train_loader, val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"glove\")"
      ],
      "metadata": {
        "id": "Ws7o13y5P5o4",
        "outputId": "933e052f-b5cf-4222-96ab-472665078ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 33.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.410\n",
            "Train Loss : 0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.406\n",
            "Train Loss : 0.416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 40.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.397\n",
            "Train Loss : 0.403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.390\n",
            "Train Loss : 0.388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 38.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.383\n",
            "Train Loss : 0.377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.377\n",
            "Train Loss : 0.370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.372\n",
            "Train Loss : 0.364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.370\n",
            "Train Loss : 0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 37.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.367\n",
            "Train Loss : 0.353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.366\n",
            "Train Loss : 0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 55.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.366\n",
            "Train Loss : 0.343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.365\n",
            "Train Loss : 0.338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 36.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.365\n",
            "Train Loss : 0.334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.366\n",
            "Train Loss : 0.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.368\n",
            "Train Loss : 0.323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GloVe BASELINE:\")\n",
        "print_report(embed_classifier, val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "NsdbFRv1yrmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302cdedd-28cc-4876-c755-408e033da34b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe BASELINE:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3092\n",
            "  Precision:\t0.3175\n",
            "  Recall:\t0.3847\n",
            "  Accuracy:\t0.789\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.2986\t\t0.2374\t\t0.4024\t\t0.8726\t\t82\n",
            "  Self-direction: action    \t0.4658\t\t0.379\t\t0.6041\t\t0.6664\t\t293\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.9647\t\t43\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.9737\t\t32\n",
            "  Achievement               \t0.5928\t\t0.5409\t\t0.6556\t\t0.7313\t\t363\n",
            "  Power: dominance          \t0.2525\t\t0.3521\t\t0.1969\t\t0.8784\t\t127\n",
            "  Power: resources          \t0.5103\t\t0.7025\t\t0.4007\t\t0.825\t\t277\n",
            "  Face                      \t0.0213\t\t0.2\t\t0.0112\t\t0.9244\t\t89\n",
            "  Security: personal        \t0.6223\t\t0.4754\t\t0.9008\t\t0.5472\t\t504\n",
            "  Security: societal        \t0.679\t\t0.6084\t\t0.7682\t\t0.7297\t\t453\n",
            "  Tradition                 \t0.2537\t\t0.2203\t\t0.2989\t\t0.8743\t\t87\n",
            "  Conformity: rules         \t0.4503\t\t0.3239\t\t0.7384\t\t0.5867\t\t279\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.954\t\t56\n",
            "  Humility                  \t0.0674\t\t0.4286\t\t0.0366\t\t0.9318\t\t82\n",
            "  Benevolence: caring       \t0.3102\t\t0.2815\t\t0.3454\t\t0.6163\t\t304\n",
            "  Benevolence: dependability\t0.0917\t\t0.1528\t\t0.0655\t\t0.8209\t\t168\n",
            "  Universalism: concern     \t0.5935\t\t0.4883\t\t0.7565\t\t0.5768\t\t497\n",
            "  Universalism: nature      \t0.5053\t\t0.4138\t\t0.6486\t\t0.9228\t\t74\n",
            "  Universalism: tolerance   \t0.2222\t\t0.3953\t\t0.1545\t\t0.9022\t\t110\n",
            "  Universalism: objectivity \t0.2461\t\t0.1488\t\t0.7103\t\t0.4815\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT + LSTM model (transfer learning)\n",
        "The following model is proposed to enhance the GloVe model through the following changes:\n",
        "- Usage of contextual frozen Bert encoding instead of GloVe embeddings\n",
        "(changes were performed in the collate)\n",
        "- Substitution of the GRU layers with LSTM layers, which are more complex. \n",
        "- Meaningful initialization of the LSTM hidden and cell states using\n",
        "the pooler-output of the BERT encoding of an argument passed to two different dense layers (ideally the pooler-output represents the encoding of the \\[CLS\\] token which is at the beginning of every argument and contains general informations about semantics of the whole sentence).\n",
        "- Classification focussed on the concatenation of the output cell states of the LSTM layers, rather than the encoding of the whole sentence (concatenation of the hidden states).\n",
        "This reduces the number of required neurons and elaborates a tensor that retains the most important semantic informations on the sentence."
      ],
      "metadata": {
        "id": "H7VPAGgCNE7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection of the BERT model\n",
        "For this task we used the bert-based-uncased model and tokenizer. \n",
        "We also decided to try different variations of BERT (ELECTRA, ALBERT, Funnel Transformer, ...), but we didn't obtain remarkable improvements."
      ],
      "metadata": {
        "id": "wVQlUUX3PSaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import of the BERT tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model.to(device)\n",
        "print(\"Bert loaded\")"
      ],
      "metadata": {
        "id": "tt17dYqothM3",
        "outputId": "b2b47a1a-0250-4c52-9e99-7c36d85c8c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "35e43302874f45388ad5320f6867ca7f",
            "c207a527cdbd445e8c051d94cd4035fb",
            "b865316022d6439bbacc94e435f09186",
            "b0c2cb96837e43f7a128cad4be0ccb24",
            "6b041d8d8fce4d72850303f3dded58ee",
            "c87b578adb5843f5ae195ef9a35ebc7d",
            "806f1497caf04d52b9246871c7ac814c",
            "a195a91b97c04eb891dea5c54ce10154",
            "f8212945919d49788213c9b927292222",
            "0b7dd1f201a04d49a9229002be0ba903",
            "6fc7ca8891de4706905a4496e1ea08ec",
            "6d790bef888c45bcaba7fc412feec7eb",
            "8d01edc801f149edabc6adcff5ad5915",
            "024e0fde8f6e47ec9a5865fe2e68e284",
            "1c9092e6aace4609a0fcce0cce5e3ba9",
            "f9a4a0ea610b472d8a730bbf8b4e0670",
            "2113ebe0c4214bd89e3a2813149003bd",
            "63dd1d001d9f4ab4833fc8da8fcddb31",
            "1006a3fca90543d3a8598ee5d8f33c8c",
            "6db00617370d46dcb891f902ce4d6289",
            "5558d2755d194eb7aa6d000710b98c57",
            "9ccec07865f348168273307e4877ca94",
            "8143d64533b84ebaac12523c428af741",
            "2f1483b541cb49b1a97e7eb62d0611a4",
            "0ddf4ae9364247aab61e0bb53e2b5b1d",
            "2cfa47170e2b4943851e024812912717",
            "07f2a689d0064a079900a4090ca8e8f0",
            "4644341faf9a47ef98e226cfe32e1732",
            "3a9b58d2e90243bda813374fb788083c",
            "0343f4a183ca4f7f9fb51defc6d80a73",
            "492094176a1144ada704aaf8a50e1c53",
            "79539f3533814475b539b2609b4d044a",
            "002bdcc7899f4017ba7c45b91e344e47",
            "2973e3fcbfc84d8d95d67ec870d78154",
            "97d4458980734d64b1c3497c894de259",
            "ceb0b7dadd3547a2893eafc2ff67c845",
            "454ce92d492d45278f30103dfdc3cde9",
            "08769365a26b42b8bcfd228693932e89",
            "7e7722128d454dc6b4d3dfcf9d377ac5",
            "9f6cd46ced964561ba5fec19b244b009",
            "144558dc00304744bccdb603c3d6697d",
            "af6e42a16528413cb6357aa52d8d4ab5",
            "68e99378184940c2b808e0d20f6ca4b8",
            "4f8c3e5064c942719deb95425e2d3566"
          ]
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35e43302874f45388ad5320f6867ca7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d790bef888c45bcaba7fc412feec7eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8143d64533b84ebaac12523c428af741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2973e3fcbfc84d8d95d67ec870d78154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bert loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice for the maximum length of the BERT encodings is 70 because\n",
        "it is slightly above the sum of the 90-th percentile of the lengths of premises, stances and conclusions.\n",
        "It is longer with respect to the maximum number of words for the GloVe model,\n",
        "since BERT-encoded vectors are much more dense."
      ],
      "metadata": {
        "id": "R8L68FX3Q8MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words_bert = 70\n",
        "# collate function that uses the tokenizer relative to the bert pretrained model\n",
        "def bert_vectorize_batch(batch):\n",
        "  \"\"\"\n",
        "  Collate function to preprocess the data for the BERT-based models.\n",
        "  In particular it joins premises, stances and conclusions in the same string,\n",
        "  separated by the [SEP] token.\n",
        "  Using the appropriate tokenizer, arguments are tokenized, truncated and padded.\n",
        "  Target labels are already one-hot encoded.\n",
        "\n",
        "  Params:\n",
        "    batch: batch of data to be preprocessed\n",
        "  Returns:\n",
        "    X_tensor: a tensor containing a torch tensor containing the input_ids, the token_type_ids and the\n",
        "              attention_mask for each example of the batch, which has shape:\n",
        "              (3, batch_size, max_words_bert)\n",
        "    Y_tensor: a tensor containing labels, which has shape\n",
        "              (batch_size, num_classes)\n",
        "  \"\"\"\n",
        "  X = [elem[\"Premise\"] + \" [SEP] \" + elem[\"Stance\"] + \" [SEP] \" + elem[\"Conclusion\"] for elem in batch]\n",
        "  Y = [elem[\"labels\"] for elem in batch]\n",
        "  X = bert_tokenizer(X, padding=\"max_length\", truncation=\"longest_first\", return_tensors = \"pt\", max_length = max_words_bert) \n",
        "  Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "  for i, tokens in enumerate(Y):    \n",
        "      Y_tensor[i] = Y[i]\n",
        "  X_tensor = torch.stack([X[\"input_ids\"], X[\"token_type_ids\"], X[\"attention_mask\"]])\n",
        "\n",
        "  return X_tensor, Y_tensor\n",
        "\n",
        "train_dataset = whole_dataset[\"train\"]\n",
        "val_dataset = whole_dataset[\"val\"] \n",
        "test_dataset = whole_dataset[\"test\"] "
      ],
      "metadata": {
        "id": "gCwN1D6evfAF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class BertLSTM(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the BERT + LSTM model.\n",
        "  Remark: max_words_bert and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self, bert_model):\n",
        "    # the single parameter of this init function is the bert model \n",
        "    # that has to be used for transfer learning\n",
        "    super(BertLSTM, self).__init__() \n",
        "    self.lstm_layers = 2\n",
        "    self.lstm_hs = 128 # hidden size of the lstm\n",
        "    bert_hidden_size = bert_model.config.hidden_size\n",
        "\n",
        "    # freezing the parameters for the BERT model\n",
        "    self.bert_model = bert_model\n",
        "    for param in self.bert_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=bert_hidden_size,\n",
        "                        hidden_size=self.lstm_hs,\n",
        "                        num_layers=self.lstm_layers ,\n",
        "                        batch_first=True,\n",
        "                        bidirectional=True)\n",
        "    self.reducer_c0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "    self.reducer_h0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "    self.linear_1 = nn.Linear(self.lstm_hs*2*self.lstm_layers, self.lstm_hs)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(self.lstm_hs, num_classes) # since the dimensions\n",
        "    # are already small there is no need for a third linear layer\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    #Remark: The LSTM layer does not contain the encoding of the [CLS] token\n",
        "    #since it is used to initialize the hidden and cell states.\n",
        "    out = self.bert_model(input_ids=X_batch[0], token_type_ids = X_batch[1], attention_mask = X_batch[2])\n",
        "    cell = self.reducer_c0(out.pooler_output)\n",
        "    hidden = self.reducer_h0(out.pooler_output)\n",
        "    out = out.last_hidden_state[:,1:,:]\n",
        "    c0 = torch.stack([cell,cell,cell,cell]) \n",
        "    h0 = torch.stack([hidden, hidden, hidden, hidden])\n",
        "    out_lstm, hc_n  = self.lstm(out, (h0, c0))\n",
        "    c_n = hc_n[1].permute(1, 0, 2) # permutation in order to obtain the batch \n",
        "                                   # size dimension first\n",
        "    out = torch.cat([c_n[:,0,:], c_n[:,1,:]], 1) # concatenation of the cell states\n",
        "    out2 = torch.cat([c_n[:,2,:], c_n[:,3,:]], 1)\n",
        "    out = torch.cat([out, out2], 1)\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "oEb_5p623uWU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training informations\n",
        "The training was performed considering a maximum of 50 epochs with the following parameters for early stopping: patience equal to 3 epochs and delta equal to 1e-4. Batch size, learning rate and number of parameters for the layers were tuned by hand considering the results on the validation set.\n",
        "In particular the following pools were considered:\n",
        "- batch_size in \\{16, 32, 64\\}\n",
        "- learning rate in \\{1e-2, 1e-3, 1e-4\\}\n",
        "- hidden size of the LSTM layers in \\{128, 256, 512\\}\n",
        "- neurons of the linear layers in \\{256, 128\\}"
      ],
      "metadata": {
        "id": "W4rjn0z2TTTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "prebert_classifier = BertLSTM(bert_model)\n",
        "optimizer = Adam(prebert_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "bert_train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "prebert_classifier.to(device)\n",
        "summary(prebert_classifier, \n",
        "                input_data=next(iter(bert_train_loader))[0],\n",
        "                device=device)"
      ],
      "metadata": {
        "id": "1sU40iio3-4l",
        "outputId": "d81dbf99-f7dd-49fb-dee1-509f6e2478ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "BertLSTM                                                [32, 20]                  --\n",
              "├─BertModel: 1-1                                        [32, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [32, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [32, 70, 768]             (23,440,896)\n",
              "│    │    └─Embedding: 3-2                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              (393,216)\n",
              "│    │    └─LayerNorm: 3-4                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Dropout: 3-5                                [32, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [32, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        (85,054,464)\n",
              "│    └─BertPooler: 2-3                                  [32, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [32, 768]                 (590,592)\n",
              "│    │    └─Tanh: 3-8                                   [32, 768]                 --\n",
              "├─Linear: 1-2                                           [32, 128]                 98,432\n",
              "├─Linear: 1-3                                           [32, 128]                 98,432\n",
              "├─LSTM: 1-4                                             [32, 69, 256]             1,314,816\n",
              "├─Linear: 1-5                                           [32, 128]                 65,664\n",
              "├─ReLU: 1-6                                             [32, 128]                 --\n",
              "├─Linear: 1-7                                           [32, 20]                  2,580\n",
              "=========================================================================================================\n",
              "Total params: 111,062,164\n",
              "Trainable params: 1,579,924\n",
              "Non-trainable params: 109,482,240\n",
              "Total mult-adds (G): 6.40\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 1863.20\n",
              "Params size (MB): 444.25\n",
              "Estimated Total Size (MB): 2307.50\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "prebert_classifier = TrainModel(prebert_classifier, loss_fn, optimizer, bert_train_loader, bert_val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"bertencoder\")"
      ],
      "metadata": {
        "id": "qr86sx6J4cJY",
        "outputId": "7749385a-e0b4-4a26-9e7f-abd3b9693906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:21<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.381\n",
            "Train Loss : 0.396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:21<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.372\n",
            "Train Loss : 0.343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:23<00:00,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.368\n",
            "Train Loss : 0.324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:22<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.366\n",
            "Train Loss : 0.309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:22<00:00,  5.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.367\n",
            "Train Loss : 0.294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:22<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.377\n",
            "Train Loss : 0.280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:21<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.391\n",
            "Train Loss : 0.266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT+LSTM:\")\n",
        "print_report(prebert_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "n_wI6jIOW4xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97d2ea2-7374-4744-dbcc-98899fbb45d1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT+LSTM:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3546\n",
            "  Precision:\t0.3797\n",
            "  Recall:\t0.4145\n",
            "  Accuracy:\t0.8014\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3012\t\t0.2976\t\t0.3049\t\t0.9047\t\t82\n",
            "  Self-direction: action    \t0.4711\t\t0.3833\t\t0.6109\t\t0.6697\t\t293\n",
            "  Stimulation               \t0.0952\t\t0.15\t\t0.0698\t\t0.9532\t\t43\n",
            "  Hedonism                  \t0.2609\t\t0.4286\t\t0.1875\t\t0.9721\t\t32\n",
            "  Achievement               \t0.6343\t\t0.5469\t\t0.7548\t\t0.7403\t\t363\n",
            "  Power: dominance          \t0.1625\t\t0.3939\t\t0.1024\t\t0.8899\t\t127\n",
            "  Power: resources          \t0.4206\t\t0.596\t\t0.3249\t\t0.7962\t\t277\n",
            "  Face                      \t0.1639\t\t0.303\t\t0.1124\t\t0.9162\t\t89\n",
            "  Security: personal        \t0.6879\t\t0.6218\t\t0.7698\t\t0.7108\t\t504\n",
            "  Security: societal        \t0.6891\t\t0.6593\t\t0.7219\t\t0.7576\t\t453\n",
            "  Tradition                 \t0.2125\t\t0.2329\t\t0.1954\t\t0.8965\t\t87\n",
            "  Conformity: rules         \t0.4882\t\t0.3425\t\t0.8495\t\t0.5916\t\t279\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.954\t\t56\n",
            "  Humility                  \t0.18\t\t0.5\t\t0.1098\t\t0.9326\t\t82\n",
            "  Benevolence: caring       \t0.3333\t\t0.3451\t\t0.3224\t\t0.6779\t\t304\n",
            "  Benevolence: dependability\t0.2601\t\t0.1664\t\t0.5952\t\t0.5325\t\t168\n",
            "  Universalism: concern     \t0.6231\t\t0.5809\t\t0.672\t\t0.668\t\t497\n",
            "  Universalism: nature      \t0.3957\t\t0.2696\t\t0.7432\t\t0.862\t\t74\n",
            "  Universalism: tolerance   \t0.4432\t\t0.5909\t\t0.3545\t\t0.9195\t\t110\n",
            "  Universalism: objectivity \t0.2684\t\t0.1849\t\t0.4897\t\t0.682\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT fine tuning\n",
        "The following model is simply a fine tuned version of the BERT model on the reference dataset and it is proposed as an alternative to the previous models.\n",
        "In particular a similar model has been proposed by the authors of the dataset, hence it can be used as a reference point, since the datasets are not exacly equal.\n",
        "\n",
        "The architecture is a simple fine tuning of BERT followed by two linear layers which elaborate its pooler-output and reduce its dimension to num_classes.\n",
        "It is a common architecture that employs BERT in order to perform multi-label text classification."
      ],
      "metadata": {
        "id": "lzk-QUXGT6F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class FineTunedBert(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the model that allows to fine-tune BERT for this task.\n",
        "  Remark: max_words_bert and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self, bert_model):\n",
        "    # the single parameter of this init function is the bert model \n",
        "    # that has to be used for fine-tuning\n",
        "    super(FineTunedBert, self).__init__() \n",
        "    self.bert_model = bert_model\n",
        "    for param in self.bert_model.parameters():\n",
        "        param.requires_grad = True\n",
        "    bert_hidden_size = bert_model.config.hidden_size\n",
        "    self.linear_1 = nn.Linear(bert_hidden_size, bert_hidden_size//2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(bert_hidden_size//2, num_classes)\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    out = self.bert_model(input_ids=X_batch[0], \n",
        "                          token_type_ids = X_batch[1],\n",
        "                          attention_mask = X_batch[2])\n",
        "\n",
        "    out = out.last_hidden_state[:,0,:]\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    return out\n",
        "\n",
        "# Training function\n",
        "def finetune_bert(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name, scheduler):\n",
        "  \"\"\"\n",
        "  Training function for the fine-tuning of BERT. if arly_stopping_info info is set\n",
        "  to None, early stopping is not performed.\n",
        "  Params:\n",
        "    model: the model that has to be fine-tuned\n",
        "    loss_fn: the loss function to adopt in order to perform the training\n",
        "    optimizer: the optimizer to be used for training\n",
        "    train_loader: the dataloader for the training dataset\n",
        "    val_loader: the dataloader for the validation dataset\n",
        "    epochs: the number of epochs for training\n",
        "    early_stopping_info: dictionary containing the parameters for the early stopping:\n",
        "                          - delta: min acceptable improvement in the validation loss\n",
        "                          - patience: number of epochs to wait for improvement\n",
        "    model_name: string containing the name of the model (used in order to save\n",
        "                the weights)\n",
        "    scheduler: the learning rate scheduler to be applied (it is a step scheduler)\n",
        "  Returns:\n",
        "    model: the trained model\n",
        "  \"\"\"\n",
        "  patience_acc = 0\n",
        "  precedent_loss = np.Inf\n",
        "  model.train()\n",
        "  for i in range(1, epochs+1):\n",
        "      losses = []\n",
        "      for X, Y in tqdm(train_loader):\n",
        "          model.zero_grad()\n",
        "          Y_preds = model(X)\n",
        "          loss = loss_fn(Y_preds, Y)\n",
        "          losses.append(loss.item())\n",
        "\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "\n",
        "      loss = compute_validation_loss(model, loss_fn, val_loader)\n",
        "      print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "      if early_stopping_info != None:\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "            patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          precedent_loss = loss\n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc > early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"best.pth\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "L2AFayf470lu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_unfrozen = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model_unfrozen.to(device)\n",
        "print(\"reloaded\")"
      ],
      "metadata": {
        "outputId": "32b49908-1c84-4ee6-b6cf-ff35ecf2420c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLK5mrMjAMAj"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training informations\n",
        "The training recipe and the model were adapted from the following tutorial:<br>\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
        "<br>\n",
        "As suggested in the tutorial the AdamW optimizer was used, the gradients were clipped to 1 and hyperparameters were drawn from the following pools:\n",
        "- batch_size in \\{16, 32\\}\n",
        "- learning rate in {5e-5, 3e-5, 2e-5}\n",
        "- number of epochs in \\{2, 3, 4\\}, but also 5 and 6 were tested. With 6 epochs the validation loss goes a little bit up, but returns better F1 scores.\n",
        "- the number of neurons of the linear layers are obtained by progressively halving the output of the BERT model"
      ],
      "metadata": {
        "id": "FiGEQaXlZgwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 6\n",
        "learning_rate = 5e-5\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "finetune_classifier = FineTunedBert(bert_model_unfrozen)\n",
        "optimizer = AdamW(finetune_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
        "\n",
        "\n",
        "bert_train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(val_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(test_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
        "                                            num_training_steps=len(bert_train_loader)*epochs)\n",
        "\n",
        "finetune_classifier.to(device)\n",
        "summary(finetune_classifier, input_data=next(iter(bert_train_loader))[0], device=device, dtypes = [torch.int]*3)"
      ],
      "metadata": {
        "id": "v1bsrMwW_KYH",
        "outputId": "e186c3e8-bdf3-4817-ad40-45e38bcb2871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "FineTunedBert                                           [16, 20]                  --\n",
              "├─BertModel: 1-1                                        [16, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [16, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [16, 70, 768]             23,440,896\n",
              "│    │    └─Embedding: 3-2                              [16, 70, 768]             1,536\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              393,216\n",
              "│    │    └─LayerNorm: 3-4                              [16, 70, 768]             1,536\n",
              "│    │    └─Dropout: 3-5                                [16, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [16, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        85,054,464\n",
              "│    └─BertPooler: 2-3                                  [16, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [16, 768]                 590,592\n",
              "│    │    └─Tanh: 3-8                                   [16, 768]                 --\n",
              "├─Linear: 1-2                                           [16, 384]                 295,296\n",
              "├─ReLU: 1-3                                             [16, 384]                 --\n",
              "├─Linear: 1-4                                           [16, 20]                  7,700\n",
              "=========================================================================================================\n",
              "Total params: 109,785,236\n",
              "Trainable params: 109,785,236\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.75\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.03\n",
              "Forward/backward pass size (MB): 929.55\n",
              "Params size (MB): 439.14\n",
              "Estimated Total Size (MB): 1368.72\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "finetune_classifier = finetune_bert(finetune_classifier, \n",
        "                                   loss_fn, optimizer,\n",
        "                                   bert_train_loader,\n",
        "                                   bert_val_loader,\n",
        "                                   epochs,\n",
        "                                   None, \n",
        "                                   \"finebert\", scheduler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Bka5d2uStJ",
        "outputId": "42250a88-33b0-492a-aebe-0e06942d9b0c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:14<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.374\n",
            "Train Loss : 0.402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:03<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.352\n",
            "Train Loss : 0.321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:02<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.348\n",
            "Train Loss : 0.273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:05<00:00,  3.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.345\n",
            "Train Loss : 0.234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:03<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.353\n",
            "Train Loss : 0.205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:10<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.347\n",
            "Train Loss : 0.186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINETUNED BERT:\")\n",
        "print_report(finetune_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37348ec9-0766-4622-8525-0886d743c3b6",
        "id": "igiHgAFsvifc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINETUNED BERT:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.4037\n",
            "  Precision:\t0.4748\n",
            "  Recall:\t0.4233\n",
            "  Accuracy:\t0.8403\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3904\t\t0.2899\t\t0.5976\t\t0.8743\t\t82\n",
            "  Self-direction: action    \t0.5417\t\t0.5106\t\t0.5768\t\t0.765\t\t293\n",
            "  Stimulation               \t0.12\t\t0.4286\t\t0.0698\t\t0.9638\t\t43\n",
            "  Hedonism                  \t0.2162\t\t0.8\t\t0.125\t\t0.9762\t\t32\n",
            "  Achievement               \t0.6479\t\t0.5824\t\t0.73\t\t0.7634\t\t363\n",
            "  Power: dominance          \t0.2581\t\t0.3111\t\t0.2205\t\t0.8677\t\t127\n",
            "  Power: resources          \t0.5809\t\t0.5918\t\t0.5704\t\t0.8127\t\t277\n",
            "  Face                      \t0.0638\t\t0.6\t\t0.0337\t\t0.9277\t\t89\n",
            "  Security: personal        \t0.7047\t\t0.6325\t\t0.7956\t\t0.7239\t\t504\n",
            "  Security: societal        \t0.7126\t\t0.6766\t\t0.7528\t\t0.774\t\t453\n",
            "  Tradition                 \t0.3106\t\t0.3378\t\t0.2874\t\t0.9088\t\t87\n",
            "  Conformity: rules         \t0.5219\t\t0.4505\t\t0.6201\t\t0.7395\t\t279\n",
            "  Conformity: interpersonal \t0.0328\t\t0.2\t\t0.0179\t\t0.9515\t\t56\n",
            "  Humility                  \t0.0426\t\t0.1667\t\t0.0244\t\t0.926\t\t82\n",
            "  Benevolence: caring       \t0.4332\t\t0.4063\t\t0.4638\t\t0.6968\t\t304\n",
            "  Benevolence: dependability\t0.2871\t\t0.2374\t\t0.3631\t\t0.751\t\t168\n",
            "  Universalism: concern     \t0.6522\t\t0.5732\t\t0.7565\t\t0.6705\t\t497\n",
            "  Universalism: nature      \t0.7852\t\t0.8689\t\t0.7162\t\t0.9762\t\t74\n",
            "  Universalism: tolerance   \t0.4362\t\t0.5256\t\t0.3727\t\t0.9129\t\t110\n",
            "  Universalism: objectivity \t0.3364\t\t0.3068\t\t0.3724\t\t0.825\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the models\n",
        "As also indicated in the paper describing the dataset, the task of extracting values from arguments is inevitabily dependant on the cultural background of the people expressing them. For this reason, the models are evalueted both on our test split (original validation split) and on the dataset split extracted by a chinese-background source.\n",
        "The reference evaluation scores are the macro F1s, but we also provide macro inter-class precision, recall and accuracy.\n",
        "We also tuned the threshold needed to obtain hard labels. The default should be 0.5, but we decided to lower it to 0.25 in order to sacrifice a bit of precision and gain an improvement to the recall and thus obtain a better F1 score. \n",
        "Since the threshold is an hyperparameter of the model, tuning was **not** meant to be a way to artifically increase F1-scores."
      ],
      "metadata": {
        "id": "U_pijllXe9j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on the set with the same cultural background\n",
        "We first present and discuss the results on the dataset with same source as the training dataset."
      ],
      "metadata": {
        "id": "8aKWwVBbypB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GloVe BASELINE:\")\n",
        "print_report(embed_classifier, test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzg9AFc-fsQj",
        "outputId": "4cd96387-31c4-4eed-801b-ad00be27d6fe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe BASELINE:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3205\n",
            "  Precision:\t0.4084\n",
            "  Recall:\t0.3944\n",
            "  Accuracy:\t0.7883\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3327\t\t0.3134\t\t0.3546\t\t0.8117\t\t251\n",
            "  Self-direction: action    \t0.4677\t\t0.3729\t\t0.627\t\t0.6266\t\t496\n",
            "  Stimulation               \t0.0284\t\t0.6667\t\t0.0145\t\t0.9277\t\t138\n",
            "  Hedonism                  \t0.0377\t\t0.6667\t\t0.0194\t\t0.9462\t\t103\n",
            "  Achievement               \t0.5364\t\t0.497\t\t0.5826\t\t0.6946\t\t575\n",
            "  Power: dominance          \t0.2591\t\t0.3855\t\t0.1951\t\t0.9035\t\t164\n",
            "  Power: resources          \t0.4324\t\t0.3902\t\t0.4848\t\t0.9114\t\t132\n",
            "  Face                      \t0.0153\t\t1.0\t\t0.0077\t\t0.932\t\t130\n",
            "  Security: personal        \t0.6647\t\t0.5284\t\t0.8959\t\t0.6382\t\t759\n",
            "  Security: societal        \t0.555\t\t0.4833\t\t0.6516\t\t0.731\t\t488\n",
            "  Tradition                 \t0.338\t\t0.3279\t\t0.3488\t\t0.8761\t\t172\n",
            "  Conformity: rules         \t0.474\t\t0.3485\t\t0.7407\t\t0.6055\t\t455\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9684\t\t60\n",
            "  Humility                  \t0.0408\t\t0.15\t\t0.0236\t\t0.9256\t\t127\n",
            "  Benevolence: caring       \t0.4784\t\t0.4225\t\t0.5513\t\t0.5986\t\t633\n",
            "  Benevolence: dependability\t0.1298\t\t0.1824\t\t0.1007\t\t0.8091\t\t268\n",
            "  Universalism: concern     \t0.5824\t\t0.4667\t\t0.7744\t\t0.5976\t\t687\n",
            "  Universalism: nature      \t0.5252\t\t0.4834\t\t0.5748\t\t0.9304\t\t127\n",
            "  Universalism: tolerance   \t0.1246\t\t0.2317\t\t0.0852\t\t0.8592\t\t223\n",
            "  Universalism: objectivity \t0.388\t\t0.251\t\t0.8544\t\t0.4726\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT+LSTM\")\n",
        "print_report(prebert_classifier, bert_test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De3leoMYfsJj",
        "outputId": "d0b7721b-6cb0-4ca1-b7b4-2c7c75189322"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT+LSTM\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3782\n",
            "  Precision:\t0.3753\n",
            "  Recall:\t0.4381\n",
            "  Accuracy:\t0.7967\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3542\t\t0.3868\t\t0.3267\t\t0.8423\t\t251\n",
            "  Self-direction: action    \t0.4701\t\t0.4125\t\t0.5464\t\t0.6777\t\t496\n",
            "  Stimulation               \t0.2479\t\t0.2885\t\t0.2174\t\t0.904\t\t138\n",
            "  Hedonism                  \t0.3429\t\t0.4167\t\t0.2913\t\t0.9393\t\t103\n",
            "  Achievement               \t0.5948\t\t0.4837\t\t0.7722\t\t0.6809\t\t575\n",
            "  Power: dominance          \t0.217\t\t0.4792\t\t0.1402\t\t0.9124\t\t164\n",
            "  Power: resources          \t0.3465\t\t0.3607\t\t0.3333\t\t0.9124\t\t132\n",
            "  Face                      \t0.1804\t\t0.184\t\t0.1769\t\t0.8898\t\t130\n",
            "  Security: personal        \t0.7118\t\t0.6117\t\t0.8511\t\t0.7242\t\t759\n",
            "  Security: societal        \t0.6085\t\t0.6168\t\t0.6004\t\t0.8012\t\t488\n",
            "  Tradition                 \t0.4263\t\t0.4626\t\t0.3953\t\t0.9035\t\t172\n",
            "  Conformity: rules         \t0.4841\t\t0.3528\t\t0.7714\t\t0.6055\t\t455\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9684\t\t60\n",
            "  Humility                  \t0.0779\t\t0.2222\t\t0.0472\t\t0.9251\t\t127\n",
            "  Benevolence: caring       \t0.5101\t\t0.4689\t\t0.5592\t\t0.6414\t\t633\n",
            "  Benevolence: dependability\t0.2661\t\t0.1721\t\t0.5858\t\t0.5432\t\t268\n",
            "  Universalism: concern     \t0.543\t\t0.4601\t\t0.6623\t\t0.596\t\t687\n",
            "  Universalism: nature      \t0.5513\t\t0.4649\t\t0.6772\t\t0.9262\t\t127\n",
            "  Universalism: tolerance   \t0.1812\t\t0.3256\t\t0.1256\t\t0.8666\t\t223\n",
            "  Universalism: objectivity \t0.4498\t\t0.3355\t\t0.6819\t\t0.6735\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINETUNING BERT:\")\n",
        "print_report(finetune_classifier, bert_test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szR1bBY3fr_a",
        "outputId": "2a0df7c4-7643-42b0-947d-0ff37315c2d7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINETUNING BERT:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.4155\n",
            "  Precision:\t0.4647\n",
            "  Recall:\t0.443\n",
            "  Accuracy:\t0.8348\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.4718\t\t0.3818\t\t0.6175\t\t0.817\t\t251\n",
            "  Self-direction: action    \t0.552\t\t0.5076\t\t0.6048\t\t0.7431\t\t496\n",
            "  Stimulation               \t0.2811\t\t0.5532\t\t0.1884\t\t0.9299\t\t138\n",
            "  Hedonism                  \t0.3425\t\t0.5814\t\t0.2427\t\t0.9494\t\t103\n",
            "  Achievement               \t0.6202\t\t0.554\t\t0.7043\t\t0.7384\t\t575\n",
            "  Power: dominance          \t0.3132\t\t0.3761\t\t0.2683\t\t0.8982\t\t164\n",
            "  Power: resources          \t0.5043\t\t0.4085\t\t0.6591\t\t0.9098\t\t132\n",
            "  Face                      \t0.0704\t\t0.4167\t\t0.0385\t\t0.9304\t\t130\n",
            "  Security: personal        \t0.7293\t\t0.6447\t\t0.8393\t\t0.7505\t\t759\n",
            "  Security: societal        \t0.6098\t\t0.5567\t\t0.6742\t\t0.778\t\t488\n",
            "  Tradition                 \t0.4194\t\t0.471\t\t0.3779\t\t0.9051\t\t172\n",
            "  Conformity: rules         \t0.5288\t\t0.5135\t\t0.5451\t\t0.7669\t\t455\n",
            "  Conformity: interpersonal \t0.0323\t\t0.5\t\t0.0167\t\t0.9684\t\t60\n",
            "  Humility                  \t0.0148\t\t0.125\t\t0.0079\t\t0.9299\t\t127\n",
            "  Benevolence: caring       \t0.5708\t\t0.5036\t\t0.6588\t\t0.6693\t\t633\n",
            "  Benevolence: dependability\t0.2682\t\t0.2365\t\t0.3097\t\t0.7611\t\t268\n",
            "  Universalism: concern     \t0.6387\t\t0.5281\t\t0.8079\t\t0.6688\t\t687\n",
            "  Universalism: nature      \t0.675\t\t0.7168\t\t0.6378\t\t0.9589\t\t127\n",
            "  Universalism: tolerance   \t0.2133\t\t0.2984\t\t0.1659\t\t0.856\t\t223\n",
            "  Universalism: objectivity \t0.4549\t\t0.4201\t\t0.496\t\t0.7674\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that, starting from the macro aggregation, that the distribution of scores is almost the same as the one registered on the validation set. In general the GloVe baseline reaches around 30-32% of F1, the BERT+LSTM reaches 35-37% F1 and the Finetuned BERT reaches almost 42% F1. \n",
        "we can also see as the scores in general increment from the simplest model to the most complex, expecially in terms of precision, while the recall remains almost the same, probably due to the usage of the same conversion threshold for each model. <br>\n",
        "If one wants to focus more on the per-class F1 scores, they remain almost the same w.r.t. the validation, except some higher fluctuations (> +/- 7%) common on all models:\n",
        "- \"Tradition\", \"Stimulation\", \"Benevolence: caring\" and \"Universalism: objectivity\" which seem all to increment in the test set\n",
        "- \"Power: resources\", \"Security: Societal\", \"Universalism:Tolerance\" which all seem to decrement.\n",
        "Since this consistent decrements correspond to the classes that have a slightly skewed distribution with respect to the validation set, we can address this fluctuation to change in distribution.\n",
        "\n",
        "Then, we can also individuate the most difficult classes (\\<25\\% F1) being the one under-represented in the training set: \"Stimulation\", \"Hedonism\", \"Face\", \"Conformity:Interpersonal\", \"Humility\".\n",
        "Also \"Universalism:Tolerance\" seems to be quite misclassified, despite having a consistent support."
      ],
      "metadata": {
        "id": "CIsEKd_byoMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_index_label(label_cols, label):\n",
        "  \"\"\"\n",
        "  Function returning the index of the label from the ordered list of labels.\n",
        "  Params:\n",
        "    label_cols: ordered list of labels\n",
        "  Returns: \n",
        "    the index of label in label_cols\n",
        "  \"\"\"\n",
        "  return label_cols.index(label)\n",
        "\n",
        "def labels_array_to_names(labels, label_cols):\n",
        "  \"\"\"\n",
        "  Function converting the binary multi-label arrays into a list of the names\n",
        "  corresponding to the \"1\" values.\n",
        "  Params:\n",
        "    labels: binary labels to be converted\n",
        "    label_cols:  ordered list of labels\n",
        "  returns: \n",
        "    the list containing the label names marked as \"1\" in labels\n",
        "  \"\"\"\n",
        "  return [label_cols[idx] for idx, label in enumerate(labels) if label == 1]\n",
        "\n",
        "def get_true_preds_from_label(model, loader, dataset, label, label_cols, threshold=0.25):\n",
        "  \"\"\"\n",
        "  Function returning the true labels and the predicted labels associated to category\n",
        "  in form of lists of category names.\n",
        "  Params:\n",
        "    model: model to be used to produce predictions\n",
        "    loader: dataloader for the dataset to be used\n",
        "    label: target label to extract from the dataset\n",
        "    label_cols: ordered list of labels\n",
        "    threshold: threshold used to convert scores to hard labels. Defaults to .25\n",
        "  Returns:\n",
        "    return_true: list of true labels of examples being labeled as label\n",
        "    return_preds: list of predicted labels of the corresponding examples in return_true\n",
        "  \"\"\"\n",
        "  \n",
        "  _y_preds = []\n",
        "  y_true = []\n",
        "  model.eval()\n",
        "  for idx, (X, Y) in enumerate(loader):\n",
        "    with torch.no_grad():\n",
        "      preds = model(X)\n",
        "    y_true.extend(Y.cpu().numpy())\n",
        "    _y_preds.append(preds)\n",
        "\n",
        "  gc.collect()\n",
        "  _y_preds = torch.cat(_y_preds)\n",
        "  _y_preds = _y_preds.sigmoid()\n",
        "  _y_preds = _y_preds.detach()\n",
        "\n",
        "  y_preds = []\n",
        "  for i in range(_y_preds.shape[0]):\n",
        "    y_preds.append([1 if _y_preds[i][j] > threshold else 0 for j in range(_y_preds.shape[1])])\n",
        "\n",
        "  index_label = get_index_label(label_cols, label) if type(label) != int else label\n",
        "  if index_label >= num_classes:\n",
        "    return\n",
        "\n",
        "  return_true = []\n",
        "  return_preds = []\n",
        "  return_samples = []\n",
        "  y_one_hot_true = []\n",
        "  y_one_hot_pred = []\n",
        "  for idx, y in enumerate(y_true):\n",
        "    if y[index_label] == 1:\n",
        "      return_samples.append(dataset[idx])\n",
        "      return_true.append(labels_array_to_names(y_true[idx], label_cols))\n",
        "      y_one_hot_true.append(y_true[idx])\n",
        "      return_preds.append(labels_array_to_names(y_preds[idx], label_cols))\n",
        "      y_one_hot_pred.append(y_preds[idx])\n",
        "\n",
        "  return return_true, return_preds, return_samples, y_one_hot_true, y_one_hot_pred"
      ],
      "metadata": {
        "id": "k7Tlz_II7saj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further analysis\n",
        "Since we observed that the class \"Universalism: tolerance\" is affected by a strange trend, because it is a class with high support in the training\n",
        "set (comparable to \"Power: dominance\" and \"Tradition\") but relatively low score on the test set. <br>\n",
        "It is appropriate to analyze which are the classes that are missclassified the most when computing the labels for those examples that also contain \"Universalism:tolerance\", in order to comprehend why it is not assigned that much as a label and in favor of which other labels.\n",
        "To do so we analyze true positives, false positives, true negatives and false negatives for each class of each example which contains the true label \"Universalism: tolerance\"."
      ],
      "metadata": {
        "id": "8JjdGvY2BhG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "universalism_tolerance_idx = 18\n",
        "true, preds, samples, one_true, one_pred = get_true_preds_from_label(finetune_classifier, bert_test_loader, whole_dataset[\"test\"], label_list[universalism_tolerance_idx], label_list)"
      ],
      "metadata": {
        "id": "oNL6UtlLNadt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_counts_for_unique_labels(true, preds, label_list):\n",
        "  \"\"\"\n",
        "  Function returning the true counts and the predicted counts for each category\n",
        "  Params:\n",
        "    true: list of list of labels. Each list corresponds to the true labels\n",
        "         associated to an example\n",
        "    true: list of list of labels. Each list corresponds to the predicted labels\n",
        "         associated to an example\n",
        "     label_list: ordered list of labels (names)\n",
        "  Returns:\n",
        "    true_counts_all_labels: a list containing the true counts for each category\n",
        "      in label_list, aggregated from true\n",
        "    preds_counts_all_labels: a list containing the predicted counts for each category\n",
        "      in label_list, aggregated from preds\n",
        "  \"\"\"\n",
        "  all_true_labels = []\n",
        "  all_predicted_labels = []\n",
        "  for idx, elem in enumerate(true):\n",
        "    all_true_labels.extend([elem[j] for j in range(0, len(elem))])\n",
        "    all_predicted_labels.extend(preds[idx][j] for j in range(0, len(preds[idx])))\n",
        "\n",
        "\n",
        "  true_label_arr, true_counts = np.unique(all_true_labels, return_counts = True)\n",
        "  pred_label_arr, pred_counts = np.unique(all_predicted_labels, return_counts = True)\n",
        "\n",
        "  true_counts_all_labels = np.zeros(len(label_list))\n",
        "  preds_counts_all_labels = np.zeros(len(label_list))\n",
        "  for i in range(0, len(label_list)):\n",
        "    if label_list[i] in true_label_arr:\n",
        "      true_counts_all_labels[i] = true_counts[np.where(true_label_arr == label_list[i])]\n",
        "    if label_list[i] in pred_label_arr:\n",
        "      preds_counts_all_labels[i] = pred_counts[np.where(pred_label_arr == label_list[i])]\n",
        "  return true_counts_all_labels, preds_counts_all_labels\n",
        "\n",
        "def print_counts_for_unique_labels(true_counts_all_labels, preds_counts_all_labels, label_list):\n",
        "  \"\"\"\n",
        "  Function printing the outputs of get_counts_for_unique_labels. It prints\n",
        "  true and predicted counts for each label.\n",
        "  Params:\n",
        "     true_counts_all_labels: a list containing the true counts for each category\n",
        "      in label_list of a portion of examples\n",
        "    preds_counts_all_labels: a list containing the predicted counts for each category\n",
        "      in label_list of a portion of examples\n",
        "    label_list: ordered list of labels (names)\n",
        "  \"\"\"\n",
        "  print(\"\\t\\t\\t\\tTrue counts\\t\\tPredicted counts\\n\")\n",
        "  for i, label in enumerate(label_list):\n",
        "    print(label +\" \"*(30 - len(label)) + \"\\t\"+str(true_counts_all_labels[i])+\"\\t\\t\\t\"+str(preds_counts_all_labels[i]))\n",
        "\n",
        "true_counts_all_labels, preds_counts_all_labels = get_counts_for_unique_labels(true, preds, label_list)\n",
        "print_counts_for_unique_labels(true_counts_all_labels, preds_counts_all_labels, label_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZVQ9vI-ueSI",
        "outputId": "743d4722-0a81-4a40-8cca-660a14ce3c2b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\t\tTrue counts\t\tPredicted counts\n",
            "\n",
            "Self-direction: thought       \t56.0\t\t\t77.0\n",
            "Self-direction: action        \t84.0\t\t\t88.0\n",
            "Stimulation                   \t34.0\t\t\t10.0\n",
            "Hedonism                      \t18.0\t\t\t6.0\n",
            "Achievement                   \t77.0\t\t\t96.0\n",
            "Power: dominance              \t22.0\t\t\t10.0\n",
            "Power: resources              \t5.0\t\t\t11.0\n",
            "Face                          \t24.0\t\t\t4.0\n",
            "Security: personal            \t91.0\t\t\t119.0\n",
            "Security: societal            \t41.0\t\t\t57.0\n",
            "Tradition                     \t23.0\t\t\t30.0\n",
            "Conformity: rules             \t43.0\t\t\t44.0\n",
            "Conformity: interpersonal     \t18.0\t\t\t1.0\n",
            "Humility                      \t19.0\t\t\t1.0\n",
            "Benevolence: caring           \t81.0\t\t\t108.0\n",
            "Benevolence: dependability    \t21.0\t\t\t27.0\n",
            "Universalism: concern         \t95.0\t\t\t129.0\n",
            "Universalism: nature          \t5.0\t\t\t7.0\n",
            "Universalism: tolerance       \t223.0\t\t\t37.0\n",
            "Universalism: objectivity     \t60.0\t\t\t64.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inference_types_for_fn(one_true, one_pred, label_list, label_idx):\n",
        "  \"\"\"\n",
        "  Function building the confusion matrix for a portion of examples where\n",
        "  the label corresponding to a specific index was not predicted (false negative).\n",
        "  This function should help identifying the labels that are more probably\n",
        "  associated to those examples then the said label is not assigned.\n",
        "  Params:\n",
        "    one_true: list of binary arrays. Each array represent the true labels of an\n",
        "      example\n",
        "    one_pred: list of binary arrays. Each array represent the predicted labels of an\n",
        "      example\n",
        "    label_list: ordered list of labels (names)\n",
        "    label_idx: index corresponding to the label under analysis (false negative)\n",
        "  Returns:\n",
        "    class_inferences: a list of lists containing the false negatives, true negatives,\n",
        "                false positives and true positives for each class, discarding the examples\n",
        "                where the target class indicated with label_idx is a false negative.\n",
        "  \"\"\"\n",
        "  class_inferences = np.zeros((20, 4))\n",
        "  for example in range(0, len(one_true)):\n",
        "    inf_mat = [one_pred[example][i] - one_true[example][i] if one_pred[example][i] != one_true[example][i] else 2 if one_pred[example][i] == 1 else 0 for i in range(0, len(one_pred[0])) ]\n",
        "    added_mat = inf_mat + np.ones(len(inf_mat))\n",
        "    if added_mat[label_idx] == 0:\n",
        "      for i in range(len(inf_mat)):\n",
        "        if i != label_idx:\n",
        "          if added_mat[i] == 3:\n",
        "            #tp_acc\n",
        "            class_inferences[i][3] += 1\n",
        "          elif added_mat[i] == 2:\n",
        "            #fp_acc\n",
        "            class_inferences[i][2] += 1\n",
        "          elif added_mat[i] == 1:\n",
        "            #tn_acc\n",
        "            class_inferences[i][1] += 1\n",
        "          else: \n",
        "            #fn_acc\n",
        "            class_inferences[i][0] += 1\n",
        "  return class_inferences\n",
        "\n",
        "def print_inference_types_fn(class_inferences, label_list, label_idx):\n",
        "  \"\"\"\n",
        "  Function printing the results of get_inference_types_for_fn.\n",
        "  Params:\n",
        "    class_inferences: a list of lists containing the false negatives, true negatives,\n",
        "                false positives and true positives for each class\n",
        "    label_list: ordered list of labels (names)\n",
        "    label_idx: index corresponding to the label under analysis (false negative).\n",
        "                it is removed from the printed report\n",
        "    \n",
        "  \"\"\"\n",
        "  print(\"\\t\\t\\t\\t\" + \"tp\" + \"\\t\" + \"fp\" + \"\\t\" + \"tn\"+ \"\\t\"+ \"fn\")\n",
        "  for idx, label in enumerate(label_list):\n",
        "    if idx != label_idx:\n",
        "      print(label +\" \"*(30 - len(label)) + \"\\t\"+str(class_inferences[idx][3])+\"\\t\"+str(class_inferences[idx][2])+\"\\t\"+str(class_inferences[idx][1])+\"\\t\"+str(class_inferences[idx][0]))\n",
        "\n",
        "inf_fn_mat = get_inference_types_for_fn(one_true, one_pred, label_list, label_idx = universalism_tolerance_idx)\n",
        "print_inference_types_fn(inf_fn_mat, label_list, label_idx = universalism_tolerance_idx)\n"
      ],
      "metadata": {
        "id": "RoBE7LqMGsPH",
        "outputId": "10c3483a-48b8-476b-9fea-1a95eb3da4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\t\ttp\tfp\ttn\tfn\n",
            "Self-direction: thought       \t29.0\t24.0\t119.0\t14.0\n",
            "Self-direction: action        \t47.0\t29.0\t80.0\t30.0\n",
            "Stimulation                   \t3.0\t5.0\t150.0\t28.0\n",
            "Hedonism                      \t2.0\t2.0\t168.0\t14.0\n",
            "Achievement                   \t45.0\t26.0\t99.0\t16.0\n",
            "Power: dominance              \t2.0\t7.0\t161.0\t16.0\n",
            "Power: resources              \t4.0\t7.0\t174.0\t1.0\n",
            "Face                          \t2.0\t1.0\t166.0\t17.0\n",
            "Security: personal            \t61.0\t43.0\t62.0\t20.0\n",
            "Security: societal            \t19.0\t28.0\t122.0\t17.0\n",
            "Tradition                     \t9.0\t15.0\t152.0\t10.0\n",
            "Conformity: rules             \t23.0\t20.0\t126.0\t17.0\n",
            "Conformity: interpersonal     \t0.0\t1.0\t170.0\t15.0\n",
            "Humility                      \t0.0\t0.0\t170.0\t16.0\n",
            "Benevolence: caring           \t51.0\t45.0\t67.0\t23.0\n",
            "Benevolence: dependability    \t5.0\t22.0\t144.0\t15.0\n",
            "Universalism: concern         \t58.0\t48.0\t61.0\t19.0\n",
            "Universalism: nature          \t3.0\t4.0\t178.0\t1.0\n",
            "Universalism: objectivity     \t18.0\t22.0\t121.0\t25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label \"Universalism: tolerance\" has 181 false negatives over 223 examples. By observing the false positives of those examples where \"Universalism: tolerance\" is a false negative, we can derive that the top-5 classes that are confused the most with this label (false positives) are:\n",
        "- Self-direction: action \n",
        "- Security: personal\n",
        "- Security: societal \n",
        "- Benevolence: caring \n",
        "- Universalism: concern\n",
        "\n",
        "The labels \"Security: personal\" and \"Security: societal\" are distant w.r.t. \"Universalism: tolerance\" if considering the values continuum. <br> \n",
        "However they belong to the most supported classes in the training set and the often appear together with \"Universalism: tolerance\" in the same arguments. <br>\n",
        "The other classes which have a strong correlation with this label are \"Universalism: concern\", \"Benevolence: caring\" and \"Self-direction: action\", they also are closer to \"Universalism: tolerance\" in the continuum.\n",
        "\n",
        "From this follows that due to correlation and the fact that these values can all be brought back to the same themes of being \"Tolerant\" (or the opposite of it) and being interested to equality and freedom among people (\"Universalism: concern\", \"Self-direction: action\") or in general being \"good\" to others (\"Benevolence: caring\"), we can expect that the corresponding arguments are semantically very similar and thus difficult to be distinguished between them."
      ],
      "metadata": {
        "id": "a0TUyHGGIqoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation on the set with a different cultural background\n",
        "We then present and discuss the results on the dataset with a different source from those of the training dataset."
      ],
      "metadata": {
        "id": "Ij_p4-VE5GZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "bert_chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))"
      ],
      "metadata": {
        "id": "RjbLllyCSzCT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GloVe BASELINE:\")\n",
        "print_report(embed_classifier, chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "62tEI5umoyte",
        "outputId": "f594dfc2-751c-4915-d911-b50feaf567ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe BASELINE:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.253\n",
            "  Precision:\t0.1887\n",
            "  Recall:\t0.4269\n",
            "  Accuracy:\t0.765\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.1875\t\t0.1154\t\t0.5\t\t0.74\t\t6\n",
            "  Self-direction: action    \t0.3333\t\t0.2258\t\t0.6364\t\t0.72\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t0\n",
            "  Hedonism                  \t0.5\t\t0.5\t\t0.5\t\t0.98\t\t2\n",
            "  Achievement               \t0.6034\t\t0.4545\t\t0.8974\t\t0.54\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.91\t\t1\n",
            "  Power: resources          \t0.4\t\t0.3226\t\t0.5263\t\t0.7\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.4538\t\t0.3034\t\t0.9\t\t0.35\t\t30\n",
            "  Security: societal        \t0.4471\t\t0.3519\t\t0.6129\t\t0.53\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t0\n",
            "  Conformity: rules         \t0.35\t\t0.28\t\t0.4667\t\t0.74\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.94\t\t5\n",
            "  Benevolence: caring       \t0.2264\t\t0.1463\t\t0.5\t\t0.59\t\t12\n",
            "  Benevolence: dependability\t0.08\t\t0.0455\t\t0.3333\t\t0.77\t\t3\n",
            "  Universalism: concern     \t0.5067\t\t0.3519\t\t0.9048\t\t0.63\t\t21\n",
            "  Universalism: nature      \t0.5385\t\t0.3889\t\t0.875\t\t0.88\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.93\t\t2\n",
            "  Universalism: objectivity \t0.434\t\t0.2875\t\t0.8846\t\t0.4\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT+LSTM:\")\n",
        "print_report(prebert_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "o9mxpo4jorh4",
        "outputId": "c3ac2db1-5483-42bc-bcb0-51ba8b7702a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT+LSTM:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.2583\n",
            "  Precision:\t0.2014\n",
            "  Recall:\t0.4301\n",
            "  Accuracy:\t0.792\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.25\t\t0.1538\t\t0.6667\t\t0.76\t\t6\n",
            "  Self-direction: action    \t0.2899\t\t0.1724\t\t0.9091\t\t0.51\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.91\t\t0\n",
            "  Hedonism                  \t0.3333\t\t0.25\t\t0.5\t\t0.96\t\t2\n",
            "  Achievement               \t0.5873\t\t0.4253\t\t0.9487\t\t0.48\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Power: resources          \t0.3571\t\t0.2703\t\t0.5263\t\t0.64\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.96\t\t1\n",
            "  Security: personal        \t0.551\t\t0.3971\t\t0.9\t\t0.56\t\t30\n",
            "  Security: societal        \t0.4194\t\t0.4194\t\t0.4194\t\t0.64\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.4324\t\t0.3636\t\t0.5333\t\t0.79\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.375\t\t0.3\t\t0.5\t\t0.8\t\t12\n",
            "  Benevolence: dependability\t0.1111\t\t0.0606\t\t0.6667\t\t0.68\t\t3\n",
            "  Universalism: concern     \t0.5909\t\t0.5652\t\t0.619\t\t0.82\t\t21\n",
            "  Universalism: nature      \t0.4375\t\t0.2917\t\t0.875\t\t0.82\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t2\n",
            "  Universalism: objectivity \t0.4308\t\t0.359\t\t0.5385\t\t0.63\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINETUNED BERT:\")\n",
        "print_report(finetune_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "l8nyZS91oqwE",
        "outputId": "de16e548-8bd2-46e4-96d5-98cb93b61f54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINETUNED BERT:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3135\n",
            "  Precision:\t0.2758\n",
            "  Recall:\t0.443\n",
            "  Accuracy:\t0.8365\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.2941\t\t0.1786\t\t0.8333\t\t0.76\t\t6\n",
            "  Self-direction: action    \t0.3729\t\t0.2292\t\t1.0\t\t0.63\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t0\n",
            "  Hedonism                  \t0.6667\t\t1.0\t\t0.5\t\t0.99\t\t2\n",
            "  Achievement               \t0.6667\t\t0.5397\t\t0.8718\t\t0.66\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t1\n",
            "  Power: resources          \t0.4151\t\t0.3235\t\t0.5789\t\t0.69\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.5783\t\t0.4528\t\t0.8\t\t0.65\t\t30\n",
            "  Security: societal        \t0.5405\t\t0.4651\t\t0.6452\t\t0.66\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.4737\t\t0.3913\t\t0.6\t\t0.8\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.3226\t\t0.2632\t\t0.4167\t\t0.79\t\t12\n",
            "  Benevolence: dependability\t0.1\t\t0.0588\t\t0.3333\t\t0.82\t\t3\n",
            "  Universalism: concern     \t0.6102\t\t0.4737\t\t0.8571\t\t0.77\t\t21\n",
            "  Universalism: nature      \t0.7619\t\t0.6154\t\t1.0\t\t0.95\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Universalism: objectivity \t0.4681\t\t0.5238\t\t0.4231\t\t0.75\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As quite expected, the values of F1 dropped of about 10 points from the correspondant test score. We must first remark that other than being a different source dataset with a quite different distribution of labels, two labels are missing from this split, being \"Stimulation\" and \"Tradition\". This surely contributes in lowering the scores, together with the most difficult classes having very low support in this test set (among the 0-F1-scored classes, most of them has 1 to a few examples). These results, in fact, also confirm our previous observations on difficult and easier classes.\n",
        "In general we can see how both the GloVe model and the BERT+LSTM model are less flexible w.r.t. the finetuned bert, as they achieve very similar scores. However, BERT+LSTM still has a very slight increment in performance w.r.t. GloVe, showing that it still marginally improves it."
      ],
      "metadata": {
        "id": "mH8FQHd85reX"
      }
    }
  ]
}
