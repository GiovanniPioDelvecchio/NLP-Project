{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c104e49b5744e85ac32bf8eaa631aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04b4b7d920d849ff9de655e4f1be121e",
              "IPY_MODEL_d270f8ff78464a03aedf5af00972dfc6",
              "IPY_MODEL_ff43d4605e8747689b01a22321e4e8a6"
            ],
            "layout": "IPY_MODEL_87e123e1a6214a0e8fa19ce34dae93eb"
          }
        },
        "04b4b7d920d849ff9de655e4f1be121e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ebef705591493595b2775423d6d518",
            "placeholder": "​",
            "style": "IPY_MODEL_c88ee05eee7f4d93be1c5a5c6c1f97f8",
            "value": "100%"
          }
        },
        "d270f8ff78464a03aedf5af00972dfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0398f8bc05480da47f52ee1e5555da",
            "max": 4176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f14eef72b914af7a66c9b6d3a758294",
            "value": 4176
          }
        },
        "ff43d4605e8747689b01a22321e4e8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1a88b1d4b1c4100b32a6c3cde34611f",
            "placeholder": "​",
            "style": "IPY_MODEL_314b831f60784d499a29dddad43ee838",
            "value": " 4176/4176 [00:03&lt;00:00, 1163.93ex/s]"
          }
        },
        "87e123e1a6214a0e8fa19ce34dae93eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ebef705591493595b2775423d6d518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88ee05eee7f4d93be1c5a5c6c1f97f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f0398f8bc05480da47f52ee1e5555da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f14eef72b914af7a66c9b6d3a758294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1a88b1d4b1c4100b32a6c3cde34611f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314b831f60784d499a29dddad43ee838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c58f6475e834652b5c6c1cf3cee7423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1b08c6cabbb4ee48469c093a13e6ef2",
              "IPY_MODEL_4d1dd8b20bbd42d6b8770ff7a9568ee0",
              "IPY_MODEL_f97b734bfc73452eb06e955e2ab27835"
            ],
            "layout": "IPY_MODEL_a648212654eb4000a0bd55491057a44e"
          }
        },
        "b1b08c6cabbb4ee48469c093a13e6ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1730709430a04d81bdbccfd8a3eec405",
            "placeholder": "​",
            "style": "IPY_MODEL_e8408933aad543af9c52b616097ed255",
            "value": "100%"
          }
        },
        "4d1dd8b20bbd42d6b8770ff7a9568ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2354b540b74d6a84aba1ddf4efad87",
            "max": 1217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bf108f03ee34136a5d035708b2e3c0b",
            "value": 1217
          }
        },
        "f97b734bfc73452eb06e955e2ab27835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f3337c65664ee5856158b7fb05bdcb",
            "placeholder": "​",
            "style": "IPY_MODEL_df9f0e53d92c457a81fd14e70e8638c2",
            "value": " 1217/1217 [00:00&lt;00:00, 1329.64ex/s]"
          }
        },
        "a648212654eb4000a0bd55491057a44e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1730709430a04d81bdbccfd8a3eec405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8408933aad543af9c52b616097ed255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad2354b540b74d6a84aba1ddf4efad87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf108f03ee34136a5d035708b2e3c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f3337c65664ee5856158b7fb05bdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df9f0e53d92c457a81fd14e70e8638c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cb4e570df1f486f9f34bcd69dbcc74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_252a945a052b4aaa8acf7afc1857754c",
              "IPY_MODEL_bfa9388962d74bd3a381820a2ce91706",
              "IPY_MODEL_495f20874fe34888b4fc4611dc2e2c12"
            ],
            "layout": "IPY_MODEL_676e6bad052a453cbe7ffe031f2f1a51"
          }
        },
        "252a945a052b4aaa8acf7afc1857754c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658e54be10cd4e6eb0611d9eaa6f4800",
            "placeholder": "​",
            "style": "IPY_MODEL_5d9478b7068b4ef086eedee50f5345bb",
            "value": "100%"
          }
        },
        "bfa9388962d74bd3a381820a2ce91706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7082b017a24c5bb6899b27b4bc440d",
            "max": 1896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03a53be19d7c4a73b2ba91cad2a07bd1",
            "value": 1896
          }
        },
        "495f20874fe34888b4fc4611dc2e2c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45dec7c9ac6845c5ad55166bd13fd4d5",
            "placeholder": "​",
            "style": "IPY_MODEL_13ebafd1415040b690860fda01899345",
            "value": " 1896/1896 [00:01&lt;00:00, 864.40ex/s]"
          }
        },
        "676e6bad052a453cbe7ffe031f2f1a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658e54be10cd4e6eb0611d9eaa6f4800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d9478b7068b4ef086eedee50f5345bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be7082b017a24c5bb6899b27b4bc440d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a53be19d7c4a73b2ba91cad2a07bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45dec7c9ac6845c5ad55166bd13fd4d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ebafd1415040b690860fda01899345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "204ed3813e5b4e5e9026485ed5c25d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c86b67c9398a4636acacf6f14e4fd42a",
              "IPY_MODEL_e9e750d5c8b046d9b732ec3e190381cb",
              "IPY_MODEL_37627cf9a90745da96168588f184cb96"
            ],
            "layout": "IPY_MODEL_a3cf63338e6f4fc38ee6c774301ae6bd"
          }
        },
        "c86b67c9398a4636acacf6f14e4fd42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e2a3fa1428411d9fc5e9ad5768de22",
            "placeholder": "​",
            "style": "IPY_MODEL_0a14b0194e9048aa92e339ee707cf088",
            "value": "100%"
          }
        },
        "e9e750d5c8b046d9b732ec3e190381cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43335f1174284f3ca193c28d4068482a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d0cd3510f674a618c7fa26cf267ae50",
            "value": 100
          }
        },
        "37627cf9a90745da96168588f184cb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea8dc2ab196433da436b34143297a80",
            "placeholder": "​",
            "style": "IPY_MODEL_5aa84a2a8a664bd0b34eb3d07e2ef643",
            "value": " 100/100 [00:00&lt;00:00, 1046.66ex/s]"
          }
        },
        "a3cf63338e6f4fc38ee6c774301ae6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e2a3fa1428411d9fc5e9ad5768de22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a14b0194e9048aa92e339ee707cf088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43335f1174284f3ca193c28d4068482a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0cd3510f674a618c7fa26cf267ae50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fea8dc2ab196433da436b34143297a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa84a2a8a664bd0b34eb3d07e2ef643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP course project\n",
        "**Summary**: Application of text classification approaches for Human Value Detection <br>\n",
        "**Members**:\n",
        "- Dell'Olio Domenico\n",
        "- Delvecchio Giovanni Pio\n",
        "- Disabato Raffaele  \n"
      ],
      "metadata": {
        "id": "wWUTpjsbw3DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project was developed in order to create and test various models to address the task of Human Value Detection proposed in the challenge: <br>\n",
        "https://touche.webis.de/semeval23/touche23-web/index.html <br>\n",
        "\n",
        "The challenge can be tackled as a multi-label text clasification problem, thus we decided to implement and test various architectures in order to compare their performances. <br>\n",
        "These architectures were either already present at the state of the art or were obtained as a result of experiments."
      ],
      "metadata": {
        "id": "D6YEI0XMxl2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook contains the following implementations:\n",
        "- GloVe baseline with two layers of Bi-GRU, followed by flatten and two dense layers with ReLU activation and a single dense layer with no activation;\n",
        "- BERT baseline with two layers of Bi-LSTM (transfer learning), where the output cell states are concatenated and passed to a dense layer with ReLU activation and a single dense layer with no activation;\n",
        "- finetuning of BERT followed by a dense layer with ReLU activation followed by a dense layer with no activation.\n",
        "\n",
        "## This notebook does **not** contain:\n",
        "- exstensive Data analysis (it is explored in the other notebook)"
      ],
      "metadata": {
        "id": "3tcwwV4uu6kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cF2LQqwOLX2",
        "outputId": "70c555db-09a5-4bbf-d80f-85ed9c332feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# installation of the required libraries\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for the download of the datasets\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYe5zjeVO5yS",
        "outputId": "86b0aee2-2e09-4ba9-bbd4-9507d3c0448b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-09 16:03:10--  https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1012498 (989K) [application/octet-stream]\n",
            "Saving to: ‘arguments-training.tsv’\n",
            "\n",
            "arguments-training. 100%[===================>] 988.77K   176KB/s    in 6.7s    \n",
            "\n",
            "2023-02-09 16:03:20 (147 KB/s) - ‘arguments-training.tsv’ saved [1012498/1012498]\n",
            "\n",
            "--2023-02-09 16:03:20--  https://zenodo.org/record/7550385/files/labels-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253843 (248K) [application/octet-stream]\n",
            "Saving to: ‘labels-training.tsv’\n",
            "\n",
            "labels-training.tsv 100%[===================>] 247.89K   318KB/s    in 0.8s    \n",
            "\n",
            "2023-02-09 16:03:23 (318 KB/s) - ‘labels-training.tsv’ saved [253843/253843]\n",
            "\n",
            "--2023-02-09 16:03:23--  https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362608 (354K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>] 354.11K   304KB/s    in 1.2s    \n",
            "\n",
            "2023-02-09 16:03:26 (304 KB/s) - ‘arguments-validation.tsv’ saved [362608/362608]\n",
            "\n",
            "--2023-02-09 16:03:26--  https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89484 (87K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation.tsv’\n",
            "\n",
            "labels-validation.t 100%[===================>]  87.39K   452KB/s    in 0.2s    \n",
            "\n",
            "2023-02-09 16:03:28 (452 KB/s) - ‘labels-validation.tsv’ saved [89484/89484]\n",
            "\n",
            "--2023-02-09 16:03:28--  https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290185 (283K) [application/octet-stream]\n",
            "Saving to: ‘arguments-test.tsv’\n",
            "\n",
            "arguments-test.tsv  100%[===================>] 283.38K   351KB/s    in 0.8s    \n",
            "\n",
            "2023-02-09 16:03:31 (351 KB/s) - ‘arguments-test.tsv’ saved [290185/290185]\n",
            "\n",
            "--2023-02-09 16:03:31--  https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22082 (22K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation-zhihu.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>]  21.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-09 16:03:33 (268 MB/s) - ‘arguments-validation-zhihu.tsv’ saved [22082/22082]\n",
            "\n",
            "--2023-02-09 16:03:33--  https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5072 (5.0K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation-zhihu.tsv’\n",
            "\n",
            "labels-validation-z 100%[===================>]   4.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-09 16:03:34 (697 MB/s) - ‘labels-validation-zhihu.tsv’ saved [5072/5072]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for dataset loading\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# torch imports\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "from torchinfo import summary\n",
        "from torch.optim import AdamW\n",
        "\n",
        "#huggingface imports\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "\n",
        "# progress bar\n",
        "from tqdm import tqdm\n",
        "# garbage collector\n",
        "import gc\n",
        "\n",
        "# imports for evaluation\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "4-K7IcSRPtPO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "  \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "  Params:\n",
        "    seed: the seed to use. \n",
        "  \"\"\"\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "OFk0dSBHFCYx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell needed to fix the seeds and define the available device\n",
        "# for the training of the models\n",
        "seed = 10\n",
        "fix_random(seed)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "DbJvCz2MOnRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2060401c-e338-4e08-a9aa-ac7b55e4b07b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def huggingface_from_pandas(pandas_df):\n",
        "  \"\"\"\n",
        "  Function converting a pandas dataframe to a huggingface dataset.\n",
        "  It also returns an ordered list containing the target labels\n",
        "\n",
        "  Params:\n",
        "    pandas_df: the dataset that has to be converted\n",
        "  Returns:\n",
        "    hf_ds:     the huggingface dataset obrained from pandas_df\n",
        "    label_cols: the ordered list of target labels of pandas_df\n",
        "  \"\"\"\n",
        "\n",
        "  hf_ds = Dataset.from_pandas(pandas_df, preserve_index=False)\n",
        "  hf_ds = hf_ds.remove_columns([\"Argument ID\", \"Argument ID2\"])\n",
        "  # Aggregating labels in a single list\n",
        "  hf_ds = hf_ds.map(lambda x:{\"labels\": [int(x[col]) for col in hf_ds.column_names if\n",
        "                                      col not in ['Conclusion', 'Stance', 'Premise']]})\n",
        "  label_cols = [col for col in hf_ds.column_names if col not in ['Conclusion', 'Stance', 'Premise', \"labels\"]]\n",
        "  # here we are removing the columns related to the labels from the dataset\n",
        "  hf_ds = hf_ds.remove_columns(label_cols)\n",
        "  return hf_ds, label_cols"
      ],
      "metadata": {
        "id": "pLN6XBISHnLf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The challenge provides the already splitted dataset in Train, Validation and Test splits. However the Test split does not have public labels available, \n",
        "so we decided to split the Training set in (Training, Validation) \n",
        "(with proportions 80-20 on unique conclusions) and to use the validation set as Test set.  <br>\n",
        "We decided to probe the robustness of our model on the Chinese validation\n",
        "set too, which has a different cultural background."
      ],
      "metadata": {
        "id": "hq8Fgjoj0__P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_wrt_conclusions(train, ratio = 0.8):\n",
        "  \"\"\"\n",
        "  Function needed to perform the splits over the original train dataset,\n",
        "  in order to obtain a train and a validation set which are divided by unique\n",
        "  conclusions. The ratio parameter is needed in order to assign which portion \n",
        "  of the unique conclusions must be selected for the train split.\n",
        "  \n",
        "  Params:\n",
        "    train: the original train set, to be splitted (Pandas dataframe)\n",
        "    ratio: the proportion in (0, 1) of unique conclusions to be inserted in \n",
        "           the training dataframe.\n",
        "  Returns:\n",
        "    train_set_to_return: the portion of train that contains ratio unique\n",
        "                         conclusions.\n",
        "    val_set_to_return: the proportion of the train that contains 1 - ratio\n",
        "                       unique conclusions (the remaining ones)\n",
        "  \"\"\"\n",
        "  val = []\n",
        "  unique_conc = pd.unique(train[\"Conclusion\"])\n",
        "  num_train_con = int(len(unique_conc)*ratio)\n",
        "  train_unique_conc = np.random.choice(unique_conc, num_train_con, replace = False)\n",
        "  val_unique_conc = set(unique_conc) - set(train_unique_conc)\n",
        "  train_set_to_return = train[train.Conclusion.isin(train_unique_conc)] \n",
        "  val_set_to_return = train[train.Conclusion.isin(val_unique_conc)]\n",
        "  return train_set_to_return, val_set_to_return"
      ],
      "metadata": {
        "id": "swL5m3C4x7wV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loading and splitting\n",
        "raw_training = pd.read_csv(\"arguments-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_training_lab = pd.read_csv(\"labels-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test = pd.read_csv(\"arguments-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_lab = pd.read_csv(\"labels-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn=pd.read_csv(\"arguments-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn_lab=pd.read_csv(\"labels-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "\n",
        "train = raw_training.join(raw_training_lab,how='inner' ,lsuffix='2') # joining labels\n",
        "test = raw_test.join(raw_test_lab, how='inner', lsuffix='2') # joining labels\n",
        "test_chn = raw_test_chn.join(raw_test_chn_lab, how='inner', lsuffix='2') # joining labels\n",
        "fix_random(seed)\n",
        "train, val = train_test_split_wrt_conclusions(train) # splitting training\n",
        "\n",
        "train_ds, label_list = huggingface_from_pandas(train)\n",
        "val_ds, _ = huggingface_from_pandas(val)\n",
        "test_ds, _ = huggingface_from_pandas(test)\n",
        "test_chn_ds, _ = huggingface_from_pandas(test_chn) \n",
        "\n",
        "print(\"Single example from the training dataset: \")\n",
        "print(train_ds[0])\n",
        "print(\"Full list of target labels: \")\n",
        "print(label_list)\n",
        "num_classes = len(label_list)\n",
        "print(\"Total number of target labels: \")\n",
        "print(num_classes)\n",
        "whole_dataset = DatasetDict()\n",
        "whole_dataset[\"train\"] = train_ds.with_format(\"torch\")\n",
        "whole_dataset[\"val\"] = val_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test\"] = test_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test_chn\"] = test_chn_ds.with_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "6c104e49b5744e85ac32bf8eaa631aa4",
            "04b4b7d920d849ff9de655e4f1be121e",
            "d270f8ff78464a03aedf5af00972dfc6",
            "ff43d4605e8747689b01a22321e4e8a6",
            "87e123e1a6214a0e8fa19ce34dae93eb",
            "d7ebef705591493595b2775423d6d518",
            "c88ee05eee7f4d93be1c5a5c6c1f97f8",
            "6f0398f8bc05480da47f52ee1e5555da",
            "5f14eef72b914af7a66c9b6d3a758294",
            "b1a88b1d4b1c4100b32a6c3cde34611f",
            "314b831f60784d499a29dddad43ee838",
            "4c58f6475e834652b5c6c1cf3cee7423",
            "b1b08c6cabbb4ee48469c093a13e6ef2",
            "4d1dd8b20bbd42d6b8770ff7a9568ee0",
            "f97b734bfc73452eb06e955e2ab27835",
            "a648212654eb4000a0bd55491057a44e",
            "1730709430a04d81bdbccfd8a3eec405",
            "e8408933aad543af9c52b616097ed255",
            "ad2354b540b74d6a84aba1ddf4efad87",
            "2bf108f03ee34136a5d035708b2e3c0b",
            "89f3337c65664ee5856158b7fb05bdcb",
            "df9f0e53d92c457a81fd14e70e8638c2",
            "8cb4e570df1f486f9f34bcd69dbcc74a",
            "252a945a052b4aaa8acf7afc1857754c",
            "bfa9388962d74bd3a381820a2ce91706",
            "495f20874fe34888b4fc4611dc2e2c12",
            "676e6bad052a453cbe7ffe031f2f1a51",
            "658e54be10cd4e6eb0611d9eaa6f4800",
            "5d9478b7068b4ef086eedee50f5345bb",
            "be7082b017a24c5bb6899b27b4bc440d",
            "03a53be19d7c4a73b2ba91cad2a07bd1",
            "45dec7c9ac6845c5ad55166bd13fd4d5",
            "13ebafd1415040b690860fda01899345",
            "204ed3813e5b4e5e9026485ed5c25d0f",
            "c86b67c9398a4636acacf6f14e4fd42a",
            "e9e750d5c8b046d9b732ec3e190381cb",
            "37627cf9a90745da96168588f184cb96",
            "a3cf63338e6f4fc38ee6c774301ae6bd",
            "80e2a3fa1428411d9fc5e9ad5768de22",
            "0a14b0194e9048aa92e339ee707cf088",
            "43335f1174284f3ca193c28d4068482a",
            "8d0cd3510f674a618c7fa26cf267ae50",
            "fea8dc2ab196433da436b34143297a80",
            "5aa84a2a8a664bd0b34eb3d07e2ef643"
          ]
        },
        "id": "FU98Kgv5Q3PO",
        "outputId": "ed6b6469-6d2d-4c68-8a18-920062ccbd1b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4176 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c104e49b5744e85ac32bf8eaa631aa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1217 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c58f6475e834652b5c6c1cf3cee7423"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1896 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cb4e570df1f486f9f34bcd69dbcc74a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "204ed3813e5b4e5e9026485ed5c25d0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single example from the training dataset: \n",
            "{'Conclusion': 'We should ban human cloning', 'Stance': 'in favor of', 'Premise': 'we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.', 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "Full list of target labels: \n",
            "['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']\n",
            "Total number of target labels: \n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, loader):\n",
        "  \"\"\"\n",
        "  Function needed to obtain the prediction for the target labels\n",
        "  given a model and a data loader.\n",
        "\n",
        "  Params:\n",
        "    model: the model that will be used to obtain the predictions over\n",
        "           the labels\n",
        "    loader: the data loader needed to feed the model with the data for which\n",
        "            we want to obtain label predictions\n",
        "  Returns:\n",
        "    Y_preds: tensor containing the predicted label for each example.\n",
        "             These labels are obtained as the output of the model passed to\n",
        "             a sigmoid function.\n",
        "  \"\"\"\n",
        "  Y_preds = []\n",
        "  model.eval()\n",
        "  for X, Y in loader:\n",
        "    with torch.no_grad():\n",
        "      preds = model(X)\n",
        "    Y_preds.append(preds)\n",
        "  gc.collect()\n",
        "  Y_preds = torch.cat(Y_preds)\n",
        "  Y_preds = Y_preds.sigmoid()\n",
        "  return Y_preds.detach()\n",
        "\n",
        "def keep_above_thresh(Y_preds, thr):\n",
        "  \"\"\"\n",
        "  Function needed to convert the results of the models to hard labels\n",
        "  using a threshold.\n",
        "  \n",
        "  Params:\n",
        "    Y_preds: scores obtained by the model which have to be converted to hard\n",
        "             labels\n",
        "    thr: threshold to be applied to the scores, element of (0, 1), if a score\n",
        "         is greater than thr it becomes a hard label with value 1, \n",
        "         0 otherwise\n",
        "  Retuns:\n",
        "    Y_preds_thr: hard labels obtained by thresholding Y_preds with thr\n",
        "  \"\"\"\n",
        "  Y_preds_thr = np.copy(Y_preds.numpy())\n",
        "  max_rows = Y_preds_thr.shape[0]\n",
        "  max_cols = Y_preds_thr.shape[1]\n",
        "  for i in range(max_rows):\n",
        "    new_row = np.array([1 if Y_preds_thr[i][j] > thr else 0 for j in range(max_cols)])\n",
        "    Y_preds_thr[i] = new_row\n",
        "  return Y_preds_thr\n",
        "\n",
        "def compute_macro_score(M_true, M_pred, score_func):\n",
        "  \"\"\"\n",
        "  Function needed to compute the macro aggregation of a scored function\n",
        "  over the different classes.\n",
        "\n",
        "  Params:\n",
        "    M_true: true labels needed to compute the scores\n",
        "    M_pred: predicted labels needed to compute the scores\n",
        "    score_func: scoring function to be computed\n",
        "  Returns:\n",
        "    macro: aggregation of the result of score_func computed over all the\n",
        "           labels.\n",
        "    scores: list of per-label score\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for i in range(M_true.shape[1]):\n",
        "      true = M_true[:, i]\n",
        "      pred = M_pred[:, i]\n",
        "      if score_func == accuracy_score:\n",
        "        scores.append(score_func(true, pred))\n",
        "      else: \n",
        "        scores.append(score_func(true, pred, zero_division=0))\n",
        "  macro = np.mean(scores)\n",
        "  return macro, scores\n",
        "  \n",
        "def support(true, pred, zero_division):\n",
        "  \"\"\"\n",
        "  Utility function to compute the support of the class labels,\n",
        "  pred and zero_division are dummy parameters needed to have conformity\n",
        "  with the sklearn functions to compute scores.\n",
        "\n",
        "  Params: \n",
        "    true: binary true labels for a single class for each example that are needed\n",
        "          to compute the support for the single class\n",
        "    pred: dummy parameter\n",
        "    zero_division: dummy parameter\n",
        "  Returns:\n",
        "    sum(true): the number of example for a single class (support)\n",
        "  \"\"\"\n",
        "  return sum(true)\n",
        "\n",
        "def print_report(classifier, loader, y_true, threshold, labels=label_list):\n",
        "  \"\"\"\n",
        "  Function needed to print the classification results given a classifier,\n",
        "  a dataset loader, true labels and a threshold. \n",
        "  The printed report includes macro accuracy, precision, recall and F1, as \n",
        "  well as per-class accuracy, precision, recall, F1 and support.\n",
        "\n",
        "  Params:\n",
        "    classifier: the model that has to be evaluated\n",
        "    loader: data-loader needed to feed the data to the classifier to get \n",
        "            predicted labels\n",
        "    y_true: true labels associated to the dataset associated to the loader\n",
        "    threshold: threshold for the conversion of the scores to hard labels,\n",
        "               check keep_above_thresh for further details\n",
        "    labels: ordered list of target labels. Defaults to the list extracted from\n",
        "            the dataset\n",
        "  \"\"\"\n",
        "\n",
        "  Y_preds = make_predictions(classifier, loader)\n",
        "  Y_preds_thr = keep_above_thresh(Y_preds.to('cpu'), threshold)\n",
        "\n",
        "  f1_macro, f1 = compute_macro_score(y_true, Y_preds_thr, f1_score)\n",
        "  acc_macro, acc = compute_macro_score(y_true, Y_preds_thr, accuracy_score)\n",
        "  prec_macro, prec = compute_macro_score(y_true, Y_preds_thr, precision_score)\n",
        "  rec_macro, rec = compute_macro_score(y_true, Y_preds_thr, recall_score)\n",
        "  _, sup = compute_macro_score(y_true, Y_preds_thr, support)\n",
        "\n",
        "  print(\"----- MACRO AVG. -----\")\n",
        "  print(f\"  F1-score:\\t{round(f1_macro,4)}\\n\\\n",
        "  Precision:\\t{round(prec_macro,4)}\\n\\\n",
        "  Recall:\\t{round(rec_macro,4)}\\n\\\n",
        "  Accuracy:\\t{round(acc_macro,4)}\")\n",
        "  print(\"----- PER-CLASS VALUES -----\")\n",
        "  print(\"  \\t\\t\\t\\tF1-score\\tPrecision\\tRecall\\t\\tAccuracy\\tSupport\")\n",
        "  for i in range(len(labels)):\n",
        "    print(\"  \" + labels[i]+\" \"*(len(max(labels, key=len))-len(labels[i])), end=\"\\t\")\n",
        "    print(f\"{round(f1[i],4)}\\t\\t{round(prec[i],4)}\\t\\t{round(rec[i],4)}\\t\\t{round(acc[i],4)}\\t\\t{sup[i]}\")"
      ],
      "metadata": {
        "id": "uU_qeLA6l7OE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe model\n",
        "The first model that was developed is a GloVe 100d embedding + two Bi-GRU layers\n",
        "That serves as an advanced baseline to perfom experiments for multi-label classification problems like the current one. \n",
        "It is still a baseline since it has a simple architecture, OOV are treated using zero-vectors, the hidden states of the Bi-GRU layers are initialized \n",
        "as zero-vectors and most importantly the model does not work with contextual information, but only with the semantics of the words. <br>\n",
        "Moreover an heavy preprocessing to the dataset is not applied except for lowercasing the arguments, tokenization and the addition of truncation and padding because the GloVe embeddings would return too many unmasked zero vectors. <br>\n",
        "About padding and truncation: the maximum allowed length is 35 which is \n",
        "slightly above the sum of the mean token length value for the premises and the\n",
        "conclusion. \n",
        "\n",
        "N.B.: the last dense layer has no activation for all the models, since the loss\n",
        "function applies it by guaranteeing numerical stability. Thus the output of the\n",
        "layer must be passed to a sigmoid function before converting it to labels."
      ],
      "metadata": {
        "id": "LosoIWWz_5e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained GloVe setup\n",
        "\n",
        "global_vectors = GloVe(name='6B', dim=100)\n",
        "\n",
        "# the current choice is to give an id to each word\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "TOU9N3-WJgn3",
        "outputId": "6d236141-5774-4fe0-edad-6ec6404af0c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:43, 5.28MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:16<00:00, 24181.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# these parameters are used both by the following function and by the \n",
        "# implementation of the GloVe model itself, thus are kept global\n",
        "max_words_emb = 35\n",
        "embed_len = 100\n",
        "\n",
        "# collate function where the Premises are tokenized and embedded in batches\n",
        "def vectorize_batch(batch):\n",
        "  \"\"\"\n",
        "  Collate function to preprocess the data for the GloVe model.\n",
        "  In particular it joins premises, stances and conclusions in the same string,\n",
        "  tokenizes, truncates and pads them and then converts each token to a GloVe\n",
        "  vector. Target labels are already one-hot encoded.\n",
        "\n",
        "  Params:\n",
        "    batch: batch of data to be preprocessed\n",
        "  Returns:\n",
        "    X_tensor: a tensor containing GloVe vectors of dimension 100, which has shape\n",
        "              (batch_size, max_words_emb, embed_len)\n",
        "    Y_tensor: a tensor containing labels, which has shape\n",
        "              (batch_size, num_classes)\n",
        "  \"\"\"\n",
        "  X = [elem[\"Premise\"] + \" \" + elem[\"Stance\"] + \" \" +elem[\"Conclusion\"] for elem in batch]\n",
        "  Y = [elem[\"labels\"] for elem in batch]\n",
        "  X = [tokenizer(x) for x in X]\n",
        "  X = [tokens+[\"\"] * (max_words_emb-len(tokens))  if len(tokens)<max_words_emb else tokens[:max_words_emb] for tokens in X]\n",
        "  X_tensor = torch.zeros(len(batch), max_words_emb, embed_len)\n",
        "  Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "  for i, tokens in enumerate(X):\n",
        "      X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
        "      Y_tensor[i] = Y[i]\n",
        "  return X_tensor, Y_tensor"
      ],
      "metadata": {
        "id": "0eFmzKrDbvlJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class EmbeddingClassifier(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the GloVe model.\n",
        "  Remark: max_words_emb, embed_len and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      super(EmbeddingClassifier, self).__init__() \n",
        "      \n",
        "      self.gru_layers = 2\n",
        "\n",
        "      self.gru = nn.GRU(input_size = embed_len,\n",
        "                        hidden_size = embed_len,\n",
        "                        num_layers = self.gru_layers,\n",
        "                        batch_first=True, \n",
        "                        bidirectional = True)\n",
        "      self.flatten = nn.Flatten(start_dim=1)\n",
        "      self.linear_1 = nn.Linear(max_words_emb*embed_len*2, 512)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.linear_2 = nn.Linear(512,128)\n",
        "      self.linear_3 = nn.Linear(128, num_classes)\n",
        "      \n",
        "              \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    \"\"\"\n",
        "    It is important to note that the initial hidden states of the GRU\n",
        "    layers are initialized with zero tensors.\n",
        "\n",
        "    The outcomes of the GRU layers are flattened and classified. \n",
        "    \"\"\"\n",
        "    h0 = torch.zeros(2*self.gru_layers,X_batch.shape[0], embed_len)\n",
        "    h0 = h0.to(device)\n",
        "    out, hn = self.gru(X_batch, h0)\n",
        "    out = self.flatten(out)\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_3(out)\n",
        "    return out\n",
        "\n",
        "# Function needed to compute the validation loss and the accuracy\n",
        "def compute_validation_loss(model, loss_fn, val_loader):\n",
        "  \"\"\"\n",
        "  Function computing and printing the loss on the validation set.\n",
        "  Params:\n",
        "    model: the model for which the loss must be computed and printed\n",
        "    loss_fn: the loss function to adopt\n",
        "    val_loader: dataloader for the validation set\n",
        "\n",
        "  Returns:\n",
        "    loss: the computed mean loss across the batch\n",
        "  \"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    losses = []\n",
        "    for X, Y in val_loader:\n",
        "      preds = model(X)\n",
        "      loss = loss_fn(preds, Y)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "    loss = torch.tensor(losses).mean()\n",
        "    print(\"Valid Loss : {:.3f}\".format(loss))\n",
        "  return loss\n",
        "\n",
        "\n",
        "# Training function\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name):\n",
        "  \"\"\"\n",
        "  Function for model training. If early stopping info is defined it saves the \n",
        "  last best models and eventually returns it, in case of early stopping.\n",
        "  In case early_stopping_info is not defined, the early stopping is not\n",
        "  applied.\n",
        "\n",
        "  Params:\n",
        "    model: the model that has to be trained\n",
        "    loss_fn: the loss function to adopt in order to perform the training\n",
        "    optimizer: the optimizer to be used for training\n",
        "    train_loader: the dataloader for the training dataset\n",
        "    val_loader: the dataloader for the validation dataset\n",
        "    epochs: the number of epochs for training\n",
        "    early_stopping_info: dictionary containing the parameters for the early stopping:\n",
        "                          - delta: min acceptable improvement in the validation loss\n",
        "                          - patience: number of epochs to wait for improvement\n",
        "    model_name: string containing the name of the model (used in order to save\n",
        "                the weights)\n",
        "  Returns:\n",
        "    model: the trained model\n",
        "  \"\"\"\n",
        "  patience_acc = 0\n",
        "  precedent_loss = np.Inf\n",
        "  model.train()\n",
        "  for i in range(1, epochs+1):\n",
        "      losses = []\n",
        "      for X, Y in tqdm(train_loader):\n",
        "\n",
        "          Y_preds = model(X)\n",
        "\n",
        "          loss = loss_fn(Y_preds, Y)\n",
        "          losses.append(loss.item())\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      loss = compute_validation_loss(model, loss_fn, val_loader)\n",
        "      print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "      if early_stopping_info != None:\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "            patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          precedent_loss = loss  \n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc >= early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"_best.pth\")           \n",
        "  return model\n"
      ],
      "metadata": {
        "id": "XHy7Zl7EK-FA"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training informations\n",
        "The training was performed considering a maximum of 50 epochs with the following parameters for early stopping: patience equal to 3 epochs and delta equal to 1e-4. Batch size, learning rate and number of parameters for the layers were tuned by hand considering the results on the validation set.\n",
        "In particular the following pools were considered:\n",
        "- batch_size in \\{16, 32, 64\\}\n",
        "- learning rate in \\{1e-2, 1e-3, 1e-4\\}\n",
        "- hidden size of the GRU layers in \\{100, 200\\}\n",
        "- neurons of the linear layers in \\{512, 256, 128\\}"
      ],
      "metadata": {
        "id": "ZOyMHpzEK0mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 1e-4\n",
        "batch_size = 32\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "embed_classifier = EmbeddingClassifier()\n",
        "optimizer = Adam(embed_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Construction of the Dataloaders for train and validation\n",
        "train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "\n",
        "\n",
        "embed_classifier.to(device)\n",
        "summary(embed_classifier, \n",
        "                input_data=next(iter(train_loader))[0],\n",
        "                device=device)\n"
      ],
      "metadata": {
        "id": "k4KSPSXAN6z0",
        "outputId": "6cdba138-e7fe-44f9-e361-32b99643e7d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "EmbeddingClassifier                      [32, 20]                  --\n",
              "├─GRU: 1-1                               [32, 35, 200]             302,400\n",
              "├─Flatten: 1-2                           [32, 7000]                --\n",
              "├─Linear: 1-3                            [32, 512]                 3,584,512\n",
              "├─ReLU: 1-4                              [32, 512]                 --\n",
              "├─Linear: 1-5                            [32, 128]                 65,664\n",
              "├─ReLU: 1-6                              [32, 128]                 --\n",
              "├─Linear: 1-7                            [32, 20]                  2,580\n",
              "==========================================================================================\n",
              "Total params: 3,955,156\n",
              "Trainable params: 3,955,156\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 455.58\n",
              "==========================================================================================\n",
              "Input size (MB): 0.45\n",
              "Forward/backward pass size (MB): 1.96\n",
              "Params size (MB): 15.82\n",
              "Estimated Total Size (MB): 18.23\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "embed_classifier = TrainModel(embed_classifier, loss_fn, optimizer, train_loader, val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"glove\")"
      ],
      "metadata": {
        "id": "Ws7o13y5P5o4",
        "outputId": "326876c3-a9cf-47ba-9ba7-fd500886fdc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.410\n",
            "Train Loss : 0.449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 36.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.407\n",
            "Train Loss : 0.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 52.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.397\n",
            "Train Loss : 0.407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.388\n",
            "Train Loss : 0.392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.380\n",
            "Train Loss : 0.380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 36.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.375\n",
            "Train Loss : 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.368\n",
            "Train Loss : 0.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.365\n",
            "Train Loss : 0.357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.364\n",
            "Train Loss : 0.351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 37.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.363\n",
            "Train Loss : 0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.363\n",
            "Train Loss : 0.342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.364\n",
            "Train Loss : 0.337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.364\n",
            "Train Loss : 0.333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(embed_classifier, val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "NsdbFRv1yrmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f2dcee-b8a0-419d-c6e4-db5194548db0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3213\n",
            "  Precision:\t0.3282\n",
            "  Recall:\t0.4286\n",
            "  Accuracy:\t0.7758\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.2723\t\t0.2214\t\t0.3537\t\t0.8726\t\t82\n",
            "  Self-direction: action    \t0.4715\t\t0.375\t\t0.6348\t\t0.6574\t\t293\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.9647\t\t43\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.9737\t\t32\n",
            "  Achievement               \t0.6043\t\t0.4922\t\t0.7824\t\t0.6943\t\t363\n",
            "  Power: dominance          \t0.287\t\t0.3333\t\t0.252\t\t0.8694\t\t127\n",
            "  Power: resources          \t0.3388\t\t0.6966\t\t0.2238\t\t0.8012\t\t277\n",
            "  Face                      \t0.0412\t\t0.25\t\t0.0225\t\t0.9236\t\t89\n",
            "  Security: personal        \t0.6253\t\t0.4852\t\t0.879\t\t0.5637\t\t504\n",
            "  Security: societal        \t0.6985\t\t0.5984\t\t0.8389\t\t0.7305\t\t453\n",
            "  Tradition                 \t0.3084\t\t0.2598\t\t0.3793\t\t0.8784\t\t87\n",
            "  Conformity: rules         \t0.4344\t\t0.3137\t\t0.7061\t\t0.5785\t\t279\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9515\t\t56\n",
            "  Humility                  \t0.0471\t\t0.6667\t\t0.0244\t\t0.9334\t\t82\n",
            "  Benevolence: caring       \t0.4076\t\t0.2818\t\t0.7368\t\t0.4651\t\t304\n",
            "  Benevolence: dependability\t0.1548\t\t0.169\t\t0.1429\t\t0.7847\t\t168\n",
            "  Universalism: concern     \t0.6164\t\t0.4928\t\t0.8229\t\t0.5818\t\t497\n",
            "  Universalism: nature      \t0.4279\t\t0.3262\t\t0.6216\t\t0.8989\t\t74\n",
            "  Universalism: tolerance   \t0.4372\t\t0.4476\t\t0.4273\t\t0.9006\t\t110\n",
            "  Universalism: objectivity \t0.2539\t\t0.154\t\t0.7241\t\t0.493\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT + LSTM model (transfer learning)\n",
        "The following model is proposed to enhance the GloVe model through the following changes:\n",
        "- Usage of contextual frozen Bert encoding instead of GloVe embeddings\n",
        "(changes were performed in the collate)\n",
        "- Substitution of the GRU layers with LSTM layers, which are more complex. \n",
        "- Meaningful initialization of the LSTM hidden and cell states using\n",
        "the pooler-output of the BERT encoding of an argument passed to two different dense layers (ideally the pooler-output represents the encoding of the \\[CLS\\] token which is at the beginning of every argument and contains general informations about semantics of the whole sentence).\n",
        "- Classification focussed on the concatenation of the output cell states of the LSTM layers, rather than the encoding of the whole sentence (concatenation of the hidden states).\n",
        "This reduces the number of required neurons and elaborates a tensor that retains the most important semantic informations on the sentence."
      ],
      "metadata": {
        "id": "H7VPAGgCNE7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection of the BERT model\n",
        "For this task we used the bert-based-uncased model and tokenizer. \n",
        "We also decided to try different variations of BERT (ELECTRA, ALBERT, Funnel Transformer, ...), but we didn't obtain remarkable improvements."
      ],
      "metadata": {
        "id": "wVQlUUX3PSaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import of the BERT tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model.to(device)\n",
        "print(\"Bert loaded\")"
      ],
      "metadata": {
        "id": "tt17dYqothM3",
        "outputId": "ec1d8bc2-4cae-49cd-a3a5-a9949ffcf41c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bert loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice for the maximum length of the BERT encodings is 70 because\n",
        "it is slightly above the sum of the 90-th percentile of the lengths of premises, stances and conclusions.\n",
        "It is longer with respect to the maximum number of words for the GloVe model,\n",
        "since BERT-encoded vectors are much more dense."
      ],
      "metadata": {
        "id": "R8L68FX3Q8MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words_bert = 70\n",
        "# collate function that uses the tokenizer relative to the bert pretrained model\n",
        "def bert_vectorize_batch(batch):\n",
        "  \"\"\"\n",
        "  Collate function to preprocess the data for the BERT-based models.\n",
        "  In particular it joins premises, stances and conclusions in the same string,\n",
        "  separated by the [SEP] token.\n",
        "  Using the appropriate tokenizer, arguments are tokenized, truncated and padded.\n",
        "  Target labels are already one-hot encoded.\n",
        "\n",
        "  Params:\n",
        "    batch: batch of data to be preprocessed\n",
        "  Returns:\n",
        "    X_tensor: a tensor containing a torch tensor containing the input_ids, the token_type_ids and the\n",
        "              attention_mask for each example of the batch, which has shape:\n",
        "              (3, batch_size, max_words_bert)\n",
        "    Y_tensor: a tensor containing labels, which has shape\n",
        "              (batch_size, num_classes)\n",
        "  \"\"\"\n",
        "  X = [elem[\"Premise\"] + \" [SEP] \" + elem[\"Stance\"] + \" [SEP] \" + elem[\"Conclusion\"] for elem in batch]\n",
        "  Y = [elem[\"labels\"] for elem in batch]\n",
        "  X = bert_tokenizer(X, padding=\"max_length\", truncation=\"longest_first\", return_tensors = \"pt\", max_length = max_words_bert) \n",
        "  Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "  for i, tokens in enumerate(Y):    \n",
        "      Y_tensor[i] = Y[i]\n",
        "  X_tensor = torch.stack([X[\"input_ids\"], X[\"token_type_ids\"], X[\"attention_mask\"]])\n",
        "\n",
        "  return X_tensor, Y_tensor\n",
        "\n",
        "train_dataset = whole_dataset[\"train\"]\n",
        "val_dataset = whole_dataset[\"val\"] \n",
        "test_dataset = whole_dataset[\"test\"] "
      ],
      "metadata": {
        "id": "gCwN1D6evfAF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class BertLSTM(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the BERT + LSTM model.\n",
        "  Remark: max_words_bert and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self, bert_model):\n",
        "    # the single parameter of this init function is the bert model \n",
        "    # that has to be used for transfer learning\n",
        "    super(BertLSTM, self).__init__() \n",
        "    self.lstm_layers = 2\n",
        "    self.lstm_hs = 128 # hidden size of the lstm\n",
        "    bert_hidden_size = bert_model.config.hidden_size\n",
        "\n",
        "    # freezing the parameters for the BERT model\n",
        "    self.bert_model = bert_model\n",
        "    for param in self.bert_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=bert_hidden_size,\n",
        "                        hidden_size=self.lstm_hs,\n",
        "                        num_layers=self.lstm_layers ,\n",
        "                        batch_first=True,\n",
        "                        bidirectional=True)\n",
        "    self.reducer_c0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "    self.reducer_h0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "    self.linear_1 = nn.Linear(self.lstm_hs*2*self.lstm_layers, self.lstm_hs)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(self.lstm_hs, num_classes) # since the dimensions\n",
        "    # are already small there is no need for a third linear layer\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    #Remark: The LSTM layer does not contain the encoding of the [CLS] token\n",
        "    #since it is used to initialize the hidden and cell states.\n",
        "    out = self.bert_model(input_ids=X_batch[0], token_type_ids = X_batch[1], attention_mask = X_batch[2])\n",
        "    cell = self.reducer_c0(out.pooler_output)\n",
        "    hidden = self.reducer_h0(out.pooler_output)\n",
        "    out = out.last_hidden_state[:,1:,:]\n",
        "    c0 = torch.stack([cell,cell,cell,cell]) \n",
        "    h0 = torch.stack([hidden, hidden, hidden, hidden])\n",
        "    out_lstm, hc_n  = self.lstm(out, (h0, c0))\n",
        "    c_n = hc_n[1].permute(1, 0, 2) # permutation in order to obtain the batch \n",
        "                                   # size dimension first\n",
        "    out = torch.cat([c_n[:,0,:], c_n[:,1,:]], 1) # concatenation of the cell states\n",
        "    out2 = torch.cat([c_n[:,2,:], c_n[:,3,:]], 1)\n",
        "    out = torch.cat([out, out2], 1)\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "oEb_5p623uWU"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training informations\n",
        "The training was performed considering a maximum of 50 epochs with the following parameters for early stopping: patience equal to 3 epochs and delta equal to 1e-4. Batch size, learning rate and number of parameters for the layers were tuned by hand considering the results on the validation set.\n",
        "In particular the following pools were considered:\n",
        "- batch_size in \\{16, 32, 64\\}\n",
        "- learning rate in \\{1e-2, 1e-3, 1e-4\\}\n",
        "- hidden size of the LSTM layers in \\{128, 256, 512\\}\n",
        "- neurons of the linear layers in \\{256, 128\\}"
      ],
      "metadata": {
        "id": "W4rjn0z2TTTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "prebert_classifier = BertLSTM(bert_model)\n",
        "optimizer = Adam(prebert_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "bert_train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "prebert_classifier.to(device)\n",
        "summary(prebert_classifier, \n",
        "                input_data=next(iter(bert_train_loader))[0],\n",
        "                device=device)"
      ],
      "metadata": {
        "id": "1sU40iio3-4l",
        "outputId": "7b6a55fa-689e-4025-b21a-91ff34ee9cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "BertLSTM                                                [32, 20]                  --\n",
              "├─BertModel: 1-1                                        [32, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [32, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [32, 70, 768]             (23,440,896)\n",
              "│    │    └─Embedding: 3-2                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              (393,216)\n",
              "│    │    └─LayerNorm: 3-4                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Dropout: 3-5                                [32, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [32, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        (85,054,464)\n",
              "│    └─BertPooler: 2-3                                  [32, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [32, 768]                 (590,592)\n",
              "│    │    └─Tanh: 3-8                                   [32, 768]                 --\n",
              "├─Linear: 1-2                                           [32, 128]                 98,432\n",
              "├─Linear: 1-3                                           [32, 128]                 98,432\n",
              "├─LSTM: 1-4                                             [32, 69, 256]             1,314,816\n",
              "├─Linear: 1-5                                           [32, 128]                 65,664\n",
              "├─ReLU: 1-6                                             [32, 128]                 --\n",
              "├─Linear: 1-7                                           [32, 20]                  2,580\n",
              "=========================================================================================================\n",
              "Total params: 111,062,164\n",
              "Trainable params: 1,579,924\n",
              "Non-trainable params: 109,482,240\n",
              "Total mult-adds (G): 6.40\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 1863.20\n",
              "Params size (MB): 444.25\n",
              "Estimated Total Size (MB): 2307.50\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "prebert_classifier = TrainModel(prebert_classifier, loss_fn, optimizer, bert_train_loader, bert_val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"bertencoder\")"
      ],
      "metadata": {
        "id": "qr86sx6J4cJY",
        "outputId": "f6fc3f44-ba51-4657-ffcb-82de60985268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:23<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.387\n",
            "Train Loss : 0.398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:24<00:00,  5.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.368\n",
            "Train Loss : 0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:22<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.363\n",
            "Train Loss : 0.327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:23<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.364\n",
            "Train Loss : 0.310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:23<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.368\n",
            "Train Loss : 0.295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:22<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.384\n",
            "Train Loss : 0.282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:23<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.398\n",
            "Train Loss : 0.268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(prebert_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "n_wI6jIOW4xo",
        "outputId": "2fb1439e-1c6b-40dd-bc4d-7d8fe86ef08f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3571\n",
            "  Precision:\t0.3829\n",
            "  Recall:\t0.441\n",
            "  Accuracy:\t0.7911\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.2727\t\t0.2174\t\t0.3659\t\t0.8685\t\t82\n",
            "  Self-direction: action    \t0.4597\t\t0.4026\t\t0.5358\t\t0.6968\t\t293\n",
            "  Stimulation               \t0.0769\t\t0.2222\t\t0.0465\t\t0.9606\t\t43\n",
            "  Hedonism                  \t0.1667\t\t0.75\t\t0.0938\t\t0.9753\t\t32\n",
            "  Achievement               \t0.6268\t\t0.5305\t\t0.7658\t\t0.728\t\t363\n",
            "  Power: dominance          \t0.1765\t\t0.3488\t\t0.1181\t\t0.885\t\t127\n",
            "  Power: resources          \t0.5492\t\t0.5777\t\t0.5235\t\t0.8044\t\t277\n",
            "  Face                      \t0.1905\t\t0.18\t\t0.2022\t\t0.8743\t\t89\n",
            "  Security: personal        \t0.6835\t\t0.556\t\t0.8869\t\t0.6598\t\t504\n",
            "  Security: societal        \t0.6795\t\t0.6604\t\t0.6998\t\t0.7543\t\t453\n",
            "  Tradition                 \t0.2635\t\t0.275\t\t0.2529\t\t0.8989\t\t87\n",
            "  Conformity: rules         \t0.4282\t\t0.2796\t\t0.914\t\t0.4404\t\t279\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9532\t\t56\n",
            "  Humility                  \t0.0235\t\t0.3333\t\t0.0122\t\t0.9318\t\t82\n",
            "  Benevolence: caring       \t0.272\t\t0.3736\t\t0.2138\t\t0.7141\t\t304\n",
            "  Benevolence: dependability\t0.2762\t\t0.1696\t\t0.744\t\t0.4618\t\t168\n",
            "  Universalism: concern     \t0.6507\t\t0.5282\t\t0.8471\t\t0.6286\t\t497\n",
            "  Universalism: nature      \t0.5517\t\t0.48\t\t0.6486\t\t0.9359\t\t74\n",
            "  Universalism: tolerance   \t0.4718\t\t0.5412\t\t0.4182\t\t0.9154\t\t110\n",
            "  Universalism: objectivity \t0.3229\t\t0.2319\t\t0.531\t\t0.7346\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT fine tuning\n",
        "The following model is simply a fine tuned version of the BERT model on the reference dataset and it is proposed as an alternative to the previous models.\n",
        "In particular a similar model has been proposed by the authors of the dataset, hence it can be used as a reference point, since the datasets are not exacly equal.\n",
        "\n",
        "The architecture is a simple fine tuning of BERT followed by two linear layers which elaborate its pooler-output and reduce its dimension to num_classes.\n",
        "It is a common architecture that employs BERT in order to perform multi-label text classification."
      ],
      "metadata": {
        "id": "lzk-QUXGT6F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class FineTunedBert(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the model that allows to fine-tune BERT for this task.\n",
        "  Remark: max_words_bert and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self, bert_model):\n",
        "    # the single parameter of this init function is the bert model \n",
        "    # that has to be used for fine-tuning\n",
        "    super(FineTunedBert, self).__init__() \n",
        "    self.bert_model = bert_model\n",
        "    for param in self.bert_model.parameters():\n",
        "        param.requires_grad = True\n",
        "    bert_hidden_size = bert_model.config.hidden_size\n",
        "    self.linear_1 = nn.Linear(bert_hidden_size, bert_hidden_size//2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(bert_hidden_size//2, num_classes)\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    out = self.bert_model(input_ids=X_batch[0], \n",
        "                          token_type_ids = X_batch[1],\n",
        "                          attention_mask = X_batch[2])\n",
        "\n",
        "    out = out.last_hidden_state[:,0,:]\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    return out\n",
        "\n",
        "# Training function\n",
        "def finetune_bert(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name, scheduler):\n",
        "  \"\"\"\n",
        "  Training function for the fine-tuning of BERT. if arly_stopping_info info is set\n",
        "  to None, early stopping is not performed.\n",
        "  Params:\n",
        "    model: the model that has to be fine-tuned\n",
        "    loss_fn: the loss function to adopt in order to perform the training\n",
        "    optimizer: the optimizer to be used for training\n",
        "    train_loader: the dataloader for the training dataset\n",
        "    val_loader: the dataloader for the validation dataset\n",
        "    epochs: the number of epochs for training\n",
        "    early_stopping_info: dictionary containing the parameters for the early stopping:\n",
        "                          - delta: min acceptable improvement in the validation loss\n",
        "                          - patience: number of epochs to wait for improvement\n",
        "    model_name: string containing the name of the model (used in order to save\n",
        "                the weights)\n",
        "    scheduler: the learning rate scheduler to be applied (it is a step scheduler)\n",
        "  Returns:\n",
        "    model: the trained model\n",
        "  \"\"\"\n",
        "  patience_acc = 0\n",
        "  precedent_loss = np.Inf\n",
        "  model.train()\n",
        "  for i in range(1, epochs+1):\n",
        "      losses = []\n",
        "      for X, Y in tqdm(train_loader):\n",
        "          model.zero_grad()\n",
        "          Y_preds = model(X)\n",
        "          loss = loss_fn(Y_preds, Y)\n",
        "          losses.append(loss.item())\n",
        "\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "\n",
        "      loss = compute_validation_loss(model, loss_fn, val_loader)\n",
        "      print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "      if early_stopping_info != None:\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "            patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          precedent_loss = loss\n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc > early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"best.pth\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "L2AFayf470lu"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_unfrozen = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model_unfrozen.to(device)\n",
        "print(\"reloaded\")"
      ],
      "metadata": {
        "outputId": "f5ac6aef-931d-4040-a36c-06ea8535910f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLK5mrMjAMAj"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training informations\n",
        "The training recipe and the model were adapted from the following tutorial:<br>\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
        "<br>\n",
        "As suggested in the tutorial the AdamW optimizer was used, the gradients were clipped to 1 and hyperparameters were drawn from the following pools:\n",
        "- batch_size in \\{16, 32\\}\n",
        "- learning rate in {5e-5, 3e-5, 2e-5}\n",
        "- number of epochs in \\{2, 3, 4\\}, but also 5 and 6 were tested.\n",
        "- the number of neurons of the linear layers are obtained by progressively halving the output of the BERT model"
      ],
      "metadata": {
        "id": "FiGEQaXlZgwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 3\n",
        "learning_rate = 5e-5\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "finetune_classifier = FineTunedBert(bert_model_unfrozen)\n",
        "optimizer = AdamW(finetune_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
        "\n",
        "\n",
        "bert_train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(val_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(test_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
        "                                            num_training_steps=len(bert_train_loader)*epochs)\n",
        "\n",
        "finetune_classifier.to(device)\n",
        "summary(finetune_classifier, input_data=next(iter(bert_train_loader))[0], device=device, dtypes = [torch.int]*3)"
      ],
      "metadata": {
        "id": "v1bsrMwW_KYH",
        "outputId": "a89cb0a7-4a75-486e-e1de-0789bcae4f88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "FineTunedBert                                           [16, 20]                  --\n",
              "├─BertModel: 1-1                                        [16, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [16, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [16, 70, 768]             23,440,896\n",
              "│    │    └─Embedding: 3-2                              [16, 70, 768]             1,536\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              393,216\n",
              "│    │    └─LayerNorm: 3-4                              [16, 70, 768]             1,536\n",
              "│    │    └─Dropout: 3-5                                [16, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [16, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        85,054,464\n",
              "│    └─BertPooler: 2-3                                  [16, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [16, 768]                 590,592\n",
              "│    │    └─Tanh: 3-8                                   [16, 768]                 --\n",
              "├─Linear: 1-2                                           [16, 384]                 295,296\n",
              "├─ReLU: 1-3                                             [16, 384]                 --\n",
              "├─Linear: 1-4                                           [16, 20]                  7,700\n",
              "=========================================================================================================\n",
              "Total params: 109,785,236\n",
              "Trainable params: 109,785,236\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.75\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.03\n",
              "Forward/backward pass size (MB): 929.55\n",
              "Params size (MB): 439.14\n",
              "Estimated Total Size (MB): 1368.72\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "finetune_classifier = finetune_bert(finetune_classifier, \n",
        "                                   loss_fn, optimizer,\n",
        "                                   bert_train_loader,\n",
        "                                   bert_val_loader,\n",
        "                                   epochs,\n",
        "                                   None, \n",
        "                                   \"finebert\", scheduler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Bka5d2uStJ",
        "outputId": "7103c6be-2722-428d-b985-4b42eae9ee96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:04<00:00,  4.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINETUNED BERT:\")\n",
        "print_report(finetune_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fafe775-8858-48cb-8816-411c23f8f5f1",
        "id": "igiHgAFsvifc"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINETUNED BERT:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.4132\n",
            "  Precision:\t0.4661\n",
            "  Recall:\t0.4302\n",
            "  Accuracy:\t0.8421\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3278\t\t0.2258\t\t0.5976\t\t0.8348\t\t82\n",
            "  Self-direction: action    \t0.5423\t\t0.5014\t\t0.5904\t\t0.7601\t\t293\n",
            "  Stimulation               \t0.1455\t\t0.3333\t\t0.093\t\t0.9614\t\t43\n",
            "  Hedonism                  \t0.1538\t\t0.4286\t\t0.0938\t\t0.9729\t\t32\n",
            "  Achievement               \t0.629\t\t0.5406\t\t0.7521\t\t0.7354\t\t363\n",
            "  Power: dominance          \t0.2513\t\t0.3472\t\t0.1969\t\t0.8776\t\t127\n",
            "  Power: resources          \t0.6296\t\t0.6074\t\t0.6534\t\t0.825\t\t277\n",
            "  Face                      \t0.1154\t\t0.4\t\t0.0674\t\t0.9244\t\t89\n",
            "  Security: personal        \t0.7015\t\t0.6248\t\t0.7996\t\t0.7182\t\t504\n",
            "  Security: societal        \t0.7069\t\t0.7031\t\t0.7108\t\t0.7806\t\t453\n",
            "  Tradition                 \t0.3129\t\t0.3833\t\t0.2644\t\t0.917\t\t87\n",
            "  Conformity: rules         \t0.5375\t\t0.4925\t\t0.5914\t\t0.7666\t\t279\n",
            "  Conformity: interpersonal \t0.0656\t\t0.4\t\t0.0357\t\t0.9532\t\t56\n",
            "  Humility                  \t0.1887\t\t0.4167\t\t0.122\t\t0.9293\t\t82\n",
            "  Benevolence: caring       \t0.4351\t\t0.4149\t\t0.4572\t\t0.7034\t\t304\n",
            "  Benevolence: dependability\t0.2684\t\t0.2406\t\t0.3036\t\t0.7716\t\t168\n",
            "  Universalism: concern     \t0.6679\t\t0.6042\t\t0.7465\t\t0.6968\t\t497\n",
            "  Universalism: nature      \t0.7943\t\t0.8358\t\t0.7568\t\t0.9762\t\t74\n",
            "  Universalism: tolerance   \t0.4724\t\t0.5281\t\t0.4273\t\t0.9137\t\t110\n",
            "  Universalism: objectivity \t0.3175\t\t0.2941\t\t0.3448\t\t0.8233\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the models\n",
        "The models are evalueted both on out test split (original validation split) and\n",
        "on the Chinese dataset split.\n",
        "The reference evaluation scores are the macro F1s, but we also provide macro inter-class precision, recall and accuracy.\n",
        "We also tuned the threshold needed to obtain hard labels. The default should be 0.5, but we decided to lower it to 0.25 in order to sacrifice a bit of precision and gain an improvement to the recall and thus obtain a better F1 score. \n",
        "Since the threshold is an hyperparameter of the model, tuning it is not a way to artifically increase F1-scores."
      ],
      "metadata": {
        "id": "U_pijllXe9j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(embed_classifier, test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzg9AFc-fsQj",
        "outputId": "2cf1f330-eab9-42b3-a493-b02837d26ca4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3139\n",
            "  Precision:\t0.2954\n",
            "  Recall:\t0.3992\n",
            "  Accuracy:\t0.7764\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3063\t\t0.3398\t\t0.2789\t\t0.8328\t\t251\n",
            "  Self-direction: action    \t0.4683\t\t0.3797\t\t0.6109\t\t0.6371\t\t496\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.9272\t\t138\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.9457\t\t103\n",
            "  Achievement               \t0.5427\t\t0.4493\t\t0.6852\t\t0.6498\t\t575\n",
            "  Power: dominance          \t0.2443\t\t0.3265\t\t0.1951\t\t0.8956\t\t164\n",
            "  Power: resources          \t0.3148\t\t0.4048\t\t0.2576\t\t0.9219\t\t132\n",
            "  Face                      \t0.0292\t\t0.2857\t\t0.0154\t\t0.9299\t\t130\n",
            "  Security: personal        \t0.6615\t\t0.5238\t\t0.8972\t\t0.6324\t\t759\n",
            "  Security: societal        \t0.5528\t\t0.4514\t\t0.7131\t\t0.7031\t\t488\n",
            "  Tradition                 \t0.343\t\t0.3869\t\t0.3081\t\t0.8929\t\t172\n",
            "  Conformity: rules         \t0.4454\t\t0.3298\t\t0.6857\t\t0.5902\t\t455\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9662\t\t60\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.9293\t\t127\n",
            "  Benevolence: caring       \t0.5226\t\t0.3941\t\t0.7757\t\t0.5269\t\t633\n",
            "  Benevolence: dependability\t0.1872\t\t0.1748\t\t0.2015\t\t0.7526\t\t268\n",
            "  Universalism: concern     \t0.5697\t\t0.437\t\t0.818\t\t0.5522\t\t687\n",
            "  Universalism: nature      \t0.5231\t\t0.5113\t\t0.5354\t\t0.9346\t\t127\n",
            "  Universalism: tolerance   \t0.1829\t\t0.2672\t\t0.139\t\t0.8539\t\t223\n",
            "  Universalism: objectivity \t0.3836\t\t0.2462\t\t0.8679\t\t0.4541\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(prebert_classifier, bert_test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De3leoMYfsJj",
        "outputId": "27c22497-6316-41db-e9aa-9df21b6f5982"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3739\n",
            "  Precision:\t0.3769\n",
            "  Recall:\t0.4412\n",
            "  Accuracy:\t0.7907\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.4085\t\t0.3686\t\t0.4582\t\t0.8244\t\t251\n",
            "  Self-direction: action    \t0.4343\t\t0.4352\t\t0.4335\t\t0.7046\t\t496\n",
            "  Stimulation               \t0.198\t\t0.3125\t\t0.1449\t\t0.9146\t\t138\n",
            "  Hedonism                  \t0.3467\t\t0.5532\t\t0.2524\t\t0.9483\t\t103\n",
            "  Achievement               \t0.5982\t\t0.4954\t\t0.7548\t\t0.6925\t\t575\n",
            "  Power: dominance          \t0.201\t\t0.4667\t\t0.128\t\t0.9119\t\t164\n",
            "  Power: resources          \t0.3521\t\t0.3481\t\t0.3561\t\t0.9088\t\t132\n",
            "  Face                      \t0.1308\t\t0.1308\t\t0.1308\t\t0.8808\t\t130\n",
            "  Security: personal        \t0.7019\t\t0.578\t\t0.8933\t\t0.6962\t\t759\n",
            "  Security: societal        \t0.6271\t\t0.6377\t\t0.6168\t\t0.8112\t\t488\n",
            "  Tradition                 \t0.4057\t\t0.3989\t\t0.4128\t\t0.8903\t\t172\n",
            "  Conformity: rules         \t0.4513\t\t0.2999\t\t0.9121\t\t0.4678\t\t455\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9684\t\t60\n",
            "  Humility                  \t0.0145\t\t0.0909\t\t0.0079\t\t0.9283\t\t127\n",
            "  Benevolence: caring       \t0.518\t\t0.5364\t\t0.5008\t\t0.6888\t\t633\n",
            "  Benevolence: dependability\t0.2769\t\t0.1757\t\t0.653\t\t0.5179\t\t268\n",
            "  Universalism: concern     \t0.5778\t\t0.4424\t\t0.8326\t\t0.5591\t\t687\n",
            "  Universalism: nature      \t0.5897\t\t0.6449\t\t0.5433\t\t0.9494\t\t127\n",
            "  Universalism: tolerance   \t0.1913\t\t0.2705\t\t0.148\t\t0.8528\t\t223\n",
            "  Universalism: objectivity \t0.4552\t\t0.352\t\t0.6442\t\t0.6983\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(finetune_classifier, bert_test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szR1bBY3fr_a",
        "outputId": "031ac239-1a9a-48fd-98d7-75c2ae109a38"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.4131\n",
            "  Precision:\t0.4625\n",
            "  Recall:\t0.4345\n",
            "  Accuracy:\t0.8358\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.4906\t\t0.3858\t\t0.6733\t\t0.8149\t\t251\n",
            "  Self-direction: action    \t0.5327\t\t0.4965\t\t0.5746\t\t0.7363\t\t496\n",
            "  Stimulation               \t0.2688\t\t0.5208\t\t0.1812\t\t0.9283\t\t138\n",
            "  Hedonism                  \t0.2857\t\t0.5405\t\t0.1942\t\t0.9473\t\t103\n",
            "  Achievement               \t0.6203\t\t0.5317\t\t0.7443\t\t0.7236\t\t575\n",
            "  Power: dominance          \t0.2902\t\t0.4066\t\t0.2256\t\t0.9045\t\t164\n",
            "  Power: resources          \t0.4431\t\t0.3731\t\t0.5455\t\t0.9045\t\t132\n",
            "  Face                      \t0.0795\t\t0.2857\t\t0.0462\t\t0.9267\t\t130\n",
            "  Security: personal        \t0.7376\t\t0.6493\t\t0.8538\t\t0.7569\t\t759\n",
            "  Security: societal        \t0.6181\t\t0.5737\t\t0.6701\t\t0.7869\t\t488\n",
            "  Tradition                 \t0.4203\t\t0.5041\t\t0.3605\t\t0.9098\t\t172\n",
            "  Conformity: rules         \t0.5261\t\t0.5433\t\t0.5099\t\t0.7795\t\t455\n",
            "  Conformity: interpersonal \t0.0923\t\t0.6\t\t0.05\t\t0.9689\t\t60\n",
            "  Humility                  \t0.0272\t\t0.1\t\t0.0157\t\t0.9246\t\t127\n",
            "  Benevolence: caring       \t0.5844\t\t0.5231\t\t0.6619\t\t0.6857\t\t633\n",
            "  Benevolence: dependability\t0.2746\t\t0.2422\t\t0.3172\t\t0.7632\t\t268\n",
            "  Universalism: concern     \t0.6339\t\t0.5387\t\t0.77\t\t0.6777\t\t687\n",
            "  Universalism: nature      \t0.6468\t\t0.7037\t\t0.5984\t\t0.9562\t\t127\n",
            "  Universalism: tolerance   \t0.2286\t\t0.315\t\t0.1794\t\t0.8576\t\t223\n",
            "  Universalism: objectivity \t0.461\t\t0.4156\t\t0.5175\t\t0.7632\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "bert_chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))"
      ],
      "metadata": {
        "id": "RjbLllyCSzCT"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(embed_classifier, chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "62tEI5umoyte",
        "outputId": "defac49f-7600-4591-d31a-90d371a0078c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.1647\n",
            "  Precision:\t0.2646\n",
            "  Recall:\t0.1446\n",
            "  Accuracy:\t0.8745\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.0\t\t0.0\t\t0.0\t\t0.88\t\t6\n",
            "  Self-direction: action    \t0.2667\t\t0.5\t\t0.1818\t\t0.89\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Achievement               \t0.481\t\t0.475\t\t0.4872\t\t0.59\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Power: resources          \t0.3529\t\t0.4\t\t0.3158\t\t0.78\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.4762\t\t0.4545\t\t0.5\t\t0.67\t\t30\n",
            "  Security: societal        \t0.3462\t\t0.4286\t\t0.2903\t\t0.66\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.125\t\t1.0\t\t0.0667\t\t0.86\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.1429\t\t0.5\t\t0.0833\t\t0.88\t\t12\n",
            "  Benevolence: dependability\t0.0\t\t0.0\t\t0.0\t\t0.97\t\t3\n",
            "  Universalism: concern     \t0.4545\t\t0.4348\t\t0.4762\t\t0.76\t\t21\n",
            "  Universalism: nature      \t0.4615\t\t0.6\t\t0.375\t\t0.93\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Universalism: objectivity \t0.1875\t\t0.5\t\t0.1154\t\t0.74\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(prebert_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "o9mxpo4jorh4",
        "outputId": "75823938-6387-4710-d7cd-829370a133a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.2551\n",
            "  Precision:\t0.2188\n",
            "  Recall:\t0.3798\n",
            "  Accuracy:\t0.8035\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.5556\t\t0.4167\t\t0.8333\t\t0.92\t\t6\n",
            "  Self-direction: action    \t0.2979\t\t0.1944\t\t0.6364\t\t0.67\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Achievement               \t0.6\t\t0.4444\t\t0.9231\t\t0.52\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.9\t\t1\n",
            "  Power: resources          \t0.375\t\t0.2459\t\t0.7895\t\t0.5\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.495\t\t0.3521\t\t0.8333\t\t0.49\t\t30\n",
            "  Security: societal        \t0.4719\t\t0.3621\t\t0.6774\t\t0.53\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.3448\t\t0.3571\t\t0.3333\t\t0.81\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.4167\t\t0.4167\t\t0.4167\t\t0.86\t\t12\n",
            "  Benevolence: dependability\t0.0541\t\t0.0294\t\t0.3333\t\t0.65\t\t3\n",
            "  Universalism: concern     \t0.6154\t\t0.5161\t\t0.7619\t\t0.8\t\t21\n",
            "  Universalism: nature      \t0.3636\t\t0.6667\t\t0.25\t\t0.93\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Universalism: objectivity \t0.5122\t\t0.375\t\t0.8077\t\t0.6\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(finetune_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "l8nyZS91oqwE",
        "outputId": "0ce7e5b4-01af-424a-8a7f-542d21c8ec6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.2712\n",
            "  Precision:\t0.2211\n",
            "  Recall:\t0.3944\n",
            "  Accuracy:\t0.836\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.375\t\t0.2308\t\t1.0\t\t0.8\t\t6\n",
            "  Self-direction: action    \t0.36\t\t0.2308\t\t0.8182\t\t0.68\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t0\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t2\n",
            "  Achievement               \t0.6598\t\t0.5517\t\t0.8205\t\t0.67\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Power: resources          \t0.4314\t\t0.3438\t\t0.5789\t\t0.71\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t1\n",
            "  Security: personal        \t0.5412\t\t0.4182\t\t0.7667\t\t0.61\t\t30\n",
            "  Security: societal        \t0.4444\t\t0.3902\t\t0.5161\t\t0.6\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.4324\t\t0.3636\t\t0.5333\t\t0.79\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.3158\t\t0.2308\t\t0.5\t\t0.74\t\t12\n",
            "  Benevolence: dependability\t0.0952\t\t0.0556\t\t0.3333\t\t0.81\t\t3\n",
            "  Universalism: concern     \t0.6154\t\t0.5161\t\t0.7619\t\t0.8\t\t21\n",
            "  Universalism: nature      \t0.7368\t\t0.6364\t\t0.875\t\t0.95\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.97\t\t2\n",
            "  Universalism: objectivity \t0.4167\t\t0.4545\t\t0.3846\t\t0.72\t\t26\n"
          ]
        }
      ]
    }
  ]
}