{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23345898340340b68a62dd156a59a3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9957fecd4c04e6cbf458d9372bf4bf4",
              "IPY_MODEL_1e8711382d924dc5a136c957432f8752",
              "IPY_MODEL_f1e7b518a27b428596e5fd0f7cb04da4"
            ],
            "layout": "IPY_MODEL_6352c96eee9f4462987b419cd0aa8892"
          }
        },
        "b9957fecd4c04e6cbf458d9372bf4bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef688fba29549ac9797a90dc164847a",
            "placeholder": "​",
            "style": "IPY_MODEL_d344b04f8033490dbf2f61daada4d7d0",
            "value": "100%"
          }
        },
        "1e8711382d924dc5a136c957432f8752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f1f0de33b2f411e91e88bd1ba55c134",
            "max": 4176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26a1d8455be64f858ee1eb20c55c894b",
            "value": 4176
          }
        },
        "f1e7b518a27b428596e5fd0f7cb04da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e916a25e1c854dbbb59a75789f048130",
            "placeholder": "​",
            "style": "IPY_MODEL_76d428957e3740afac8c7f10590d1afd",
            "value": " 4176/4176 [00:08&lt;00:00, 542.45ex/s]"
          }
        },
        "6352c96eee9f4462987b419cd0aa8892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef688fba29549ac9797a90dc164847a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d344b04f8033490dbf2f61daada4d7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f1f0de33b2f411e91e88bd1ba55c134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a1d8455be64f858ee1eb20c55c894b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e916a25e1c854dbbb59a75789f048130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d428957e3740afac8c7f10590d1afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c7a692d88ce4df2872462e244424364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0012279b1fa449f8ba47dc1076702d9",
              "IPY_MODEL_efc7f3f024e24f048c71f7e2b513e5a0",
              "IPY_MODEL_3be8ef31e0c34a39a4f48754b90cbf46"
            ],
            "layout": "IPY_MODEL_750a8d92d96e42f29bad8734f502cd7f"
          }
        },
        "a0012279b1fa449f8ba47dc1076702d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b02d726cd444a68557e4503093e8d1",
            "placeholder": "​",
            "style": "IPY_MODEL_00fa525ee0054539a35326175f5897c0",
            "value": "100%"
          }
        },
        "efc7f3f024e24f048c71f7e2b513e5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a82e97069614450970ad56d80a6dcef",
            "max": 1217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7c4c19d64ef458e90ef1d620f1b2faf",
            "value": 1217
          }
        },
        "3be8ef31e0c34a39a4f48754b90cbf46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95a75c2ebb844c18a6562ecf423ae8d6",
            "placeholder": "​",
            "style": "IPY_MODEL_4ce3f72c322c4aeca34f4e721e5099d9",
            "value": " 1217/1217 [00:00&lt;00:00, 1238.18ex/s]"
          }
        },
        "750a8d92d96e42f29bad8734f502cd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b02d726cd444a68557e4503093e8d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00fa525ee0054539a35326175f5897c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a82e97069614450970ad56d80a6dcef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c4c19d64ef458e90ef1d620f1b2faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95a75c2ebb844c18a6562ecf423ae8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce3f72c322c4aeca34f4e721e5099d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cddc3138a644efaa074c4bc43e78757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b2b65c087ce406983c723b1070a093e",
              "IPY_MODEL_1d8cb71c93b04ddb925a6666d4468713",
              "IPY_MODEL_2d56d39858944ec699515d563b811251"
            ],
            "layout": "IPY_MODEL_5bd06a2291cb49dea6efefe4086a2b2c"
          }
        },
        "6b2b65c087ce406983c723b1070a093e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c1d1530455406fb99a7a5a117a2b69",
            "placeholder": "​",
            "style": "IPY_MODEL_8e0ecab74a1249c6a18ae1a15bd7c528",
            "value": "100%"
          }
        },
        "1d8cb71c93b04ddb925a6666d4468713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69bef7f568148f5b0203de78ea59e03",
            "max": 1896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ebb1f7e5e114dd28fe9c82f6ddf9d00",
            "value": 1896
          }
        },
        "2d56d39858944ec699515d563b811251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce49b561b58946f28278184e25fc71cf",
            "placeholder": "​",
            "style": "IPY_MODEL_49d2b98ceaa04847aace15f4ca89a4ec",
            "value": " 1896/1896 [00:01&lt;00:00, 1265.76ex/s]"
          }
        },
        "5bd06a2291cb49dea6efefe4086a2b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c1d1530455406fb99a7a5a117a2b69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e0ecab74a1249c6a18ae1a15bd7c528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c69bef7f568148f5b0203de78ea59e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ebb1f7e5e114dd28fe9c82f6ddf9d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce49b561b58946f28278184e25fc71cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d2b98ceaa04847aace15f4ca89a4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67f83cfbb8474d909d9c882be1fd94e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f637125d76924b23a4b649795a20b9c2",
              "IPY_MODEL_1d2707fe64164b839191f3099aeb90f0",
              "IPY_MODEL_b028e36c4f8f4551b0ee4e134cc959b9"
            ],
            "layout": "IPY_MODEL_cd6204f22f3e4dc4829dcd1df5762a5b"
          }
        },
        "f637125d76924b23a4b649795a20b9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_461090dad5084fda9e19f0e59f86d8fd",
            "placeholder": "​",
            "style": "IPY_MODEL_378df4bc985f441f8b950e8320a6a308",
            "value": "100%"
          }
        },
        "1d2707fe64164b839191f3099aeb90f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a6497b34794867ade88551c65aa2ed",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebd77588ec4a4da7b17739854d08d367",
            "value": 100
          }
        },
        "b028e36c4f8f4551b0ee4e134cc959b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae31b05c7da45af8f8b91f6004c9f89",
            "placeholder": "​",
            "style": "IPY_MODEL_aa90011fa3bc426db77f65837980c43d",
            "value": " 100/100 [00:00&lt;00:00, 153.86ex/s]"
          }
        },
        "cd6204f22f3e4dc4829dcd1df5762a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "461090dad5084fda9e19f0e59f86d8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "378df4bc985f441f8b950e8320a6a308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3a6497b34794867ade88551c65aa2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd77588ec4a4da7b17739854d08d367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cae31b05c7da45af8f8b91f6004c9f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa90011fa3bc426db77f65837980c43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14a1a34e8050417884d020d4a18092f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a76776bcac04d6bb630a671fc273595",
              "IPY_MODEL_380543fc0e25430f840368c691dd3566",
              "IPY_MODEL_61d82302390a4ad5bacea61da775111d"
            ],
            "layout": "IPY_MODEL_59e4358c3a2849ecb5a10eadc175edec"
          }
        },
        "5a76776bcac04d6bb630a671fc273595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae2e9a94df449f99117c29ff5cbb15c",
            "placeholder": "​",
            "style": "IPY_MODEL_f465073b4cc1434cadcfb9ba85cfc36a",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "380543fc0e25430f840368c691dd3566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44f5b77778e40d38659bc3c5317e183",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b0309039a6e42ce81e419ae20ee87e3",
            "value": 231508
          }
        },
        "61d82302390a4ad5bacea61da775111d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f404c913584a80a32d57cf59c542e2",
            "placeholder": "​",
            "style": "IPY_MODEL_3b6567bca1194402a0e7dc6860ef984e",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]"
          }
        },
        "59e4358c3a2849ecb5a10eadc175edec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae2e9a94df449f99117c29ff5cbb15c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f465073b4cc1434cadcfb9ba85cfc36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d44f5b77778e40d38659bc3c5317e183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0309039a6e42ce81e419ae20ee87e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44f404c913584a80a32d57cf59c542e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b6567bca1194402a0e7dc6860ef984e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2ee900c2c714d9ba0f84bc64929fffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3dde680ef0b4214a40c3e6a2f28657a",
              "IPY_MODEL_736a3250283d413ba9e437a454f918e3",
              "IPY_MODEL_12f6af730bc3436fa30913003a1bed11"
            ],
            "layout": "IPY_MODEL_e4acb61d5b834bf3a13e750a0a83420d"
          }
        },
        "a3dde680ef0b4214a40c3e6a2f28657a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a0f9cb3156459ebaba4d3a68257e05",
            "placeholder": "​",
            "style": "IPY_MODEL_e6da8c5370394888a1b1babb3ef021b6",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "736a3250283d413ba9e437a454f918e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25fde6979b7945a0a79d3126a1612f4d",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2581a0f2879a48ef892cddd1693a4e5a",
            "value": 28
          }
        },
        "12f6af730bc3436fa30913003a1bed11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_334eefc9c97a4cab87c94da41821a293",
            "placeholder": "​",
            "style": "IPY_MODEL_5e75d829a882425fbfa8d725e974e37d",
            "value": " 28.0/28.0 [00:00&lt;00:00, 424B/s]"
          }
        },
        "e4acb61d5b834bf3a13e750a0a83420d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a0f9cb3156459ebaba4d3a68257e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6da8c5370394888a1b1babb3ef021b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25fde6979b7945a0a79d3126a1612f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2581a0f2879a48ef892cddd1693a4e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "334eefc9c97a4cab87c94da41821a293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e75d829a882425fbfa8d725e974e37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a31ea57f11f4d4ea993047242f0f854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c487fccd9bc946a8bac0d38ae52c2309",
              "IPY_MODEL_e8295028196340fca8a7a2b3b946ac61",
              "IPY_MODEL_6fd12cb0ac314750a92f3b90e0fb15eb"
            ],
            "layout": "IPY_MODEL_64bae11e4abf4c83bbb7da3ada6c9575"
          }
        },
        "c487fccd9bc946a8bac0d38ae52c2309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2fb065a86a439c8c892444f019501f",
            "placeholder": "​",
            "style": "IPY_MODEL_0dd99858923445ef8db5cb044c02b04c",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e8295028196340fca8a7a2b3b946ac61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fd2792d1d1947a18a4eab739740c4a6",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_917f6704c7254a1a93ae0b7e8d441b8f",
            "value": 570
          }
        },
        "6fd12cb0ac314750a92f3b90e0fb15eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ced347ceb7a4100bb5cbe034f5e499d",
            "placeholder": "​",
            "style": "IPY_MODEL_177d90beb5e34e6ea17420efe41f8b67",
            "value": " 570/570 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "64bae11e4abf4c83bbb7da3ada6c9575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2fb065a86a439c8c892444f019501f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd99858923445ef8db5cb044c02b04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd2792d1d1947a18a4eab739740c4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917f6704c7254a1a93ae0b7e8d441b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ced347ceb7a4100bb5cbe034f5e499d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177d90beb5e34e6ea17420efe41f8b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b03e9e56b3844e0c96a08bcb1d10af75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cb9742701954af29d3dfc7086931dda",
              "IPY_MODEL_11639bf11a954c4db38d8f7e8e9de290",
              "IPY_MODEL_40745e58ef6f4d42916e24b17f8115f7"
            ],
            "layout": "IPY_MODEL_e70f83dc96754dfb953f153e75e0760b"
          }
        },
        "1cb9742701954af29d3dfc7086931dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f08d0539944fdaa047fd7f2587bf39",
            "placeholder": "​",
            "style": "IPY_MODEL_2859aaf51f4b431fb61180502d08fb82",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "11639bf11a954c4db38d8f7e8e9de290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c81b531e8e4b58b2f7263781001541",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35ac5c980174488c81eab6a89f4679f6",
            "value": 440473133
          }
        },
        "40745e58ef6f4d42916e24b17f8115f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8754fc8e32a434b8784c0b53219846c",
            "placeholder": "​",
            "style": "IPY_MODEL_8b13110ca57e4a9da78f49cea1526d36",
            "value": " 440M/440M [00:04&lt;00:00, 97.1MB/s]"
          }
        },
        "e70f83dc96754dfb953f153e75e0760b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f08d0539944fdaa047fd7f2587bf39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2859aaf51f4b431fb61180502d08fb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c81b531e8e4b58b2f7263781001541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ac5c980174488c81eab6a89f4679f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8754fc8e32a434b8784c0b53219846c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b13110ca57e4a9da78f49cea1526d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP course project\n",
        "**Summary**: Application of text classification approaches for Human Value Detection <br>\n",
        "**Members**:\n",
        "- Dell'Olio Domenico\n",
        "- Delvecchio Giovanni Pio\n",
        "- Disabato Raffaele  \n"
      ],
      "metadata": {
        "id": "wWUTpjsbw3DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project was developed in order to create and test various models to address the task of Human Value Detection proposed in the challenge: <br>\n",
        "https://touche.webis.de/semeval23/touche23-web/index.html <br>\n",
        "\n",
        "The challenge can be tackled as a multi-label text clasification problem, thus we decided to implement and test various architectures in order to compare their performances. <br>\n",
        "These architectures were either already present at the state of the art or were obtained as a result of experiments."
      ],
      "metadata": {
        "id": "D6YEI0XMxl2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook contains the following implementations:\n",
        "- GloVe baseline with two layers of Bi-GRU, followed by flatten and two dense layers with ReLU activation and a single dense layer with no activation;\n",
        "- BERT baseline with two layers of Bi-LSTM (transfer learning), where the output cell states are concatenated and passed to a dense layer with ReLU activation and a single dense layer with no activation;\n",
        "- finetuning of BERT followed by a dense layer with ReLU activation followed by a dense layer with no activation.\n",
        "\n",
        "## This notebook does **not** contain:\n",
        "- exstensive Data analysis (it is explored in the other notebook)"
      ],
      "metadata": {
        "id": "3tcwwV4uu6kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6cF2LQqwOLX2",
        "outputId": "ff7702e6-28b6-4af2-f099-f8c125799f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# installation of the required libraries\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for the download of the datasets\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-training.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
        "!wget https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYe5zjeVO5yS",
        "outputId": "dcaf8e21-11e6-4011-9a1c-024cba991979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-09 22:08:15--  https://zenodo.org/record/7550385/files/arguments-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1012498 (989K) [application/octet-stream]\n",
            "Saving to: ‘arguments-training.tsv’\n",
            "\n",
            "arguments-training. 100%[===================>] 988.77K  1.66MB/s    in 0.6s    \n",
            "\n",
            "2023-02-09 22:08:17 (1.66 MB/s) - ‘arguments-training.tsv’ saved [1012498/1012498]\n",
            "\n",
            "--2023-02-09 22:08:17--  https://zenodo.org/record/7550385/files/labels-training.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253843 (248K) [application/octet-stream]\n",
            "Saving to: ‘labels-training.tsv’\n",
            "\n",
            "labels-training.tsv 100%[===================>] 247.89K   713KB/s    in 0.3s    \n",
            "\n",
            "2023-02-09 22:08:19 (713 KB/s) - ‘labels-training.tsv’ saved [253843/253843]\n",
            "\n",
            "--2023-02-09 22:08:19--  https://zenodo.org/record/7550385/files/arguments-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362608 (354K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>] 354.11K   508KB/s    in 0.7s    \n",
            "\n",
            "2023-02-09 22:08:22 (508 KB/s) - ‘arguments-validation.tsv’ saved [362608/362608]\n",
            "\n",
            "--2023-02-09 22:08:22--  https://zenodo.org/record/7550385/files/labels-validation.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89484 (87K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation.tsv’\n",
            "\n",
            "labels-validation.t 100%[===================>]  87.39K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-02-09 22:08:24 (751 KB/s) - ‘labels-validation.tsv’ saved [89484/89484]\n",
            "\n",
            "--2023-02-09 22:08:24--  https://zenodo.org/record/7550385/files/arguments-test.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290185 (283K) [application/octet-stream]\n",
            "Saving to: ‘arguments-test.tsv’\n",
            "\n",
            "arguments-test.tsv  100%[===================>] 283.38K   813KB/s    in 0.3s    \n",
            "\n",
            "2023-02-09 22:08:26 (813 KB/s) - ‘arguments-test.tsv’ saved [290185/290185]\n",
            "\n",
            "--2023-02-09 22:08:26--  https://zenodo.org/record/7550385/files/arguments-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22082 (22K) [application/octet-stream]\n",
            "Saving to: ‘arguments-validation-zhihu.tsv’\n",
            "\n",
            "arguments-validatio 100%[===================>]  21.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-09 22:08:27 (220 MB/s) - ‘arguments-validation-zhihu.tsv’ saved [22082/22082]\n",
            "\n",
            "--2023-02-09 22:08:27--  https://zenodo.org/record/7550385/files/labels-validation-zhihu.tsv\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5072 (5.0K) [application/octet-stream]\n",
            "Saving to: ‘labels-validation-zhihu.tsv’\n",
            "\n",
            "labels-validation-z 100%[===================>]   4.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-09 22:08:28 (475 MB/s) - ‘labels-validation-zhihu.tsv’ saved [5072/5072]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for dataset loading\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# torch imports\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "from torchinfo import summary\n",
        "from torch.optim import AdamW\n",
        "\n",
        "#huggingface imports\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "\n",
        "# progress bar\n",
        "from tqdm import tqdm\n",
        "# garbage collector\n",
        "import gc\n",
        "\n",
        "# imports for evaluation\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "4-K7IcSRPtPO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "  \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "  Params:\n",
        "    seed: the seed to use. \n",
        "  \"\"\"\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "OFk0dSBHFCYx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell needed to fix the seeds and define the available device\n",
        "# for the training of the models\n",
        "seed = 10\n",
        "fix_random(seed)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "DbJvCz2MOnRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4725248a-da60-4e7c-951b-cace0487c7b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def huggingface_from_pandas(pandas_df):\n",
        "  \"\"\"\n",
        "  Function converting a pandas dataframe to a huggingface dataset.\n",
        "  It also returns an ordered list containing the target labels\n",
        "\n",
        "  Params:\n",
        "    pandas_df: the dataset that has to be converted\n",
        "  Returns:\n",
        "    hf_ds:     the huggingface dataset obrained from pandas_df\n",
        "    label_cols: the ordered list of target labels of pandas_df\n",
        "  \"\"\"\n",
        "\n",
        "  hf_ds = Dataset.from_pandas(pandas_df, preserve_index=False)\n",
        "  hf_ds = hf_ds.remove_columns([\"Argument ID\", \"Argument ID2\"])\n",
        "  # Aggregating labels in a single list\n",
        "  hf_ds = hf_ds.map(lambda x:{\"labels\": [int(x[col]) for col in hf_ds.column_names if\n",
        "                                      col not in ['Conclusion', 'Stance', 'Premise']]})\n",
        "  label_cols = [col for col in hf_ds.column_names if col not in ['Conclusion', 'Stance', 'Premise', \"labels\"]]\n",
        "  # here we are removing the columns related to the labels from the dataset\n",
        "  hf_ds = hf_ds.remove_columns(label_cols)\n",
        "  return hf_ds, label_cols"
      ],
      "metadata": {
        "id": "pLN6XBISHnLf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The challenge provides the already splitted dataset in Train, Validation and Test splits. However the Test split does not have public labels available, \n",
        "so we decided to split the Training set in (Training, Validation) \n",
        "(with proportions 80-20 on unique conclusions) and to use the validation set as Test set.  <br>\n",
        "We decided to probe the robustness of our model on the Chinese validation\n",
        "set too, which has a different cultural background."
      ],
      "metadata": {
        "id": "hq8Fgjoj0__P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_wrt_conclusions(train, ratio = 0.8):\n",
        "  \"\"\"\n",
        "  Function needed to perform the splits over the original train dataset,\n",
        "  in order to obtain a train and a validation set which are divided by unique\n",
        "  conclusions. The ratio parameter is needed in order to assign which portion \n",
        "  of the unique conclusions must be selected for the train split.\n",
        "  \n",
        "  Params:\n",
        "    train: the original train set, to be splitted (Pandas dataframe)\n",
        "    ratio: the proportion in (0, 1) of unique conclusions to be inserted in \n",
        "           the training dataframe.\n",
        "  Returns:\n",
        "    train_set_to_return: the portion of train that contains ratio unique\n",
        "                         conclusions.\n",
        "    val_set_to_return: the proportion of the train that contains 1 - ratio\n",
        "                       unique conclusions (the remaining ones)\n",
        "  \"\"\"\n",
        "  val = []\n",
        "  unique_conc = pd.unique(train[\"Conclusion\"])\n",
        "  num_train_con = int(len(unique_conc)*ratio)\n",
        "  train_unique_conc = np.random.choice(unique_conc, num_train_con, replace = False)\n",
        "  val_unique_conc = set(unique_conc) - set(train_unique_conc)\n",
        "  train_set_to_return = train[train.Conclusion.isin(train_unique_conc)] \n",
        "  val_set_to_return = train[train.Conclusion.isin(val_unique_conc)]\n",
        "  return train_set_to_return, val_set_to_return"
      ],
      "metadata": {
        "id": "swL5m3C4x7wV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loading and splitting\n",
        "raw_training = pd.read_csv(\"arguments-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_training_lab = pd.read_csv(\"labels-training.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test = pd.read_csv(\"arguments-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_lab = pd.read_csv(\"labels-validation.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn=pd.read_csv(\"arguments-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "raw_test_chn_lab=pd.read_csv(\"labels-validation-zhihu.tsv\", encoding='utf-8', sep='\\t', header=0)\n",
        "\n",
        "train = raw_training.join(raw_training_lab,how='inner' ,lsuffix='2') # joining labels\n",
        "test = raw_test.join(raw_test_lab, how='inner', lsuffix='2') # joining labels\n",
        "test_chn = raw_test_chn.join(raw_test_chn_lab, how='inner', lsuffix='2') # joining labels\n",
        "fix_random(seed)\n",
        "train, val = train_test_split_wrt_conclusions(train) # splitting training\n",
        "\n",
        "train_ds, label_list = huggingface_from_pandas(train)\n",
        "val_ds, _ = huggingface_from_pandas(val)\n",
        "test_ds, _ = huggingface_from_pandas(test)\n",
        "test_chn_ds, _ = huggingface_from_pandas(test_chn) \n",
        "\n",
        "print(\"Single example from the training dataset: \")\n",
        "print(train_ds[0])\n",
        "print(\"Full list of target labels: \")\n",
        "print(label_list)\n",
        "num_classes = len(label_list)\n",
        "print(\"Total number of target labels: \")\n",
        "print(num_classes)\n",
        "whole_dataset = DatasetDict()\n",
        "whole_dataset[\"train\"] = train_ds.with_format(\"torch\")\n",
        "whole_dataset[\"val\"] = val_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test\"] = test_ds.with_format(\"torch\")\n",
        "whole_dataset[\"test_chn\"] = test_chn_ds.with_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "23345898340340b68a62dd156a59a3ed",
            "b9957fecd4c04e6cbf458d9372bf4bf4",
            "1e8711382d924dc5a136c957432f8752",
            "f1e7b518a27b428596e5fd0f7cb04da4",
            "6352c96eee9f4462987b419cd0aa8892",
            "2ef688fba29549ac9797a90dc164847a",
            "d344b04f8033490dbf2f61daada4d7d0",
            "2f1f0de33b2f411e91e88bd1ba55c134",
            "26a1d8455be64f858ee1eb20c55c894b",
            "e916a25e1c854dbbb59a75789f048130",
            "76d428957e3740afac8c7f10590d1afd",
            "2c7a692d88ce4df2872462e244424364",
            "a0012279b1fa449f8ba47dc1076702d9",
            "efc7f3f024e24f048c71f7e2b513e5a0",
            "3be8ef31e0c34a39a4f48754b90cbf46",
            "750a8d92d96e42f29bad8734f502cd7f",
            "53b02d726cd444a68557e4503093e8d1",
            "00fa525ee0054539a35326175f5897c0",
            "8a82e97069614450970ad56d80a6dcef",
            "d7c4c19d64ef458e90ef1d620f1b2faf",
            "95a75c2ebb844c18a6562ecf423ae8d6",
            "4ce3f72c322c4aeca34f4e721e5099d9",
            "4cddc3138a644efaa074c4bc43e78757",
            "6b2b65c087ce406983c723b1070a093e",
            "1d8cb71c93b04ddb925a6666d4468713",
            "2d56d39858944ec699515d563b811251",
            "5bd06a2291cb49dea6efefe4086a2b2c",
            "b1c1d1530455406fb99a7a5a117a2b69",
            "8e0ecab74a1249c6a18ae1a15bd7c528",
            "c69bef7f568148f5b0203de78ea59e03",
            "8ebb1f7e5e114dd28fe9c82f6ddf9d00",
            "ce49b561b58946f28278184e25fc71cf",
            "49d2b98ceaa04847aace15f4ca89a4ec",
            "67f83cfbb8474d909d9c882be1fd94e9",
            "f637125d76924b23a4b649795a20b9c2",
            "1d2707fe64164b839191f3099aeb90f0",
            "b028e36c4f8f4551b0ee4e134cc959b9",
            "cd6204f22f3e4dc4829dcd1df5762a5b",
            "461090dad5084fda9e19f0e59f86d8fd",
            "378df4bc985f441f8b950e8320a6a308",
            "e3a6497b34794867ade88551c65aa2ed",
            "ebd77588ec4a4da7b17739854d08d367",
            "cae31b05c7da45af8f8b91f6004c9f89",
            "aa90011fa3bc426db77f65837980c43d"
          ]
        },
        "id": "FU98Kgv5Q3PO",
        "outputId": "2a43f978-8382-4752-f1a0-e21665be6fe7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4176 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23345898340340b68a62dd156a59a3ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1217 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c7a692d88ce4df2872462e244424364"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1896 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cddc3138a644efaa074c4bc43e78757"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67f83cfbb8474d909d9c882be1fd94e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single example from the training dataset: \n",
            "{'Conclusion': 'We should ban human cloning', 'Stance': 'in favor of', 'Premise': 'we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.', 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "Full list of target labels: \n",
            "['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']\n",
            "Total number of target labels: \n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, loader):\n",
        "  \"\"\"\n",
        "  Function needed to obtain the prediction for the target labels\n",
        "  given a model and a data loader.\n",
        "\n",
        "  Params:\n",
        "    model: the model that will be used to obtain the predictions over\n",
        "           the labels\n",
        "    loader: the data loader needed to feed the model with the data for which\n",
        "            we want to obtain label predictions\n",
        "  Returns:\n",
        "    Y_preds: tensor containing the predicted label for each example.\n",
        "             These labels are obtained as the output of the model passed to\n",
        "             a sigmoid function.\n",
        "  \"\"\"\n",
        "  Y_preds = []\n",
        "  model.eval()\n",
        "  for X, Y in loader:\n",
        "    with torch.no_grad():\n",
        "      preds = model(X)\n",
        "    Y_preds.append(preds)\n",
        "  gc.collect()\n",
        "  Y_preds = torch.cat(Y_preds)\n",
        "  Y_preds = Y_preds.sigmoid()\n",
        "  return Y_preds.detach()\n",
        "\n",
        "def keep_above_thresh(Y_preds, thr):\n",
        "  \"\"\"\n",
        "  Function needed to convert the results of the models to hard labels\n",
        "  using a threshold.\n",
        "  \n",
        "  Params:\n",
        "    Y_preds: scores obtained by the model which have to be converted to hard\n",
        "             labels\n",
        "    thr: threshold to be applied to the scores, element of (0, 1), if a score\n",
        "         is greater than thr it becomes a hard label with value 1, \n",
        "         0 otherwise\n",
        "  Retuns:\n",
        "    Y_preds_thr: hard labels obtained by thresholding Y_preds with thr\n",
        "  \"\"\"\n",
        "  Y_preds_thr = np.copy(Y_preds.numpy())\n",
        "  max_rows = Y_preds_thr.shape[0]\n",
        "  max_cols = Y_preds_thr.shape[1]\n",
        "  for i in range(max_rows):\n",
        "    new_row = np.array([1 if Y_preds_thr[i][j] > thr else 0 for j in range(max_cols)])\n",
        "    Y_preds_thr[i] = new_row\n",
        "  return Y_preds_thr\n",
        "\n",
        "def compute_macro_score(M_true, M_pred, score_func):\n",
        "  \"\"\"\n",
        "  Function needed to compute the macro aggregation of a scored function\n",
        "  over the different classes.\n",
        "\n",
        "  Params:\n",
        "    M_true: true labels needed to compute the scores\n",
        "    M_pred: predicted labels needed to compute the scores\n",
        "    score_func: scoring function to be computed\n",
        "  Returns:\n",
        "    macro: aggregation of the result of score_func computed over all the\n",
        "           labels.\n",
        "    scores: list of per-label score\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for i in range(M_true.shape[1]):\n",
        "      true = M_true[:, i]\n",
        "      pred = M_pred[:, i]\n",
        "      if score_func == accuracy_score:\n",
        "        scores.append(score_func(true, pred))\n",
        "      else: \n",
        "        scores.append(score_func(true, pred, zero_division=0))\n",
        "  macro = np.mean(scores)\n",
        "  return macro, scores\n",
        "  \n",
        "def support(true, pred, zero_division):\n",
        "  \"\"\"\n",
        "  Utility function to compute the support of the class labels,\n",
        "  pred and zero_division are dummy parameters needed to have conformity\n",
        "  with the sklearn functions to compute scores.\n",
        "\n",
        "  Params: \n",
        "    true: binary true labels for a single class for each example that are needed\n",
        "          to compute the support for the single class\n",
        "    pred: dummy parameter\n",
        "    zero_division: dummy parameter\n",
        "  Returns:\n",
        "    sum(true): the number of example for a single class (support)\n",
        "  \"\"\"\n",
        "  return sum(true)\n",
        "\n",
        "def print_report(classifier, loader, y_true, threshold, labels=label_list):\n",
        "  \"\"\"\n",
        "  Function needed to print the classification results given a classifier,\n",
        "  a dataset loader, true labels and a threshold. \n",
        "  The printed report includes macro accuracy, precision, recall and F1, as \n",
        "  well as per-class accuracy, precision, recall, F1 and support.\n",
        "\n",
        "  Params:\n",
        "    classifier: the model that has to be evaluated\n",
        "    loader: data-loader needed to feed the data to the classifier to get \n",
        "            predicted labels\n",
        "    y_true: true labels associated to the dataset associated to the loader\n",
        "    threshold: threshold for the conversion of the scores to hard labels,\n",
        "               check keep_above_thresh for further details\n",
        "    labels: ordered list of target labels. Defaults to the list extracted from\n",
        "            the dataset\n",
        "  \"\"\"\n",
        "\n",
        "  Y_preds = make_predictions(classifier, loader)\n",
        "  Y_preds_thr = keep_above_thresh(Y_preds.to('cpu'), threshold)\n",
        "\n",
        "  f1_macro, f1 = compute_macro_score(y_true, Y_preds_thr, f1_score)\n",
        "  acc_macro, acc = compute_macro_score(y_true, Y_preds_thr, accuracy_score)\n",
        "  prec_macro, prec = compute_macro_score(y_true, Y_preds_thr, precision_score)\n",
        "  rec_macro, rec = compute_macro_score(y_true, Y_preds_thr, recall_score)\n",
        "  _, sup = compute_macro_score(y_true, Y_preds_thr, support)\n",
        "\n",
        "  print(\"----- MACRO AVG. -----\")\n",
        "  print(f\"  F1-score:\\t{round(f1_macro,4)}\\n\\\n",
        "  Precision:\\t{round(prec_macro,4)}\\n\\\n",
        "  Recall:\\t{round(rec_macro,4)}\\n\\\n",
        "  Accuracy:\\t{round(acc_macro,4)}\")\n",
        "  print(\"----- PER-CLASS VALUES -----\")\n",
        "  print(\"  \\t\\t\\t\\tF1-score\\tPrecision\\tRecall\\t\\tAccuracy\\tSupport\")\n",
        "  for i in range(len(labels)):\n",
        "    print(\"  \" + labels[i]+\" \"*(len(max(labels, key=len))-len(labels[i])), end=\"\\t\")\n",
        "    print(f\"{round(f1[i],4)}\\t\\t{round(prec[i],4)}\\t\\t{round(rec[i],4)}\\t\\t{round(acc[i],4)}\\t\\t{sup[i]}\")"
      ],
      "metadata": {
        "id": "uU_qeLA6l7OE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe model\n",
        "The first model that was developed is a GloVe 100d embedding + two Bi-GRU layers\n",
        "That serves as an advanced baseline to perfom experiments for multi-label classification problems like the current one. \n",
        "It is still a baseline since it has a simple architecture, OOV are treated using zero-vectors, the hidden states of the Bi-GRU layers are initialized \n",
        "as zero-vectors and most importantly the model does not work with contextual information, but only with the semantics of the words. <br>\n",
        "Moreover an heavy preprocessing to the dataset is not applied except for lowercasing the arguments, tokenization and the addition of truncation and padding because the GloVe embeddings would return too many unmasked zero vectors. <br>\n",
        "About padding and truncation: the maximum allowed length is 35 which is \n",
        "slightly above the sum of the mean token length value for the premises and the\n",
        "conclusion. \n",
        "\n",
        "N.B.: the last dense layer has no activation for all the models, since the loss\n",
        "function applies it by guaranteeing numerical stability. Thus the output of the\n",
        "layer must be passed to a sigmoid function before converting it to labels."
      ],
      "metadata": {
        "id": "LosoIWWz_5e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained GloVe setup\n",
        "\n",
        "global_vectors = GloVe(name='6B', dim=100)\n",
        "\n",
        "# the current choice is to give an id to each word\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "TOU9N3-WJgn3",
        "outputId": "494089d3-c020-4f92-d143-5acd89284767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:43, 5.26MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:15<00:00, 26055.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# these parameters are used both by the following function and by the \n",
        "# implementation of the GloVe model itself, thus are kept global\n",
        "max_words_emb = 35\n",
        "embed_len = 100\n",
        "\n",
        "# collate function where the Premises are tokenized and embedded in batches\n",
        "def vectorize_batch(batch):\n",
        "  \"\"\"\n",
        "  Collate function to preprocess the data for the GloVe model.\n",
        "  In particular it joins premises, stances and conclusions in the same string,\n",
        "  tokenizes, truncates and pads them and then converts each token to a GloVe\n",
        "  vector. Target labels are already one-hot encoded.\n",
        "\n",
        "  Params:\n",
        "    batch: batch of data to be preprocessed\n",
        "  Returns:\n",
        "    X_tensor: a tensor containing GloVe vectors of dimension 100, which has shape\n",
        "              (batch_size, max_words_emb, embed_len)\n",
        "    Y_tensor: a tensor containing labels, which has shape\n",
        "              (batch_size, num_classes)\n",
        "  \"\"\"\n",
        "  X = [elem[\"Premise\"] + \" \" + elem[\"Stance\"] + \" \" +elem[\"Conclusion\"] for elem in batch]\n",
        "  Y = [elem[\"labels\"] for elem in batch]\n",
        "  X = [tokenizer(x) for x in X]\n",
        "  X = [tokens+[\"\"] * (max_words_emb-len(tokens))  if len(tokens)<max_words_emb else tokens[:max_words_emb] for tokens in X]\n",
        "  X_tensor = torch.zeros(len(batch), max_words_emb, embed_len)\n",
        "  Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "  for i, tokens in enumerate(X):\n",
        "      X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
        "      Y_tensor[i] = Y[i]\n",
        "  return X_tensor, Y_tensor"
      ],
      "metadata": {
        "id": "0eFmzKrDbvlJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class EmbeddingClassifier(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the GloVe model.\n",
        "  Remark: max_words_emb, embed_len and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      super(EmbeddingClassifier, self).__init__() \n",
        "      \n",
        "      self.gru_layers = 2\n",
        "\n",
        "      self.gru = nn.GRU(input_size = embed_len,\n",
        "                        hidden_size = embed_len,\n",
        "                        num_layers = self.gru_layers,\n",
        "                        batch_first=True, \n",
        "                        bidirectional = True)\n",
        "      self.flatten = nn.Flatten(start_dim=1)\n",
        "      self.linear_1 = nn.Linear(max_words_emb*embed_len*2, 512)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.linear_2 = nn.Linear(512,128)\n",
        "      self.linear_3 = nn.Linear(128, num_classes)\n",
        "      \n",
        "              \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    \"\"\"\n",
        "    It is important to note that the initial hidden states of the GRU\n",
        "    layers are initialized with zero tensors.\n",
        "\n",
        "    The outcomes of the GRU layers are flattened and classified. \n",
        "    \"\"\"\n",
        "    h0 = torch.zeros(2*self.gru_layers,X_batch.shape[0], embed_len)\n",
        "    h0 = h0.to(device)\n",
        "    out, hn = self.gru(X_batch, h0)\n",
        "    out = self.flatten(out)\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_3(out)\n",
        "    return out\n",
        "\n",
        "# Function needed to compute the validation loss and the accuracy\n",
        "def compute_validation_loss(model, loss_fn, val_loader):\n",
        "  \"\"\"\n",
        "  Function computing and printing the loss on the validation set.\n",
        "  Params:\n",
        "    model: the model for which the loss must be computed and printed\n",
        "    loss_fn: the loss function to adopt\n",
        "    val_loader: dataloader for the validation set\n",
        "\n",
        "  Returns:\n",
        "    loss: the computed mean loss across the batch\n",
        "  \"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    losses = []\n",
        "    for X, Y in val_loader:\n",
        "      preds = model(X)\n",
        "      loss = loss_fn(preds, Y)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "    loss = torch.tensor(losses).mean()\n",
        "    print(\"Valid Loss : {:.3f}\".format(loss))\n",
        "  return loss\n",
        "\n",
        "\n",
        "# Training function\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name):\n",
        "  \"\"\"\n",
        "  Function for model training. If early stopping info is defined it saves the \n",
        "  last best models and eventually returns it, in case of early stopping.\n",
        "  In case early_stopping_info is not defined, the early stopping is not\n",
        "  applied.\n",
        "\n",
        "  Params:\n",
        "    model: the model that has to be trained\n",
        "    loss_fn: the loss function to adopt in order to perform the training\n",
        "    optimizer: the optimizer to be used for training\n",
        "    train_loader: the dataloader for the training dataset\n",
        "    val_loader: the dataloader for the validation dataset\n",
        "    epochs: the number of epochs for training\n",
        "    early_stopping_info: dictionary containing the parameters for the early stopping:\n",
        "                          - delta: min acceptable improvement in the validation loss\n",
        "                          - patience: number of epochs to wait for improvement\n",
        "    model_name: string containing the name of the model (used in order to save\n",
        "                the weights)\n",
        "  Returns:\n",
        "    model: the trained model\n",
        "  \"\"\"\n",
        "  patience_acc = 0\n",
        "  precedent_loss = np.Inf\n",
        "  model.train()\n",
        "  for i in range(1, epochs+1):\n",
        "      losses = []\n",
        "      for X, Y in tqdm(train_loader):\n",
        "\n",
        "          Y_preds = model(X)\n",
        "\n",
        "          loss = loss_fn(Y_preds, Y)\n",
        "          losses.append(loss.item())\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      loss = compute_validation_loss(model, loss_fn, val_loader)\n",
        "      print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "      if early_stopping_info != None:\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "            patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          precedent_loss = loss  \n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc >= early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"_best.pth\")           \n",
        "  return model\n"
      ],
      "metadata": {
        "id": "XHy7Zl7EK-FA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training informations\n",
        "The training was performed considering a maximum of 50 epochs with the following parameters for early stopping: patience equal to 3 epochs and delta equal to 1e-4. Batch size, learning rate and number of parameters for the layers were tuned by hand considering the results on the validation set.\n",
        "In particular the following pools were considered:\n",
        "- batch_size in \\{16, 32, 64\\}\n",
        "- learning rate in \\{1e-2, 1e-3, 1e-4\\}\n",
        "- hidden size of the GRU layers in \\{100, 200\\}\n",
        "- neurons of the linear layers in \\{512, 256, 128\\}"
      ],
      "metadata": {
        "id": "ZOyMHpzEK0mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 1e-4\n",
        "batch_size = 32\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "embed_classifier = EmbeddingClassifier()\n",
        "optimizer = Adam(embed_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Construction of the Dataloaders for train and validation\n",
        "train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "\n",
        "\n",
        "embed_classifier.to(device)\n",
        "summary(embed_classifier, \n",
        "                input_data=next(iter(train_loader))[0],\n",
        "                device=device)\n"
      ],
      "metadata": {
        "id": "k4KSPSXAN6z0",
        "outputId": "e0cbf664-d2fe-4343-8f69-fc6acf0d3384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "EmbeddingClassifier                      [32, 20]                  --\n",
              "├─GRU: 1-1                               [32, 35, 200]             302,400\n",
              "├─Flatten: 1-2                           [32, 7000]                --\n",
              "├─Linear: 1-3                            [32, 512]                 3,584,512\n",
              "├─ReLU: 1-4                              [32, 512]                 --\n",
              "├─Linear: 1-5                            [32, 128]                 65,664\n",
              "├─ReLU: 1-6                              [32, 128]                 --\n",
              "├─Linear: 1-7                            [32, 20]                  2,580\n",
              "==========================================================================================\n",
              "Total params: 3,955,156\n",
              "Trainable params: 3,955,156\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 455.58\n",
              "==========================================================================================\n",
              "Input size (MB): 0.45\n",
              "Forward/backward pass size (MB): 1.96\n",
              "Params size (MB): 15.82\n",
              "Estimated Total Size (MB): 18.23\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "embed_classifier = TrainModel(embed_classifier, loss_fn, optimizer, train_loader, val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"glove\")"
      ],
      "metadata": {
        "id": "Ws7o13y5P5o4",
        "outputId": "29e183bc-5579-49ee-9e06-987332da472e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 44.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.410\n",
            "Train Loss : 0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.406\n",
            "Train Loss : 0.416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.397\n",
            "Train Loss : 0.403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.390\n",
            "Train Loss : 0.388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.383\n",
            "Train Loss : 0.377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.377\n",
            "Train Loss : 0.370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.372\n",
            "Train Loss : 0.364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 45.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.370\n",
            "Train Loss : 0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.367\n",
            "Train Loss : 0.353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.366\n",
            "Train Loss : 0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 37.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.366\n",
            "Train Loss : 0.343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.365\n",
            "Train Loss : 0.338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 54.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.365\n",
            "Train Loss : 0.334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:02<00:00, 53.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.366\n",
            "Train Loss : 0.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:03<00:00, 37.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.368\n",
            "Train Loss : 0.323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GloVe BASELINE:\")\n",
        "print_report(embed_classifier, val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "NsdbFRv1yrmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b35b52d-347a-468d-ecdd-c2a1fe7b3178"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe BASELINE:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3092\n",
            "  Precision:\t0.3175\n",
            "  Recall:\t0.3847\n",
            "  Accuracy:\t0.789\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.2986\t\t0.2374\t\t0.4024\t\t0.8726\t\t82\n",
            "  Self-direction: action    \t0.4658\t\t0.379\t\t0.6041\t\t0.6664\t\t293\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.9647\t\t43\n",
            "  Hedonism                  \t0.0\t\t0.0\t\t0.0\t\t0.9737\t\t32\n",
            "  Achievement               \t0.5928\t\t0.5409\t\t0.6556\t\t0.7313\t\t363\n",
            "  Power: dominance          \t0.2525\t\t0.3521\t\t0.1969\t\t0.8784\t\t127\n",
            "  Power: resources          \t0.5103\t\t0.7025\t\t0.4007\t\t0.825\t\t277\n",
            "  Face                      \t0.0213\t\t0.2\t\t0.0112\t\t0.9244\t\t89\n",
            "  Security: personal        \t0.6223\t\t0.4754\t\t0.9008\t\t0.5472\t\t504\n",
            "  Security: societal        \t0.679\t\t0.6084\t\t0.7682\t\t0.7297\t\t453\n",
            "  Tradition                 \t0.2537\t\t0.2203\t\t0.2989\t\t0.8743\t\t87\n",
            "  Conformity: rules         \t0.4503\t\t0.3239\t\t0.7384\t\t0.5867\t\t279\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.954\t\t56\n",
            "  Humility                  \t0.0674\t\t0.4286\t\t0.0366\t\t0.9318\t\t82\n",
            "  Benevolence: caring       \t0.3102\t\t0.2815\t\t0.3454\t\t0.6163\t\t304\n",
            "  Benevolence: dependability\t0.0917\t\t0.1528\t\t0.0655\t\t0.8209\t\t168\n",
            "  Universalism: concern     \t0.5935\t\t0.4883\t\t0.7565\t\t0.5768\t\t497\n",
            "  Universalism: nature      \t0.5053\t\t0.4138\t\t0.6486\t\t0.9228\t\t74\n",
            "  Universalism: tolerance   \t0.2222\t\t0.3953\t\t0.1545\t\t0.9022\t\t110\n",
            "  Universalism: objectivity \t0.2461\t\t0.1488\t\t0.7103\t\t0.4815\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT + LSTM model (transfer learning)\n",
        "The following model is proposed to enhance the GloVe model through the following changes:\n",
        "- Usage of contextual frozen Bert encoding instead of GloVe embeddings\n",
        "(changes were performed in the collate)\n",
        "- Substitution of the GRU layers with LSTM layers, which are more complex. \n",
        "- Meaningful initialization of the LSTM hidden and cell states using\n",
        "the pooler-output of the BERT encoding of an argument passed to two different dense layers (ideally the pooler-output represents the encoding of the \\[CLS\\] token which is at the beginning of every argument and contains general informations about semantics of the whole sentence).\n",
        "- Classification focussed on the concatenation of the output cell states of the LSTM layers, rather than the encoding of the whole sentence (concatenation of the hidden states).\n",
        "This reduces the number of required neurons and elaborates a tensor that retains the most important semantic informations on the sentence."
      ],
      "metadata": {
        "id": "H7VPAGgCNE7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection of the BERT model\n",
        "For this task we used the bert-based-uncased model and tokenizer. \n",
        "We also decided to try different variations of BERT (ELECTRA, ALBERT, Funnel Transformer, ...), but we didn't obtain remarkable improvements."
      ],
      "metadata": {
        "id": "wVQlUUX3PSaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import of the BERT tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model.to(device)\n",
        "print(\"Bert loaded\")"
      ],
      "metadata": {
        "id": "tt17dYqothM3",
        "outputId": "3453bd81-24a5-4fb5-a633-b9eeee56c9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "14a1a34e8050417884d020d4a18092f6",
            "5a76776bcac04d6bb630a671fc273595",
            "380543fc0e25430f840368c691dd3566",
            "61d82302390a4ad5bacea61da775111d",
            "59e4358c3a2849ecb5a10eadc175edec",
            "cae2e9a94df449f99117c29ff5cbb15c",
            "f465073b4cc1434cadcfb9ba85cfc36a",
            "d44f5b77778e40d38659bc3c5317e183",
            "8b0309039a6e42ce81e419ae20ee87e3",
            "44f404c913584a80a32d57cf59c542e2",
            "3b6567bca1194402a0e7dc6860ef984e",
            "e2ee900c2c714d9ba0f84bc64929fffb",
            "a3dde680ef0b4214a40c3e6a2f28657a",
            "736a3250283d413ba9e437a454f918e3",
            "12f6af730bc3436fa30913003a1bed11",
            "e4acb61d5b834bf3a13e750a0a83420d",
            "68a0f9cb3156459ebaba4d3a68257e05",
            "e6da8c5370394888a1b1babb3ef021b6",
            "25fde6979b7945a0a79d3126a1612f4d",
            "2581a0f2879a48ef892cddd1693a4e5a",
            "334eefc9c97a4cab87c94da41821a293",
            "5e75d829a882425fbfa8d725e974e37d",
            "9a31ea57f11f4d4ea993047242f0f854",
            "c487fccd9bc946a8bac0d38ae52c2309",
            "e8295028196340fca8a7a2b3b946ac61",
            "6fd12cb0ac314750a92f3b90e0fb15eb",
            "64bae11e4abf4c83bbb7da3ada6c9575",
            "7e2fb065a86a439c8c892444f019501f",
            "0dd99858923445ef8db5cb044c02b04c",
            "8fd2792d1d1947a18a4eab739740c4a6",
            "917f6704c7254a1a93ae0b7e8d441b8f",
            "5ced347ceb7a4100bb5cbe034f5e499d",
            "177d90beb5e34e6ea17420efe41f8b67",
            "b03e9e56b3844e0c96a08bcb1d10af75",
            "1cb9742701954af29d3dfc7086931dda",
            "11639bf11a954c4db38d8f7e8e9de290",
            "40745e58ef6f4d42916e24b17f8115f7",
            "e70f83dc96754dfb953f153e75e0760b",
            "73f08d0539944fdaa047fd7f2587bf39",
            "2859aaf51f4b431fb61180502d08fb82",
            "51c81b531e8e4b58b2f7263781001541",
            "35ac5c980174488c81eab6a89f4679f6",
            "a8754fc8e32a434b8784c0b53219846c",
            "8b13110ca57e4a9da78f49cea1526d36"
          ]
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14a1a34e8050417884d020d4a18092f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2ee900c2c714d9ba0f84bc64929fffb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a31ea57f11f4d4ea993047242f0f854"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b03e9e56b3844e0c96a08bcb1d10af75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bert loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice for the maximum length of the BERT encodings is 70 because\n",
        "it is slightly above the sum of the 90-th percentile of the lengths of premises, stances and conclusions.\n",
        "It is longer with respect to the maximum number of words for the GloVe model,\n",
        "since BERT-encoded vectors are much more dense."
      ],
      "metadata": {
        "id": "R8L68FX3Q8MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words_bert = 70\n",
        "# collate function that uses the tokenizer relative to the bert pretrained model\n",
        "def bert_vectorize_batch(batch):\n",
        "  \"\"\"\n",
        "  Collate function to preprocess the data for the BERT-based models.\n",
        "  In particular it joins premises, stances and conclusions in the same string,\n",
        "  separated by the [SEP] token.\n",
        "  Using the appropriate tokenizer, arguments are tokenized, truncated and padded.\n",
        "  Target labels are already one-hot encoded.\n",
        "\n",
        "  Params:\n",
        "    batch: batch of data to be preprocessed\n",
        "  Returns:\n",
        "    X_tensor: a tensor containing a torch tensor containing the input_ids, the token_type_ids and the\n",
        "              attention_mask for each example of the batch, which has shape:\n",
        "              (3, batch_size, max_words_bert)\n",
        "    Y_tensor: a tensor containing labels, which has shape\n",
        "              (batch_size, num_classes)\n",
        "  \"\"\"\n",
        "  X = [elem[\"Premise\"] + \" [SEP] \" + elem[\"Stance\"] + \" [SEP] \" + elem[\"Conclusion\"] for elem in batch]\n",
        "  Y = [elem[\"labels\"] for elem in batch]\n",
        "  X = bert_tokenizer(X, padding=\"max_length\", truncation=\"longest_first\", return_tensors = \"pt\", max_length = max_words_bert) \n",
        "  Y_tensor = torch.zeros(len(batch), Y[0].shape[0])\n",
        "  for i, tokens in enumerate(Y):    \n",
        "      Y_tensor[i] = Y[i]\n",
        "  X_tensor = torch.stack([X[\"input_ids\"], X[\"token_type_ids\"], X[\"attention_mask\"]])\n",
        "\n",
        "  return X_tensor, Y_tensor\n",
        "\n",
        "train_dataset = whole_dataset[\"train\"]\n",
        "val_dataset = whole_dataset[\"val\"] \n",
        "test_dataset = whole_dataset[\"test\"] "
      ],
      "metadata": {
        "id": "gCwN1D6evfAF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class BertLSTM(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the BERT + LSTM model.\n",
        "  Remark: max_words_bert and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self, bert_model):\n",
        "    # the single parameter of this init function is the bert model \n",
        "    # that has to be used for transfer learning\n",
        "    super(BertLSTM, self).__init__() \n",
        "    self.lstm_layers = 2\n",
        "    self.lstm_hs = 128 # hidden size of the lstm\n",
        "    bert_hidden_size = bert_model.config.hidden_size\n",
        "\n",
        "    # freezing the parameters for the BERT model\n",
        "    self.bert_model = bert_model\n",
        "    for param in self.bert_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=bert_hidden_size,\n",
        "                        hidden_size=self.lstm_hs,\n",
        "                        num_layers=self.lstm_layers ,\n",
        "                        batch_first=True,\n",
        "                        bidirectional=True)\n",
        "    self.reducer_c0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "    self.reducer_h0 = nn.Linear(bert_hidden_size, self.lstm_hs)\n",
        "    self.linear_1 = nn.Linear(self.lstm_hs*2*self.lstm_layers, self.lstm_hs)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(self.lstm_hs, num_classes) # since the dimensions\n",
        "    # are already small there is no need for a third linear layer\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    #Remark: The LSTM layer does not contain the encoding of the [CLS] token\n",
        "    #since it is used to initialize the hidden and cell states.\n",
        "    out = self.bert_model(input_ids=X_batch[0], token_type_ids = X_batch[1], attention_mask = X_batch[2])\n",
        "    cell = self.reducer_c0(out.pooler_output)\n",
        "    hidden = self.reducer_h0(out.pooler_output)\n",
        "    out = out.last_hidden_state[:,1:,:]\n",
        "    c0 = torch.stack([cell,cell,cell,cell]) \n",
        "    h0 = torch.stack([hidden, hidden, hidden, hidden])\n",
        "    out_lstm, hc_n  = self.lstm(out, (h0, c0))\n",
        "    c_n = hc_n[1].permute(1, 0, 2) # permutation in order to obtain the batch \n",
        "                                   # size dimension first\n",
        "    out = torch.cat([c_n[:,0,:], c_n[:,1,:]], 1) # concatenation of the cell states\n",
        "    out2 = torch.cat([c_n[:,2,:], c_n[:,3,:]], 1)\n",
        "    out = torch.cat([out, out2], 1)\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "oEb_5p623uWU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training informations\n",
        "The training was performed considering a maximum of 50 epochs with the following parameters for early stopping: patience equal to 3 epochs and delta equal to 1e-4. Batch size, learning rate and number of parameters for the layers were tuned by hand considering the results on the validation set.\n",
        "In particular the following pools were considered:\n",
        "- batch_size in \\{16, 32, 64\\}\n",
        "- learning rate in \\{1e-2, 1e-3, 1e-4\\}\n",
        "- hidden size of the LSTM layers in \\{128, 256, 512\\}\n",
        "- neurons of the linear layers in \\{256, 128\\}"
      ],
      "metadata": {
        "id": "W4rjn0z2TTTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "prebert_classifier = BertLSTM(bert_model)\n",
        "optimizer = Adam(prebert_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "bert_train_loader = DataLoader(whole_dataset[\"train\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(whole_dataset[\"val\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(whole_dataset[\"test\"], batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "prebert_classifier.to(device)\n",
        "summary(prebert_classifier, \n",
        "                input_data=next(iter(bert_train_loader))[0],\n",
        "                device=device)"
      ],
      "metadata": {
        "id": "1sU40iio3-4l",
        "outputId": "a2e0eb8c-10be-41ef-8c17-0966a418c2da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "BertLSTM                                                [32, 20]                  --\n",
              "├─BertModel: 1-1                                        [32, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [32, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [32, 70, 768]             (23,440,896)\n",
              "│    │    └─Embedding: 3-2                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              (393,216)\n",
              "│    │    └─LayerNorm: 3-4                              [32, 70, 768]             (1,536)\n",
              "│    │    └─Dropout: 3-5                                [32, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [32, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        (85,054,464)\n",
              "│    └─BertPooler: 2-3                                  [32, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [32, 768]                 (590,592)\n",
              "│    │    └─Tanh: 3-8                                   [32, 768]                 --\n",
              "├─Linear: 1-2                                           [32, 128]                 98,432\n",
              "├─Linear: 1-3                                           [32, 128]                 98,432\n",
              "├─LSTM: 1-4                                             [32, 69, 256]             1,314,816\n",
              "├─Linear: 1-5                                           [32, 128]                 65,664\n",
              "├─ReLU: 1-6                                             [32, 128]                 --\n",
              "├─Linear: 1-7                                           [32, 20]                  2,580\n",
              "=========================================================================================================\n",
              "Total params: 111,062,164\n",
              "Trainable params: 1,579,924\n",
              "Non-trainable params: 109,482,240\n",
              "Total mult-adds (G): 6.40\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 1863.20\n",
              "Params size (MB): 444.25\n",
              "Estimated Total Size (MB): 2307.50\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "prebert_classifier = TrainModel(prebert_classifier, loss_fn, optimizer, bert_train_loader, bert_val_loader, epochs, {\"patience\": 3, \"delta\": 1e-4}, \"bertencoder\")"
      ],
      "metadata": {
        "id": "qr86sx6J4cJY",
        "outputId": "ce0d5850-ae24-4ccd-9c5b-744f6284505b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 39/131 [06:59<16:30, 10.77s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2ecaca82f26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfix_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprebert_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprebert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_val_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"patience\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"delta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bertencoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-c36c6f0c2fea>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m           \u001b[0mY_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-255c434413c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#Remark: The LSTM layer does not contain the encoding of the [CLS] token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#since it is used to initialize the hidden and cell states.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer_c0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer_h0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         )\n\u001b[0;32m-> 1019\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    607\u001b[0m                 )\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    610\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT+LSTM:\")\n",
        "print_report(prebert_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "n_wI6jIOW4xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT fine tuning\n",
        "The following model is simply a fine tuned version of the BERT model on the reference dataset and it is proposed as an alternative to the previous models.\n",
        "In particular a similar model has been proposed by the authors of the dataset, hence it can be used as a reference point, since the datasets are not exacly equal.\n",
        "\n",
        "The architecture is a simple fine tuning of BERT followed by two linear layers which elaborate its pooler-output and reduce its dimension to num_classes.\n",
        "It is a common architecture that employs BERT in order to perform multi-label text classification."
      ],
      "metadata": {
        "id": "lzk-QUXGT6F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model to perform some tests with pytorch\n",
        "class FineTunedBert(nn.Module):\n",
        "  \"\"\"\n",
        "  Class implementing the model that allows to fine-tune BERT for this task.\n",
        "  Remark: max_words_bert and num_classes are parameters\n",
        "          used to create this architecture which are set outside the class.\n",
        "  \"\"\"\n",
        "  def __init__(self, bert_model):\n",
        "    # the single parameter of this init function is the bert model \n",
        "    # that has to be used for fine-tuning\n",
        "    super(FineTunedBert, self).__init__() \n",
        "    self.bert_model = bert_model\n",
        "    for param in self.bert_model.parameters():\n",
        "        param.requires_grad = True\n",
        "    bert_hidden_size = bert_model.config.hidden_size\n",
        "    self.linear_1 = nn.Linear(bert_hidden_size, bert_hidden_size//2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(bert_hidden_size//2, num_classes)\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    out = self.bert_model(input_ids=X_batch[0], \n",
        "                          token_type_ids = X_batch[1],\n",
        "                          attention_mask = X_batch[2])\n",
        "\n",
        "    out = out.last_hidden_state[:,0,:]\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    return out\n",
        "\n",
        "# Training function\n",
        "def finetune_bert(model, loss_fn, optimizer, train_loader, val_loader, epochs, early_stopping_info, model_name, scheduler):\n",
        "  \"\"\"\n",
        "  Training function for the fine-tuning of BERT. if arly_stopping_info info is set\n",
        "  to None, early stopping is not performed.\n",
        "  Params:\n",
        "    model: the model that has to be fine-tuned\n",
        "    loss_fn: the loss function to adopt in order to perform the training\n",
        "    optimizer: the optimizer to be used for training\n",
        "    train_loader: the dataloader for the training dataset\n",
        "    val_loader: the dataloader for the validation dataset\n",
        "    epochs: the number of epochs for training\n",
        "    early_stopping_info: dictionary containing the parameters for the early stopping:\n",
        "                          - delta: min acceptable improvement in the validation loss\n",
        "                          - patience: number of epochs to wait for improvement\n",
        "    model_name: string containing the name of the model (used in order to save\n",
        "                the weights)\n",
        "    scheduler: the learning rate scheduler to be applied (it is a step scheduler)\n",
        "  Returns:\n",
        "    model: the trained model\n",
        "  \"\"\"\n",
        "  patience_acc = 0\n",
        "  precedent_loss = np.Inf\n",
        "  model.train()\n",
        "  for i in range(1, epochs+1):\n",
        "      losses = []\n",
        "      for X, Y in tqdm(train_loader):\n",
        "          model.zero_grad()\n",
        "          Y_preds = model(X)\n",
        "          loss = loss_fn(Y_preds, Y)\n",
        "          losses.append(loss.item())\n",
        "\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "\n",
        "      loss = compute_validation_loss(model, loss_fn, val_loader)\n",
        "      print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "      if early_stopping_info != None:\n",
        "        if precedent_loss - loss < early_stopping_info[\"delta\"]:\n",
        "            patience_acc = patience_acc + 1\n",
        "        else:\n",
        "          patience_acc = 0\n",
        "          precedent_loss = loss\n",
        "          torch.save(model, model_name + \"_best.pth\")\n",
        "\n",
        "        if patience_acc > early_stopping_info[\"patience\"]:\n",
        "          return torch.load(model_name + \"best.pth\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "L2AFayf470lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_unfrozen = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model_unfrozen.to(device)\n",
        "print(\"reloaded\")"
      ],
      "metadata": {
        "outputId": "a82c4c7e-64a5-4276-ef71-41a3b0ddd51e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLK5mrMjAMAj"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training informations\n",
        "The training recipe and the model were adapted from the following tutorial:<br>\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
        "<br>\n",
        "As suggested in the tutorial the AdamW optimizer was used, the gradients were clipped to 1 and hyperparameters were drawn from the following pools:\n",
        "- batch_size in \\{16, 32\\}\n",
        "- learning rate in {5e-5, 3e-5, 2e-5}\n",
        "- number of epochs in \\{2, 3, 4\\}, but also 5 and 6 were tested. With 6 epochs the validation loss goes a little bit up, but returns better F1 scores.\n",
        "- the number of neurons of the linear layers are obtained by progressively halving the output of the BERT model"
      ],
      "metadata": {
        "id": "FiGEQaXlZgwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 6\n",
        "learning_rate = 5e-5\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "finetune_classifier = FineTunedBert(bert_model_unfrozen)\n",
        "optimizer = AdamW(finetune_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
        "\n",
        "\n",
        "bert_train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_val_loader  = DataLoader(val_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "bert_test_loader  = DataLoader(test_dataset, batch_size=batch_size, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
        "                                            num_training_steps=len(bert_train_loader)*epochs)\n",
        "\n",
        "finetune_classifier.to(device)\n",
        "summary(finetune_classifier, input_data=next(iter(bert_train_loader))[0], device=device, dtypes = [torch.int]*3)"
      ],
      "metadata": {
        "id": "v1bsrMwW_KYH",
        "outputId": "cd3c13ad-15e6-423b-bbcf-e0e93b58ba82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "FineTunedBert                                           [16, 20]                  --\n",
              "├─BertModel: 1-1                                        [16, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                              [16, 70, 768]             --\n",
              "│    │    └─Embedding: 3-1                              [16, 70, 768]             23,440,896\n",
              "│    │    └─Embedding: 3-2                              [16, 70, 768]             1,536\n",
              "│    │    └─Embedding: 3-3                              [1, 70, 768]              393,216\n",
              "│    │    └─LayerNorm: 3-4                              [16, 70, 768]             1,536\n",
              "│    │    └─Dropout: 3-5                                [16, 70, 768]             --\n",
              "│    └─BertEncoder: 2-2                                 [16, 70, 768]             --\n",
              "│    │    └─ModuleList: 3-6                             --                        85,054,464\n",
              "│    └─BertPooler: 2-3                                  [16, 768]                 --\n",
              "│    │    └─Linear: 3-7                                 [16, 768]                 590,592\n",
              "│    │    └─Tanh: 3-8                                   [16, 768]                 --\n",
              "├─Linear: 1-2                                           [16, 384]                 295,296\n",
              "├─ReLU: 1-3                                             [16, 384]                 --\n",
              "├─Linear: 1-4                                           [16, 20]                  7,700\n",
              "=========================================================================================================\n",
              "Total params: 109,785,236\n",
              "Trainable params: 109,785,236\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.75\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.03\n",
              "Forward/backward pass size (MB): 929.55\n",
              "Params size (MB): 439.14\n",
              "Estimated Total Size (MB): 1368.72\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_random(seed)\n",
        "finetune_classifier = finetune_bert(finetune_classifier, \n",
        "                                   loss_fn, optimizer,\n",
        "                                   bert_train_loader,\n",
        "                                   bert_val_loader,\n",
        "                                   epochs,\n",
        "                                   None, \n",
        "                                   \"finebert\", scheduler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Bka5d2uStJ",
        "outputId": "41d0dcfa-c50d-4129-9021-94b6f73943b7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:00<00:00,  4.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.375\n",
            "Train Loss : 0.404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:00<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.346\n",
            "Train Loss : 0.323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:00<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.337\n",
            "Train Loss : 0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:05<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.340\n",
            "Train Loss : 0.241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:01<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.348\n",
            "Train Loss : 0.211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [01:01<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss : 0.347\n",
            "Train Loss : 0.193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINETUNED BERT:\")\n",
        "print_report(finetune_classifier, bert_val_loader, whole_dataset[\"val\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c47278-7684-401f-e195-94cfb4ca40b0",
        "id": "igiHgAFsvifc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINETUNED BERT:\n",
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.4093\n",
            "  Precision:\t0.4833\n",
            "  Recall:\t0.4225\n",
            "  Accuracy:\t0.8433\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3969\t\t0.2914\t\t0.622\t\t0.8726\t\t82\n",
            "  Self-direction: action    \t0.562\t\t0.5203\t\t0.6109\t\t0.7707\t\t293\n",
            "  Stimulation               \t0.1132\t\t0.3\t\t0.0698\t\t0.9614\t\t43\n",
            "  Hedonism                  \t0.2564\t\t0.7143\t\t0.1562\t\t0.9762\t\t32\n",
            "  Achievement               \t0.6394\t\t0.5672\t\t0.7328\t\t0.7535\t\t363\n",
            "  Power: dominance          \t0.2553\t\t0.3934\t\t0.189\t\t0.885\t\t127\n",
            "  Power: resources          \t0.6087\t\t0.6109\t\t0.6065\t\t0.8225\t\t277\n",
            "  Face                      \t0.0632\t\t0.5\t\t0.0337\t\t0.9269\t\t89\n",
            "  Security: personal        \t0.7166\t\t0.6644\t\t0.7778\t\t0.7453\t\t504\n",
            "  Security: societal        \t0.7126\t\t0.6766\t\t0.7528\t\t0.774\t\t453\n",
            "  Tradition                 \t0.323\t\t0.3514\t\t0.2989\t\t0.9104\t\t87\n",
            "  Conformity: rules         \t0.5231\t\t0.4713\t\t0.5878\t\t0.7543\t\t279\n",
            "  Conformity: interpersonal \t0.0656\t\t0.4\t\t0.0357\t\t0.9532\t\t56\n",
            "  Humility                  \t0.1538\t\t0.3636\t\t0.0976\t\t0.9277\t\t82\n",
            "  Benevolence: caring       \t0.4062\t\t0.3869\t\t0.4276\t\t0.6878\t\t304\n",
            "  Benevolence: dependability\t0.2798\t\t0.2477\t\t0.3214\t\t0.7716\t\t168\n",
            "  Universalism: concern     \t0.6589\t\t0.5935\t\t0.7404\t\t0.6869\t\t497\n",
            "  Universalism: nature      \t0.7737\t\t0.8413\t\t0.7162\t\t0.9745\t\t74\n",
            "  Universalism: tolerance   \t0.3529\t\t0.5\t\t0.2727\t\t0.9096\t\t110\n",
            "  Universalism: objectivity \t0.324\t\t0.2723\t\t0.4\t\t0.8012\t\t145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the models\n",
        "As also indicated in the paper describing the dataset, the task of extracting values from arguments is inevitabily dependant on the cultural background of the people expressing them. For this reason, the models are evalueted both on our test split (original validation split) and on the dataset split extracted by a chinese-background source.\n",
        "The reference evaluation scores are the macro F1s, but we also provide macro inter-class precision, recall and accuracy.\n",
        "We also tuned the threshold needed to obtain hard labels. The default should be 0.5, but we decided to lower it to 0.25 in order to sacrifice a bit of precision and gain an improvement to the recall and thus obtain a better F1 score. \n",
        "Since the threshold is an hyperparameter of the model, tuning was **not** meant to be a way to artifically increase F1-scores."
      ],
      "metadata": {
        "id": "U_pijllXe9j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on the set with the same cultural background\n",
        "We first present and discuss the results on the dataset with same source as the training dataset."
      ],
      "metadata": {
        "id": "8aKWwVBbypB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GloVe BASELINE:\")\n",
        "print_report(embed_classifier, test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzg9AFc-fsQj",
        "outputId": "a5da1a86-69c8-4349-e305-ce44612884b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3205\n",
            "  Precision:\t0.4084\n",
            "  Recall:\t0.3944\n",
            "  Accuracy:\t0.7883\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3327\t\t0.3134\t\t0.3546\t\t0.8117\t\t251\n",
            "  Self-direction: action    \t0.4677\t\t0.3729\t\t0.627\t\t0.6266\t\t496\n",
            "  Stimulation               \t0.0284\t\t0.6667\t\t0.0145\t\t0.9277\t\t138\n",
            "  Hedonism                  \t0.0377\t\t0.6667\t\t0.0194\t\t0.9462\t\t103\n",
            "  Achievement               \t0.5364\t\t0.497\t\t0.5826\t\t0.6946\t\t575\n",
            "  Power: dominance          \t0.2591\t\t0.3855\t\t0.1951\t\t0.9035\t\t164\n",
            "  Power: resources          \t0.4324\t\t0.3902\t\t0.4848\t\t0.9114\t\t132\n",
            "  Face                      \t0.0153\t\t1.0\t\t0.0077\t\t0.932\t\t130\n",
            "  Security: personal        \t0.6647\t\t0.5284\t\t0.8959\t\t0.6382\t\t759\n",
            "  Security: societal        \t0.555\t\t0.4833\t\t0.6516\t\t0.731\t\t488\n",
            "  Tradition                 \t0.338\t\t0.3279\t\t0.3488\t\t0.8761\t\t172\n",
            "  Conformity: rules         \t0.474\t\t0.3485\t\t0.7407\t\t0.6055\t\t455\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9684\t\t60\n",
            "  Humility                  \t0.0408\t\t0.15\t\t0.0236\t\t0.9256\t\t127\n",
            "  Benevolence: caring       \t0.4784\t\t0.4225\t\t0.5513\t\t0.5986\t\t633\n",
            "  Benevolence: dependability\t0.1298\t\t0.1824\t\t0.1007\t\t0.8091\t\t268\n",
            "  Universalism: concern     \t0.5824\t\t0.4667\t\t0.7744\t\t0.5976\t\t687\n",
            "  Universalism: nature      \t0.5252\t\t0.4834\t\t0.5748\t\t0.9304\t\t127\n",
            "  Universalism: tolerance   \t0.1246\t\t0.2317\t\t0.0852\t\t0.8592\t\t223\n",
            "  Universalism: objectivity \t0.388\t\t0.251\t\t0.8544\t\t0.4726\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT+LSTM\")\n",
        "print_report(prebert_classifier, bert_test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De3leoMYfsJj",
        "outputId": "46658121-bc7b-4772-e681-4c781dc077ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.3782\n",
            "  Precision:\t0.3753\n",
            "  Recall:\t0.4381\n",
            "  Accuracy:\t0.7967\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3542\t\t0.3868\t\t0.3267\t\t0.8423\t\t251\n",
            "  Self-direction: action    \t0.4701\t\t0.4125\t\t0.5464\t\t0.6777\t\t496\n",
            "  Stimulation               \t0.2479\t\t0.2885\t\t0.2174\t\t0.904\t\t138\n",
            "  Hedonism                  \t0.3429\t\t0.4167\t\t0.2913\t\t0.9393\t\t103\n",
            "  Achievement               \t0.5948\t\t0.4837\t\t0.7722\t\t0.6809\t\t575\n",
            "  Power: dominance          \t0.217\t\t0.4792\t\t0.1402\t\t0.9124\t\t164\n",
            "  Power: resources          \t0.3465\t\t0.3607\t\t0.3333\t\t0.9124\t\t132\n",
            "  Face                      \t0.1804\t\t0.184\t\t0.1769\t\t0.8898\t\t130\n",
            "  Security: personal        \t0.7118\t\t0.6117\t\t0.8511\t\t0.7242\t\t759\n",
            "  Security: societal        \t0.6085\t\t0.6168\t\t0.6004\t\t0.8012\t\t488\n",
            "  Tradition                 \t0.4263\t\t0.4626\t\t0.3953\t\t0.9035\t\t172\n",
            "  Conformity: rules         \t0.4841\t\t0.3528\t\t0.7714\t\t0.6055\t\t455\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.9684\t\t60\n",
            "  Humility                  \t0.0779\t\t0.2222\t\t0.0472\t\t0.9251\t\t127\n",
            "  Benevolence: caring       \t0.5101\t\t0.4689\t\t0.5592\t\t0.6414\t\t633\n",
            "  Benevolence: dependability\t0.2661\t\t0.1721\t\t0.5858\t\t0.5432\t\t268\n",
            "  Universalism: concern     \t0.543\t\t0.4601\t\t0.6623\t\t0.596\t\t687\n",
            "  Universalism: nature      \t0.5513\t\t0.4649\t\t0.6772\t\t0.9262\t\t127\n",
            "  Universalism: tolerance   \t0.1812\t\t0.3256\t\t0.1256\t\t0.8666\t\t223\n",
            "  Universalism: objectivity \t0.4498\t\t0.3355\t\t0.6819\t\t0.6735\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINETUNING BERT:\")\n",
        "print_report(finetune_classifier, bert_test_loader, whole_dataset[\"test\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szR1bBY3fr_a",
        "outputId": "9f552450-6f84-46c9-bee3-6df9e9ad116f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.4078\n",
            "  Precision:\t0.4789\n",
            "  Recall:\t0.4267\n",
            "  Accuracy:\t0.8336\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.4884\t\t0.4169\t\t0.5896\t\t0.8365\t\t251\n",
            "  Self-direction: action    \t0.5435\t\t0.5173\t\t0.5726\t\t0.7484\t\t496\n",
            "  Stimulation               \t0.2286\t\t0.5405\t\t0.1449\t\t0.9288\t\t138\n",
            "  Hedonism                  \t0.229\t\t0.5357\t\t0.1456\t\t0.9467\t\t103\n",
            "  Achievement               \t0.6338\t\t0.549\t\t0.7496\t\t0.7373\t\t575\n",
            "  Power: dominance          \t0.3134\t\t0.4038\t\t0.2561\t\t0.903\t\t164\n",
            "  Power: resources          \t0.4096\t\t0.3727\t\t0.4545\t\t0.9088\t\t132\n",
            "  Face                      \t0.0576\t\t0.4444\t\t0.0308\t\t0.9309\t\t130\n",
            "  Security: personal        \t0.7317\t\t0.6576\t\t0.8248\t\t0.7579\t\t759\n",
            "  Security: societal        \t0.6129\t\t0.5446\t\t0.7008\t\t0.7722\t\t488\n",
            "  Tradition                 \t0.3956\t\t0.5347\t\t0.314\t\t0.913\t\t172\n",
            "  Conformity: rules         \t0.5083\t\t0.5088\t\t0.5077\t\t0.7642\t\t455\n",
            "  Conformity: interpersonal \t0.0635\t\t0.6667\t\t0.0333\t\t0.9689\t\t60\n",
            "  Humility                  \t0.1006\t\t0.1731\t\t0.0709\t\t0.9151\t\t127\n",
            "  Benevolence: caring       \t0.5824\t\t0.5133\t\t0.673\t\t0.6777\t\t633\n",
            "  Benevolence: dependability\t0.3011\t\t0.2431\t\t0.3955\t\t0.7405\t\t268\n",
            "  Universalism: concern     \t0.6213\t\t0.5143\t\t0.7846\t\t0.6535\t\t687\n",
            "  Universalism: nature      \t0.6432\t\t0.73\t\t0.5748\t\t0.9573\t\t127\n",
            "  Universalism: tolerance   \t0.232\t\t0.3022\t\t0.1883\t\t0.8534\t\t223\n",
            "  Universalism: objectivity \t0.4586\t\t0.4084\t\t0.5229\t\t0.7584\t\t371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that, starting from the macro aggregation, that the distribution of scores is almost the same as the one registered on the validation set. In general the GloVe baseline reaches around 30-32% of F1, the BERT+LSTM reaches 35-37% F1 and the Finetuned BERT reaches almost 41% F1. \n",
        "we can also see as the scores in general increment from the simplest model to the most complex, expecially in terms of precision, while the recall remains almost the same, probably due to the usage of the same conversion threshold for each model. <br>\n",
        "If one wants to focus more on the per-class F1 scores, they remain almost the same w.r.t. the validation, except some higher fluctuations (> +/- 7%) common on all models:\n",
        "- \"Tradition\", \"Stimulation\", \"Benevolence: caring\" and \"Universalism: objectivity\" which seem all to increment in the test set\n",
        "- \"Power: resources\", \"Security: Societal\", \"Universalism:Tolerance\" which all seem to decrement.\n",
        "Since this consistent decrements correspond to the classes that have a slightly skewed distribution with respect to the validation set, we can address this fluctuation to change in distribution.\n",
        "\n",
        "Then, we can also individuate the most difficult classes (\\<25\\% F1) being the one under-represented in the training set: \"Stimulation\", \"Hedonism\", \"Face\", \"Conformity:Interpersonal\", \"Humility\".\n",
        "Also \"Universalism:Tolerance\" seems to be quite misclassified, despite having a consistent support."
      ],
      "metadata": {
        "id": "CIsEKd_byoMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_index_label(label_cols, label):\n",
        "  \"\"\"\n",
        "  Function returning the index of the label from the ordered list of labels.\n",
        "  Params:\n",
        "    label_cols: ordered list of labels\n",
        "  Returns: \n",
        "    the index of label in label_cols\n",
        "  \"\"\"\n",
        "  return label_cols.index(label)\n",
        "\n",
        "def labels_array_to_names(labels, label_cols):\n",
        "  \"\"\"\n",
        "  Function converting the binary multi-label arrays into a list of the names\n",
        "  corresponding to the \"1\" values.\n",
        "  Params:\n",
        "    labels: binary labels to be converted\n",
        "    label_cols:  ordered list of labels\n",
        "  returns: \n",
        "    the list containing the label names marked as \"1\" in labels\n",
        "  \"\"\"\n",
        "  return [label_cols[idx] for idx, label in enumerate(labels) if label == 1]\n",
        "\n",
        "def get_true_preds_from_label(model, loader, label, label_cols, threshold=0.25):\n",
        "  \"\"\"\n",
        "  Function returning the true labels and the predicted labels associated to category\n",
        "  in form of lists of category names.\n",
        "  Params:\n",
        "    model: model to be used to produce predictions\n",
        "    loader: dataloader for the dataset to be used\n",
        "    label: target label to extract from the dataset\n",
        "    label_cols: ordered list of labels\n",
        "    threshold: threshold used to convert scores to hard labels. Defaults to .25\n",
        "  Returns:\n",
        "    return_true: list of true labels of examples being labeled as label\n",
        "    return_preds: list of predicted labels of the corresponding examples in return_true\n",
        "  \"\"\"\n",
        "  _y_preds = []\n",
        "  y_true = []\n",
        "\n",
        "  model.eval()\n",
        "  for X, Y in loader:\n",
        "    preds = model(X)\n",
        "    y_true.extend(Y.cpu().numpy())\n",
        "    _y_preds.append(preds)\n",
        "  \n",
        "  gc.collect()\n",
        "  _y_preds = torch.cat(_y_preds)\n",
        "  _y_preds = _y_preds.sigmoid()\n",
        "  _y_preds = _y_preds.detach()\n",
        "\n",
        "  y_preds = []\n",
        "  for i in range(_y_preds.shape[0]):\n",
        "    y_preds.append([1 if _y_preds[i][j] > threshold else 0 for j in range(_y_preds.shape[1])])\n",
        "\n",
        "  index_label = get_index_label(label_cols, label) if type(label) != int else label\n",
        "  if index_label >= num_classes:\n",
        "    return\n",
        "\n",
        "  return_true = []\n",
        "  return_preds = []\n",
        "  for idx, y in enumerate(y_true):\n",
        "    if y[index_label] == 1:\n",
        "      return_true.append(labels_array_to_names(y_true[idx], label_cols))\n",
        "      return_preds.append(labels_array_to_names(y_preds[idx], label_cols))\n",
        "\n",
        "  return return_true, return_preds"
      ],
      "metadata": {
        "id": "k7Tlz_II7saj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true, preds = get_true_preds_from_label(prebert_classifier, bert_val_loader, \"Universalism: Tolerance\", label_list)\n"
      ],
      "metadata": {
        "id": "oNL6UtlLNadt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation on the set with a different cultural background\n"
      ],
      "metadata": {
        "id": "Ij_p4-VE5GZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in vectorize_batch(x)))\n",
        "bert_chn_loader = DataLoader(whole_dataset[\"test_chn\"], batch_size=32, collate_fn=lambda x:tuple(y.to(device) for y in bert_vectorize_batch(x)))"
      ],
      "metadata": {
        "id": "RjbLllyCSzCT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(embed_classifier, chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "62tEI5umoyte",
        "outputId": "a9dccb89-e238-4093-9372-c39fbde1681a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.253\n",
            "  Precision:\t0.1887\n",
            "  Recall:\t0.4269\n",
            "  Accuracy:\t0.765\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.1875\t\t0.1154\t\t0.5\t\t0.74\t\t6\n",
            "  Self-direction: action    \t0.3333\t\t0.2258\t\t0.6364\t\t0.72\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t0\n",
            "  Hedonism                  \t0.5\t\t0.5\t\t0.5\t\t0.98\t\t2\n",
            "  Achievement               \t0.6034\t\t0.4545\t\t0.8974\t\t0.54\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.91\t\t1\n",
            "  Power: resources          \t0.4\t\t0.3226\t\t0.5263\t\t0.7\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.4538\t\t0.3034\t\t0.9\t\t0.35\t\t30\n",
            "  Security: societal        \t0.4471\t\t0.3519\t\t0.6129\t\t0.53\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t0.98\t\t0\n",
            "  Conformity: rules         \t0.35\t\t0.28\t\t0.4667\t\t0.74\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.94\t\t5\n",
            "  Benevolence: caring       \t0.2264\t\t0.1463\t\t0.5\t\t0.59\t\t12\n",
            "  Benevolence: dependability\t0.08\t\t0.0455\t\t0.3333\t\t0.77\t\t3\n",
            "  Universalism: concern     \t0.5067\t\t0.3519\t\t0.9048\t\t0.63\t\t21\n",
            "  Universalism: nature      \t0.5385\t\t0.3889\t\t0.875\t\t0.88\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.93\t\t2\n",
            "  Universalism: objectivity \t0.434\t\t0.2875\t\t0.8846\t\t0.4\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(prebert_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "o9mxpo4jorh4",
        "outputId": "f52ba3f5-bb4b-459d-dd4d-4891189b99a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.2583\n",
            "  Precision:\t0.2014\n",
            "  Recall:\t0.4301\n",
            "  Accuracy:\t0.792\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.25\t\t0.1538\t\t0.6667\t\t0.76\t\t6\n",
            "  Self-direction: action    \t0.2899\t\t0.1724\t\t0.9091\t\t0.51\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.91\t\t0\n",
            "  Hedonism                  \t0.3333\t\t0.25\t\t0.5\t\t0.96\t\t2\n",
            "  Achievement               \t0.5873\t\t0.4253\t\t0.9487\t\t0.48\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Power: resources          \t0.3571\t\t0.2703\t\t0.5263\t\t0.64\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.96\t\t1\n",
            "  Security: personal        \t0.551\t\t0.3971\t\t0.9\t\t0.56\t\t30\n",
            "  Security: societal        \t0.4194\t\t0.4194\t\t0.4194\t\t0.64\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.4324\t\t0.3636\t\t0.5333\t\t0.79\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.375\t\t0.3\t\t0.5\t\t0.8\t\t12\n",
            "  Benevolence: dependability\t0.1111\t\t0.0606\t\t0.6667\t\t0.68\t\t3\n",
            "  Universalism: concern     \t0.5909\t\t0.5652\t\t0.619\t\t0.82\t\t21\n",
            "  Universalism: nature      \t0.4375\t\t0.2917\t\t0.875\t\t0.82\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t2\n",
            "  Universalism: objectivity \t0.4308\t\t0.359\t\t0.5385\t\t0.63\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_report(finetune_classifier, bert_chn_loader, whole_dataset[\"test_chn\"][\"labels\"], 0.25)"
      ],
      "metadata": {
        "id": "l8nyZS91oqwE",
        "outputId": "be8ef3a3-af59-4f59-ee41-ff8a20e86efd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- MACRO AVG. -----\n",
            "  F1-score:\t0.288\n",
            "  Precision:\t0.2386\n",
            "  Recall:\t0.4048\n",
            "  Accuracy:\t0.835\n",
            "----- PER-CLASS VALUES -----\n",
            "  \t\t\t\tF1-score\tPrecision\tRecall\t\tAccuracy\tSupport\n",
            "  Self-direction: thought   \t0.3704\t\t0.2381\t\t0.8333\t\t0.83\t\t6\n",
            "  Self-direction: action    \t0.36\t\t0.2308\t\t0.8182\t\t0.68\t\t11\n",
            "  Stimulation               \t0.0\t\t0.0\t\t0.0\t\t0.94\t\t0\n",
            "  Hedonism                  \t0.4\t\t0.3333\t\t0.5\t\t0.97\t\t2\n",
            "  Achievement               \t0.6214\t\t0.5\t\t0.8205\t\t0.61\t\t39\n",
            "  Power: dominance          \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Power: resources          \t0.4643\t\t0.3514\t\t0.6842\t\t0.7\t\t19\n",
            "  Face                      \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Security: personal        \t0.4935\t\t0.4043\t\t0.6333\t\t0.61\t\t30\n",
            "  Security: societal        \t0.4857\t\t0.4359\t\t0.5484\t\t0.64\t\t31\n",
            "  Tradition                 \t0.0\t\t0.0\t\t0.0\t\t1.0\t\t0\n",
            "  Conformity: rules         \t0.3333\t\t0.2857\t\t0.4\t\t0.76\t\t15\n",
            "  Conformity: interpersonal \t0.0\t\t0.0\t\t0.0\t\t0.99\t\t1\n",
            "  Humility                  \t0.0\t\t0.0\t\t0.0\t\t0.95\t\t5\n",
            "  Benevolence: caring       \t0.3226\t\t0.2632\t\t0.4167\t\t0.79\t\t12\n",
            "  Benevolence: dependability\t0.0909\t\t0.0526\t\t0.3333\t\t0.8\t\t3\n",
            "  Universalism: concern     \t0.6296\t\t0.5152\t\t0.8095\t\t0.8\t\t21\n",
            "  Universalism: nature      \t0.7\t\t0.5833\t\t0.875\t\t0.94\t\t8\n",
            "  Universalism: tolerance   \t0.0\t\t0.0\t\t0.0\t\t0.94\t\t2\n",
            "  Universalism: objectivity \t0.4889\t\t0.5789\t\t0.4231\t\t0.77\t\t26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- osservare che i risultati sono molto più bassi per due motivi: non solo diversa cultura, gli esempi sono meno, due classi sono assenti, la distribuzione è un po' diversa rispetto a quella del training/validation/test originali\n",
        "- comunque si può rivedere lo stesso trend di aumento, soprattutto considerando l'incremento di precisione\n",
        "- osservare se le classi difficili sono le stesse"
      ],
      "metadata": {
        "id": "mH8FQHd85reX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(np.arange(20),[906,1102,204,140,1149,483,348,293,1496,1275,481,898,151,313,1028,638,1584,353,554,909])"
      ],
      "metadata": {
        "id": "8hJ-SbVt3EkM",
        "outputId": "34bbf990-805b-478e-b127-7bfcce6edbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(np.arange(20),[82,293,43,32,363,127,277,89,504,453,87,279,56,82,304,168,497,74,110,145])"
      ],
      "metadata": {
        "id": "RXf00aM53qm3",
        "outputId": "37c5bf6b-8dcc-4384-da00-dc7fac3a869e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(np.arange(20),[251,496,138,103,575,164,132,130,759,488,172,455,60,127,633,268,687,127,223,371])"
      ],
      "metadata": {
        "id": "vAAriOIQ4JyU",
        "outputId": "75b6d9eb-3964-48b1-bcb4-963a710fe485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS60lEQVR4nO3db4xc133e8e9TybIDxRX1Z8uyJFHaDeFAfWGZXShy4xqu2bgSHZhq4QgygohVWDBBpcJGEqRsA6Rp0Rdyi8aNikIFazmhAteWokQVYSuJWdpB0BdSspJlWbLsaCVIIAmK3MgylURIUyW/vpjDZLTe1c4sZ3aXOt8PMJh7zz137m/vzD5798ydO6kqJElvfn9tvQuQJK0NA1+SOmHgS1InDHxJ6oSBL0mduHi9CwC46qqraseOHetdhiRdUB599NE/rKqZUftviMDfsWMHc3Nz612GJF1QkrwwTn+HdCSpEwa+JHXCwJekThj4ktQJA1+SOmHgS1InDHxJ6oSBL0mdMPAlqRMb4pO20ih2HPzi2Os8f8eHp1CJdGHyCF+SOmHgS1InDHxJ6oSBL0mdMPAlqRMGviR1wsCXpE4Y+JLUCQNfkjph4EtSJwx8SeqEgS9JnVgx8JO8K8njQ7dXknwiyRVJjiZ5pt1f3vonyZ1J5pM8kWTX9H8MSdJKVgz8qvpWVV1TVdcAfw94FXgAOAgcq6qdwLE2D3ADsLPdDgB3TaNwSdJ4xh3S2Q08W1UvAHuBw639MHBjm94L3FMDDwObkmyZSLWSpFUbN/BvBj7XpjdX1ak2/SKwuU1vBY4PrXOitb1OkgNJ5pLMLSwsjFmGJGlcIwd+kkuAjwC/tnhZVRVQ42y4qg5V1WxVzc7MzIyzqiRpFcY5wr8BeKyqTrf50+eGatr9mdZ+Etg+tN621iZJWkfjfMXhx/ir4RyAI8A+4I52/+BQ++1JPg/8AHB2aOhHklbk11lOx0iBn+RS4IeAnxhqvgO4L8l+4AXgptb+ELAHmGdwRs+tE6tWkrRqIwV+Vf0JcOWitpcYnLWzuG8Bt02kOknSxPhJW0nqhIEvSZ0w8CWpEwa+JHXCwJekThj4ktQJA1+SOmHgS1InDHxJ6oSBL0mdMPAlqRMGviR1YpzLI0vqiJcofvPxCF+SOmHgS1InDHxJ6oSBL0mdMPAlqRMjBX6STUnuT/LNJE8neW+SK5IcTfJMu7+89U2SO5PMJ3kiya7p/giSpFGMeoT/S8BvVdX3A+8GngYOAseqaidwrM0D3ADsbLcDwF0TrViStCorBn6Sy4D3A3cDVNWfVdV3gL3A4dbtMHBjm94L3FMDDwObkmyZeOWSpLGMcoT/DmAB+OUkX03y6SSXApur6lTr8yKwuU1vBY4PrX+itb1OkgNJ5pLMLSwsrP4nkCSNZJTAvxjYBdxVVe8B/oS/Gr4BoKoKqHE2XFWHqmq2qmZnZmbGWVWStAqjBP4J4ERVPdLm72fwB+D0uaGadn+mLT8JbB9af1trkyStoxUDv6peBI4neVdr2g18AzgC7Gtt+4AH2/QR4JZ2ts51wNmhoR9J0joZ9eJp/xL4bJJLgOeAWxn8sbgvyX7gBeCm1vchYA8wD7za+kqS1tlIgV9VjwOzSyzavUTfAm47z7okSRPmJ20lqRNeD/8CNe61yr1OuSSP8CWpEwa+JHXCwJekThj4ktQJA1+SOmHgS1InDHxJ6oSBL0mdMPAlqRMGviR1wsCXpE4Y+JLUCQNfkjph4EtSJwx8SeqEgS9JnRgp8JM8n+TrSR5PMtfarkhyNMkz7f7y1p4kdyaZT/JEkl3T/AEkSaMZ5wj/H1bVNVV17rttDwLHqmoncKzNA9wA7Gy3A8BdkypWkrR65zOksxc43KYPAzcOtd9TAw8Dm5JsOY/tSJImYNTAL+BLSR5NcqC1ba6qU236RWBzm94KHB9a90Rre50kB5LMJZlbWFhYRemSpHGM+iXm76uqk0n+BnA0yTeHF1ZVJalxNlxVh4BDALOzs2OtO0l+GbikXox0hF9VJ9v9GeAB4Frg9LmhmnZ/pnU/CWwfWn1ba5MkraMVAz/JpUnefm4a+BDwJHAE2Ne67QMebNNHgFva2TrXAWeHhn4kSetklCGdzcADSc71/59V9VtJfh+4L8l+4AXgptb/IWAPMA+8Ctw68aqlVXD4Tr1bMfCr6jng3Uu0vwTsXqK9gNsmUp0kaWL8pK0kdcLAl6ROGPiS1AkDX5I6YeBLUicMfEnqhIEvSZ0Y9Vo6klZp3A98gR/60nR4hC9JnTDwJakTBr4kdcLAl6ROGPiS1AkDX5I6YeBLUicMfEnqhIEvSZ0w8CWpEwa+JHVi5MBPclGSryb5Qpt/R5JHkswnuTfJJa39rW1+vi3fMZ3SJUnjGOcI/+PA00PznwQ+VVXfB7wM7G/t+4GXW/unWj9J0jobKfCTbAM+DHy6zQf4IHB/63IYuLFN723ztOW7W39J0joa9Qj/vwA/C/xFm78S+E5VvdbmTwBb2/RW4DhAW3629X+dJAeSzCWZW1hYWGX5kqRRrRj4SX4YOFNVj05yw1V1qKpmq2p2ZmZmkg8tSVrCKF+A8oPAR5LsAd4G/HXgl4BNSS5uR/HbgJOt/0lgO3AiycXAZcBLE69ckjSWFY/wq+pfV9W2qtoB3Ax8uap+FPgK8NHWbR/wYJs+0uZpy79cVTXRqiVJYzuf8/D/FfBTSeYZjNHf3drvBq5s7T8FHDy/EiVJkzDWd9pW1e8Av9OmnwOuXaLPnwI/MoHaJEkT5CdtJakTBr4kdWKsIR1J0vJ2HPzi2Os8f8eHp1DJ0jzCl6ROGPiS1AkDX5I6YeBLUicMfEnqhIEvSZ0w8CWpEwa+JHXCwJekThj4ktQJA1+SOmHgS1InDHxJ6oSBL0mdMPAlqRMrBn6StyX5vSRfS/JUkn/X2t+R5JEk80nuTXJJa39rm59vy3dM90eQJI1ilCP8/wt8sKreDVwDXJ/kOuCTwKeq6vuAl4H9rf9+4OXW/qnWT5K0zlYM/Br44zb7lnYr4IPA/a39MHBjm97b5mnLdyfJxCqWJK3KSGP4SS5K8jhwBjgKPAt8p6pea11OAFvb9FbgOEBbfha4conHPJBkLsncwsLC+f0UkqQVjRT4VfXnVXUNsA24Fvj+891wVR2qqtmqmp2ZmTnfh5MkrWCss3Sq6jvAV4D3ApuSnPsS9G3AyTZ9EtgO0JZfBrw0kWolSas2ylk6M0k2tenvAX4IeJpB8H+0ddsHPNimj7R52vIvV1VNsmhJ0vguXrkLW4DDSS5i8Afivqr6QpJvAJ9P8h+ArwJ3t/53A7+aZB74NnDzFOqWJI1pxcCvqieA9yzR/hyD8fzF7X8K/MhEqpMkTYyftJWkThj4ktQJA1+SOjHKm7aSNLYdB784Vv/n7/jwlCrROR7hS1InDHxJ6oSBL0mduODH8McdJwTHCiX1ySN8SeqEgS9JnTDwJakTBr4kdcLAl6ROGPiS1AkDX5I6ccGfhy9Jk/RmvgaQR/iS1AkDX5I6McqXmG9P8pUk30jyVJKPt/YrkhxN8ky7v7y1J8mdSeaTPJFk17R/CEnSykY5wn8N+Omquhq4DrgtydXAQeBYVe0EjrV5gBuAne12ALhr4lVLksa2YuBX1amqeqxN/xHwNLAV2Ascbt0OAze26b3APTXwMLApyZaJVy5JGstYY/hJdgDvAR4BNlfVqbboRWBzm94KHB9a7URrW/xYB5LMJZlbWFgYs2xJ0rhGDvwk3wv8OvCJqnpleFlVFVDjbLiqDlXVbFXNzszMjLOqJGkVRgr8JG9hEPafrarfaM2nzw3VtPszrf0ksH1o9W2tTZK0jkY5SyfA3cDTVfWLQ4uOAPva9D7gwaH2W9rZOtcBZ4eGfiRJ62SUT9r+IPBjwNeTPN7a/g1wB3Bfkv3AC8BNbdlDwB5gHngVuHWiFUuSVmXFwK+q/wNkmcW7l+hfwG3nWZckacL8pK0kdcLAl6ROeLVMaQRv5isoqh8e4UtSJzzC75BHq1KfPMKXpE4Y+JLUCQNfkjph4EtSJwx8SeqEgS9JnfC0zPPg6Y2SLiQe4UtSJzzC19jO5z8b/yuS1o+BL72J9foHttefeyUO6UhSJwx8SeqEgS9JnRjlS8w/k+RMkieH2q5IcjTJM+3+8taeJHcmmU/yRJJd0yxekjS6UY7wfwW4flHbQeBYVe0EjrV5gBuAne12ALhrMmVKks7XioFfVb8LfHtR817gcJs+DNw41H5PDTwMbEqyZVLFSpJWb7WnZW6uqlNt+kVgc5veChwf6neitZ1CrzPuaWPQz6ljkqbjvN+0raoCatz1khxIMpdkbmFh4XzLkCStYLWBf/rcUE27P9PaTwLbh/pta23fpaoOVdVsVc3OzMyssgxJ0qhWG/hHgH1teh/w4FD7Le1sneuAs0NDP5KkdbTiGH6SzwEfAK5KcgL4t8AdwH1J9gMvADe17g8Be4B54FXg1inULElahRUDv6o+tsyi3Uv0LeC28y1KkjR5ftJWkjph4EtSJwx8SeqEgS9JnTDwJakTfuOVtMH57U2aFI/wJakTBr4kdcLAl6ROGPiS1AkDX5I6YeBLUicMfEnqhIEvSZ0w8CWpEwa+JHXCwJekThj4ktQJA1+SOjGVwE9yfZJvJZlPcnAa25AkjWfigZ/kIuC/ATcAVwMfS3L1pLcjSRrPNI7wrwXmq+q5qvoz4PPA3ilsR5I0hlTVZB8w+ShwfVX98zb/Y8APVNXti/odAA602XcB35poIXAV8IcTfsxJ2ai1bdS6YOPWtlHrgo1bm3WNb7na/nZVzYz6IOv2jVdVdQg4NK3HTzJXVbPTevzzsVFr26h1wcatbaPWBRu3Nusa36Rqm8aQzklg+9D8ttYmSVpH0wj83wd2JnlHkkuAm4EjU9iOJGkMEx/SqarXktwO/DZwEfCZqnpq0tsZwdSGiyZgo9a2UeuCjVvbRq0LNm5t1jW+idQ28TdtJUkbk5+0laROGPiS1IkLPvBXuoxDkrcmubctfyTJjjWqa3uSryT5RpKnknx8iT4fSHI2yePt9vNrVNvzSb7etjm3xPIkubPtsyeS7Fqjut41tC8eT/JKkk8s6rMm+yzJZ5KcSfLkUNsVSY4meabdX77Muvtan2eS7Fuj2v5Tkm+25+uBJJuWWfcNn/sp1PULSU4OPV97lll3apdjWaaue4dqej7J48usO7X91R5/yZyY2mutqi7YG4M3hZ8F3glcAnwNuHpRn38B/Pc2fTNw7xrVtgXY1abfDvzBErV9APjCOuy354Gr3mD5HuA3gQDXAY+s03P7IoMPlqz5PgPeD+wCnhxq+4/AwTZ9EPjkEutdATzX7i9v05evQW0fAi5u059cqrZRnvsp1PULwM+M8Fy/4e/xpOtatPw/Az+/1vurPf6SOTGt19qFfoQ/ymUc9gKH2/T9wO4kmXZhVXWqqh5r038EPA1snfZ2J2QvcE8NPAxsSrJljWvYDTxbVS+s8XYBqKrfBb69qHn4tXQYuHGJVf8xcLSqvl1VLwNHgeunXVtVfamqXmuzDzP4/MuaWmafjWKql2N5o7paFtwEfG5S2xvHG+TEVF5rF3rgbwWOD82f4LtD9S/7tF+Is8CVa1Jd04aR3gM8ssTi9yb5WpLfTPJ316ikAr6U5NF2iYvFRtmv03Yzy/8Srsc+A9hcVafa9IvA5iX6bIR99+MM/kNbykrP/TTc3oaaPrPM0MR67rN/AJyuqmeWWb5m+2tRTkzltXahB/6Gl+R7gV8HPlFVryxa/BiDIYt3A/8V+F9rVNb7qmoXgyua3pbk/Wu03ZFk8IG9jwC/tsTi9dpnr1OD/6k33DnNSX4OeA347DJd1vq5vwv4O8A1wCkGwycbycd446P7Ndlfb5QTk3ytXeiBP8plHP6yT5KLgcuAl9aiuCRvYfAkfraqfmPx8qp6par+uE0/BLwlyVXTrquqTrb7M8ADDP6lHrbel8e4AXisqk4vXrBe+6w5fW5oq92fWaLPuu27JP8M+GHgR1tIfJcRnvuJqqrTVfXnVfUXwP9YZnvrss9aHvxT4N7l+qzF/lomJ6byWrvQA3+UyzgcAc69e/1R4MvL/TJMUhsbvBt4uqp+cZk+f/Pc+wlJrmXwfEz1j1GSS5O8/dw0gzf7nlzU7QhwSwauA84O/Xu5FpY96lqPfTZk+LW0D3hwiT6/DXwoyeVt+OJDrW2qklwP/Czwkap6dZk+ozz3k65r+L2ff7LM9tbrciz/CPhmVZ1YauFa7K83yInpvNam9e7zWt0YnFHyBwze5f+51vbvGbzwAd7GYGhgHvg94J1rVNf7GPwb9gTweLvtAX4S+MnW53bgKQZnJTwM/P01qOudbXtfa9s+t8+G6wqDL7F5Fvg6MLuGz+elDAL8sqG2Nd9nDP7gnAL+H4Ox0f0M3vs5BjwD/G/gitZ3Fvj00Lo/3l5v88Cta1TbPIPx3HOvtXNnpv0t4KE3eu6nXNevttfQEwxCbMviutr8d/0eT7Ou1v4r515XQ33XbH+1bSyXE1N5rXlpBUnqxIU+pCNJGpGBL0mdMPAlqRMGviR1wsCXpE4Y+JLUCQNfkjrx/wEjVjzZC70PQwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(np.arange(20),[6,11,0,2,39,1,19,1,30,31,0,15,1,5,12,3,21,8,2,26])"
      ],
      "metadata": {
        "id": "5OzeNngb4VTp",
        "outputId": "d4e71421-b51f-405a-de0d-4e175cf389b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}